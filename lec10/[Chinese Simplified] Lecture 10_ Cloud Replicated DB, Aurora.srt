1
00:00:00,540 --> 00:00:04,850
好的，大家今天就开始

2
00:00:05,359 --> 00:00:10,620
吧，我是 Aurora 阿姨的四天

3
00:00:10,620 --> 00:00:12,450
论文，它是关于如何

4
00:00:12,450 --> 00:00:17,520
让高性能可靠的

5
00:00:17,520 --> 00:00:19,650
数据库作为云基础设施运行的

6
00:00:19,650 --> 00:00:22,800
，它本身是由 Amazon 自己提供的基础设施构建的

7
00:00:22,800 --> 00:00:29,100
，所以

8
00:00:29,100 --> 00:00:30,210
我们阅读这篇论文

9
00:00:30,210 --> 00:00:32,098
的原因首先是它是

10
00:00:32,098 --> 00:00:34,290
最近来自亚马逊的非常成功的云服务，

11
00:00:34,290 --> 00:00:38,480
很多客户都在使用它

12
00:00:38,480 --> 00:00:41,460
 

13
00:00:41,460 --> 00:00:44,820
 

14
00:00:44,820 --> 00:00:46,530
哪种

15
00:00:46,530 --> 00:00:48,380
总结性能表明，

16
00:00:48,380 --> 00:00:51,210
相对于其他一些

17
00:00:51,210 --> 00:00:53,430
没有很好解释的系统，该论文

18
00:00:53,430 --> 00:00:55,770
声称可以将事务吞吐量提高 35 倍，

19
00:00:55,770 --> 00:00:57,480
这

20
00:00:57,480 --> 00:01:00,329
非常令人印象深刻。

21
00:01:00,329 --> 00:01:03,149
 

22
00:01:03,149 --> 00:01:04,680
 

23
00:01:04,680 --> 00:01:06,750
使用通用存储来提高性能和容错性，

24
00:01:06,750 --> 00:01:08,310
因为论文的主题之一是

25
00:01:08,310 --> 00:01:10,470
他们基本上放弃了通用

26
00:01:10,470 --> 00:01:12,510
存储，他们转而使用 从

27
00:01:12,510 --> 00:01:14,250
他们使用亚马逊自己

28
00:01:14,250 --> 00:01:16,040
的通用存储基础设施的设计开始，他们

29
00:01:16,040 --> 00:01:17,970
认为这还不够好，

30
00:01:17,970 --> 00:01:19,409
基本上构建了完全

31
00:01:19,409 --> 00:01:22,320
特定于应用程序的存储，

32
00:01:22,320 --> 00:01:23,940
此外，该论文还有很多

33
00:01:23,940 --> 00:01:25,590
关于这方面的重要内容的小花絮

34
00:01:25,590 --> 00:01:29,100
，以及 一种

35
00:01:29,100 --> 00:01:32,490
云基础设施世界，所以在

36
00:01:32,490 --> 00:01:35,010
谈论极光之前，我想

37
00:01:35,010 --> 00:01:36,510
花点时间回顾一下过去的

38
00:01:36,510 --> 00:01:38,729
历史，或者我对

39
00:01:38,729 --> 00:01:41,270
导致极光设计的故事的印象是什么，

40
00:01:41,270 --> 00:01:43,830
因为你知道那种

41
00:01:43,830 --> 00:01:47,310
m f  - 亚马逊认为

42
00:01:47,310 --> 00:01:49,950
你应该构建他们的云

43
00:01:49,950 --> 00:01:51,810
客户应该在亚马逊的基础设施上构建数据库的方式，

44
00:01:51,810 --> 00:01:55,140
所以一

45
00:01:55,140 --> 00:02:02,850
开始亚马逊基本上提供了他们

46
00:02:02,850 --> 00:02:05,369
的第一个云产品来

47
00:02:05,369 --> 00:02:06,659
支持那些想要构建

48
00:02:06,659 --> 00:02:09,419
网站但使用亚马逊的硬件和

49
00:02:09,419 --> 00:02:11,459
在亚马逊的机房里，他们的第一个

50
00:02:11,459 --> 00:02:14,900
产品

51
00:02:14,900 --> 00:02:20,099
显然也是弹性云的 ec2，

52
00:02:20,099 --> 00:02:21,750
这里的想法是亚马逊有很大的

53
00:02:21,750 --> 00:02:23,520
机房里装满了服务器，他们

54
00:02:23,520 --> 00:02:25,020
在他们的服务器上运行虚拟机监视器

55
00:02:25,020 --> 00:02:26,730
，他们将虚拟

56
00:02:26,730 --> 00:02:30,420
机出租给他们的客户，然后他们的

57
00:02:30,420 --> 00:02:32,190
客户就会知道租用

58
00:02:32,190 --> 00:02:34,020
一堆虚拟机并运行 Web

59
00:02:34,020 --> 00:02:36,030
服务器和数据库以及

60
00:02:36,030 --> 00:02:39,330
他们所拥有的一切 需要在这些

61
00:02:39,330 --> 00:02:42,500
ec2 实例中运行，因此一台

62
00:02:42,500 --> 00:02:47,989
物理服务器的图片看起来像这样 亚马逊

63
00:02:47,989 --> 00:02:50,519
我们控制

64
00:02:50,519 --> 00:02:53,010
这台硬件服务器上的虚拟机监视器，然后

65
00:02:53,010 --> 00:02:54,810
会有一堆客人一堆 ec2

66
00:02:54,810 --> 00:02:57,720
实例，每个都租给

67
00:02:57,720 --> 00:02:59,730
不同的 云客户中的每

68
00:02:59,730 --> 00:03:01,049
一个都只运行

69
00:03:01,049 --> 00:03:06,989
像 Linux 这样的标准操作系统，然后你知道一个

70
00:03:06,989 --> 00:03:11,060
Web 服务器或者可能是一个数据库服务器

71
00:03:11,060 --> 00:03:14,069
，这些相对便宜，

72
00:03:14,069 --> 00:03:17,100
相对容易设置，并且作为一项非常

73
00:03:17,100 --> 00:03:22,290
成功的服务，所以一个小细节

74
00:03:22,290 --> 00:03:23,940
对你来说非常重要

75
00:03:23,940 --> 00:03:28,500
我们最初获得存储

76
00:03:28,500 --> 00:03:30,180
的方式是，如果您租用一个 ec2 实例，您获得存储的方式

77
00:03:30,180 --> 00:03:33,269
是

78
00:03:33,269 --> 00:03:35,480
他们的每台服务器都有一个 di  sk 附加了一个

79
00:03:35,480 --> 00:03:38,430
物理磁盘

80
00:03:38,430 --> 00:03:41,400
，他们租给

81
00:03:41,400 --> 00:03:43,470
客户的每个实例都会让我们知道

82
00:03:43,470 --> 00:03:46,890
磁盘的一部分，所以他们说本地

83
00:03:46,890 --> 00:03:48,959
附加存储，你有一些

84
00:03:48,959 --> 00:03:50,430
本地附加存储，它本身

85
00:03:50,430 --> 00:03:52,109
看起来就像一个硬盘 将模拟

86
00:03:52,109 --> 00:03:56,810
硬盘驱动到虚拟机来宾

87
00:03:56,870 --> 00:04:00,480
ec2 非常适合用于

88
00:04:00,480 --> 00:04:02,220
无状态 Web 服务器的 Web 服务器 您知道您的

89
00:04:02,220 --> 00:04:04,200
客户使用他们的 Web 浏览器将

90
00:04:04,200 --> 00:04:07,230
连接到运行 Web 服务器的一堆租用的 ec2

91
00:04:07,230 --> 00:04:10,920
实例，如果

92
00:04:10,920 --> 00:04:12,299
您添加了所有 突然多了更多客户，

93
00:04:12,299 --> 00:04:14,190
您可以立即从 Amazon 租用更多 ec2

94
00:04:14,190 --> 00:04:15,540
实例

95
00:04:15,540 --> 00:04:17,940
并在其上启动 Web 服务器，这

96
00:04:17,940 --> 00:04:20,039
是一种扩展您

97
00:04:20,039 --> 00:04:23,280
处理 Web 负载的能力的简单方法，因此

98
00:04:23,280 --> 00:04:26,040
它对 Web 服务器有好处，

99
00:04:26,040 --> 00:04:27,660
但人们运行的另一个主要内容

100
00:04:27,660 --> 00:04:30,510
在 ec2 实例中，这是数据库，

101
00:04:30,510 --> 00:04:32,280
因为通常一个网站是

102
00:04:32,280 --> 00:04:34,800
由一组无状态 Web 服务器构成的，

103
00:04:34,800 --> 00:04:37,500
只要他们需要获取永久

104
00:04:37,500 --> 00:04:40,590
数据，就可以与后端数据库通信 因此

105
00:04:40,590 --> 00:04:43,590
，您将得到的可能是亚马逊网络基础设施之外

106
00:04:43,590 --> 00:04:48,060
的外部世界中的一堆客户端浏览器

107
00:04:48,060 --> 00:04:50,910
 

108
00:04:50,910 --> 00:04:56,670
，然后是您需要的许多 ec2 Web 服务器

109
00:04:56,670 --> 00:04:58,470
实例来

110
00:04:58,470 --> 00:05:00,630
运行网站的逻辑，

111
00:05:00,630 --> 00:05:05,310
这就是 现在在亚马逊内部，然后

112
00:05:05,310 --> 00:05:10,880
还有一些通常是一个

113
00:05:10,880 --> 00:05:13,830
运行数据库的 ec2 实例，您的 Web 服务器

114
00:05:13,830 --> 00:05:15,510
将与您的数据库实例通信并

115
00:05:15,510 --> 00:05:16,920
要求它在数据库中读取和写入记录，

116
00:05:16,920 --> 00:05:19,890
不幸的是，ec2 并不

117
00:05:19,890 --> 00:05:22,560
完美，它几乎同样适合

118
00:05:22,560 --> 00:05:24,270
运行 一个用于运行

119
00:05:24,270 --> 00:05:25,890
Web 服务器的数据库，最直接的

120
00:05:25,890 --> 00:05:29,820
原因是存储或

121
00:05:29,820 --> 00:05:32,550
为您的 ec2 数据库实例获取存储的主要简单方法

122
00:05:32,550 --> 00:05:35,100
是在本地

123
00:05:35,100 --> 00:05:39,600
连接的磁盘上，该磁盘连接到

124
00:05:39,600 --> 00:05:41,670
您的数据库实例的任何硬件

125
00:05:41,670 --> 00:05:44,070
当前运行实际上

126
00:05:44,070 --> 00:05:46,740
硬件崩溃了，那么您也

127
00:05:46,740 --> 00:05:48,300
无法访问其硬盘驱动器上的任何内容，

128
00:05:48,300 --> 00:05:51,750
因此，如果它是实际实现 Web 服务器的硬件，则

129
00:05:51,750 --> 00:05:54,210
 

130
00:05:54,210 --> 00:05:55,590
不会崩溃 完全有问题，因为

131
00:05:55,590 --> 00:05:57,660
它本身真的没有状态，你

132
00:05:57,660 --> 00:05:59,280
只需在一个新的 ec2 实例上启动一个新的 Web 服务器，

133
00:05:59,280 --> 00:06:02,010
如果 ec2 实例是一个

134
00:06:02,010 --> 00:06:04,740
正在运行的硬件，它崩溃了，

135
00:06:04,740 --> 00:06:06,210
你有一个严重的问题，

136
00:06:06,210 --> 00:06:08,940
如果数据存储在本地

137
00:06:08,940 --> 00:06:13,050
连接 磁盘所以最初至少

138
00:06:13,050 --> 00:06:15,030
没有多少帮助

139
00:06:15,030 --> 00:06:17,130
来做这件事做得

140
00:06:17,130 --> 00:06:19,050
很好的是亚马逊确实提供了

141
00:06:19,050 --> 00:06:22,620
这种用于存储大量数据的大型方案，

142
00:06:22,620 --> 00:06:24,420
称为 s3，

143
00:06:24,420 --> 00:06:25,950
你可以拍摄快照

144
00:06:25,950 --> 00:06:27,720
如果您需要基本

145
00:06:27,720 --> 00:06:30,870
状态并存储在 s3 中，则拍摄 Prius 定期快照并将其用于

146
00:06:30,870 --> 00:06:34,860
某种备份灾难恢复，但您

147
00:06:34,860 --> 00:06:36,870
知道定期快照的样式

148
00:06:36,870 --> 00:06:38,460
意味着您将丢失

149
00:06:38,460 --> 00:06:39,270
 

150
00:06:39,270 --> 00:06:43,080
在定期备份之间发生的更新，

151
00:06:43,080 --> 00:06:45,390
所以接下来的事情 随之而来

152
00:06:45,390 --> 00:06:47,640
的与 Aurora

153
00:06:47,640 --> 00:06:51,120
数据库故事相关的是，为了

154
00:06:51,120 --> 00:06:55,170
向他们的客户提供用于

155
00:06:55,170 --> 00:06:57,300
他们的 ec2 实例的磁盘，

156
00:06:57,300 --> 00:06:59,370
如果出现故障，这些磁盘不会消失 ilure 是一种更具

157
00:06:59,370 --> 00:07:01,920
容错性的长期存储

158
00:07:01,920 --> 00:07:04,470
，可以保证在那里亚马逊推出

159
00:07:04,470 --> 00:07:08,280
了名为 EBS 的服务，这

160
00:07:08,280 --> 00:07:09,840
代表弹性块存储，

161
00:07:09,840 --> 00:07:12,540
因此 EBS 是一种查看 ec2 实例的服务，

162
00:07:12,540 --> 00:07:16,530
它查看其中

163
00:07:16,530 --> 00:07:17,940
一个实例 这些来宾

164
00:07:17,940 --> 00:07:19,710
虚拟机之一就像它是一个

165
00:07:19,710 --> 00:07:21,990
硬盘驱动器一样，您可以将其

166
00:07:21,990 --> 00:07:24,150
格式化为硬盘驱动器，但是

167
00:07:24,150 --> 00:07:27,120
像 ext3 这样的文件系统或

168
00:07:27,120 --> 00:07:28,890
您喜欢的任何 Linux 文件系统在

169
00:07:28,890 --> 00:07:30,630
这个看起来像来宾的东西上 一个硬盘

170
00:07:30,630 --> 00:07:31,920
驱动器，但它的实际

171
00:07:31,920 --> 00:07:35,280
实现方式是一对复制的

172
00:07:35,280 --> 00:07:40,890
存储服务器，所以

173
00:07:40,890 --> 00:07:43,520
这是本地存储，这是 Mike 的本地存储之一，

174
00:07:43,520 --> 00:07:47,550
如果 EBS 出现，那么你

175
00:07:47,550 --> 00:07:49,590
可以租一个 e BS 卷

176
00:07:49,590 --> 00:07:50,670
就像一个普通的

177
00:07:50,670 --> 00:07:53,130
硬盘驱动器，但它实际上

178
00:07:53,130 --> 00:07:59,090
是成对实现的，所以这些是 EBS 服务器 一

179
00:07:59,090 --> 00:08:03,840
对 EBS 服务器，每个都有一个

180
00:08:03,840 --> 00:08:09,360
附加的硬盘驱动器，所以如果你的软件

181
00:08:09,360 --> 00:08:10,920
在这里，也许你现在正在运行一个数据库

182
00:08:10,920 --> 00:08:13,080
并且你的 当数据库服务器不写入时，数据库挂载其中一个

183
00:08:13,080 --> 00:08:15,120
EBS 卷作为其存储，

184
00:08:15,120 --> 00:08:16,350
这

185
00:08:16,350 --> 00:08:18,120
实际上意味着

186
00:08:18,120 --> 00:08:19,830
通过网络发送出去并使用

187
00:08:19,830 --> 00:08:21,300
我们上周谈到的链式复制的

188
00:08:21,300 --> 00:08:24,030
权利，你是对的，你首先知道

189
00:08:24,030 --> 00:08:27,450
写入

190
00:08:27,450 --> 00:08:28,970
支持您的卷的第一台 CBS 服务器上的 EBS 服务器

191
00:08:28,970 --> 00:08:30,960
，然后是第二台服务器，

192
00:08:30,960 --> 00:08:33,330
最后您得到回复，同样，

193
00:08:33,330 --> 00:08:35,760
当您进行读取时，我猜一些链

194
00:08:35,760 --> 00:08:37,380
复制您将成为链中的最后一个，

195
00:08:37,380 --> 00:08:41,789
所以现在数据库 在 ec2 实例上运行

196
00:08:41,789 --> 00:08:44,250
有可用的存储系统

197
00:08:44,250 --> 00:08:46,040
，该系统实际上可以在崩溃后幸存下来

198
00:08:46,040 --> 00:08:48,660
 

199
00:08:48,660 --> 00:08:50,040
 

200
00:08:50,040 --> 00:08:53,430
 

201
00:08:53,430 --> 00:08:55,170
 

202
00:08:55,170 --> 00:08:58,110
到

203
00:08:58,110 --> 00:09:01,110
 

204
00:09:01,110 --> 00:09:03,540
您的数据库的先前版本

205
00:09:03,540 --> 00:09:04,800
所附加到的同一个旧 EB​​S 卷，它会看到所有旧

206
00:09:04,800 --> 00:09:07,110
数据，就像它被

207
00:09:07,110 --> 00:09:10,500
先前的数据库遗漏一样 您将

208
00:09:10,500 --> 00:09:11,760
硬盘从一台机器移到另一台机器上，

209
00:09:11,760 --> 00:09:14,910
因此 EBS 对于

210
00:09:14,910 --> 00:09:16,230
需要它来保持永久

211
00:09:16,230 --> 00:09:26,850
状态（如运行数据库的人）的人

212
00:09:26,850 --> 00:09:29,520
来说

213
00:09:29,520 --> 00:09:33,180
真的

214
00:09:33,180 --> 00:09:36,260
很划算 随时共享的系统

215
00:09:36,260 --> 00:09:41,339
只有一个 ec2 实例 只有一个虚拟

216
00:09:41,339 --> 00:09:43,770
机可以挂载给定的 EBS 卷，

217
00:09:43,770 --> 00:09:45,300
因此 EBS 卷是在一个

218
00:09:45,300 --> 00:09:47,730
庞大的舰队上实现的

219
00:09:47,730 --> 00:09:49,620
 

220
00:09:49,620 --> 00:09:52,410
 

221
00:09:52,410 --> 00:09:55,170
每个人的 EBS 卷都存储在

222
00:09:55,170 --> 00:09:58,740
这个庞大的服务器池中，但是

223
00:09:58,740 --> 00:10:01,080
每个 PPS 卷中的每一个都只能由

224
00:10:01,080 --> 00:10:08,270
一个 ec2 实例使用，只有一个

225
00:10:08,510 --> 00:10:13,290
客户可以使用 EBS 是一个很大的进步，但

226
00:10:13,290 --> 00:10:18,180
它仍然存在一些问题，所以

227
00:10:18,180 --> 00:10:19,230
还有一些 不

228
00:10:19,230 --> 00:10:22,830
完美的事情是，如果

229
00:10:22,830 --> 00:10:24,750
你在 EBS 上运行一个数据库，它最终会

230
00:10:24,750 --> 00:10:27,750
通过网络发送大量数据

231
00:10:27,750 --> 00:10:31,740
，这就是我们现在

232
00:10:31,740 --> 00:10:33,450
开始偷偷摸摸的数字

233
00:10:33,450 --> 00:10:36,750
在论文中的两篇文章中，他们开始

234
00:10:36,750 --> 00:10:38,670
抱怨

235
00:10:38,670 --> 00:10:40,950
如果您在网络存储系统上运行数据库需要多少次写入，因此

236
00:10:40,950 --> 00:10:45,660
 

237
00:10:45,660 --> 00:10:48,000
EBS 上的数据库最终会

238
00:10:48,000 --> 00:10:50,459
产生大量网络流量，并且

239
00:10:50,459 --> 00:10:53,220
其中一种

240
00:10:53,220 --> 00:10:55,890
论文中暗示的事情是，

241
00:10:55,890 --> 00:10:59,910
它们的网络受限与 CPU

242
00:10:59,910 --> 00:11:01,770
或存储受限一样多，也就是说，它们

243
00:11:01,770 --> 00:11:03,810
非常关注减少

244
00:11:03,810 --> 00:11:05,430
Aurora 论文发送大量

245
00:11:05,430 --> 00:11:07,260
关注来减少

246
00:11:07,260 --> 00:11:09,720
网络 数据库生成并且似乎

247
00:11:09,720 --> 00:11:12,060
不太担心消耗了多少 CPU 时间

248
00:11:12,060 --> 00:11:15,860
或磁盘空间，这

249
00:11:15,860 --> 00:11:18,150
在某种程度上暗示了他们认为

250
00:11:18,150 --> 00:11:20,640
重要的是 EBS 的另一个问题

251
00:11:20,640 --> 00:11:22,710
不是非常容错 事实证明

252
00:11:22,710 --> 00:11:25,320
，出于性能原因，我 'm

253
00:11:25,320 --> 00:11:26,970
done 将始终将 EBS

254
00:11:26,970 --> 00:11:29,490
和 EBS 卷的副本都

255
00:11:29,490 --> 00:11:32,730
放在同一个数据中心中，因此

256
00:11:32,730 --> 00:11:34,650
如果您

257
00:11:34,650 --> 00:11:36,030
知道您正在使用的两台 EBS 服务器中的一台，我们将有一台服务器崩溃

258
00:11:36,030 --> 00:11:37,440
c 猛冲没关系，因为您切换

259
00:11:37,440 --> 00:11:39,180
到另一个，但是根本没有

260
00:11:39,180 --> 00:11:40,650
故事可以说明如果整个数据中心发生故障会发生什么

261
00:11:40,650 --> 00:11:50,240
，并且

262
00:11:50,240 --> 00:11:53,580
显然很多客户确实

263
00:11:53,580 --> 00:11:55,260
想要一个故事，以使他们的

264
00:11:55,260 --> 00:11:57,840
数据能够在一次中断中幸存下来 整个

265
00:11:57,840 --> 00:12:00,210
数据中心可能失去了他的网络

266
00:12:00,210 --> 00:12:01,920
连接它是建筑物着火

267
00:12:01,920 --> 00:12:04,530
或整个建筑物的电源故障

268
00:12:04,530 --> 00:12:05,730
或者人们真的

269
00:12:05,730 --> 00:12:07,110
希望至少有一个选择，如果他们

270
00:12:07,110 --> 00:12:09,330
愿意支付更多的费用将他们的数据

271
00:12:09,330 --> 00:12:10,590
存储在一个 他们隐藏的方式他们

272
00:12:10,590 --> 00:12:13,860
仍然可以得到它我即使一个数据

273
00:12:13,860 --> 00:12:20,390
中心出现故障并且亚马逊

274
00:12:20,390 --> 00:12:25,470
描述的方式是

275
00:12:25,470 --> 00:12:29,940
实例及其 EBS 到 EBS 副本都

276
00:12:29,940 --> 00:12:32,360
处于相同的能力面纱能力区域

277
00:12:32,360 --> 00:12:34,740
和亚马逊行话 可用

278
00:12:34,740 --> 00:12:36,900
区是一个特定的数据中心，

279
00:12:36,900 --> 00:12:38,790
他们构建数据中心的方式是

280
00:12:38,790 --> 00:12:42,170
，通常有多个

281
00:12:42,170 --> 00:12:44,760
独立的数据中心

282
00:12:44,760 --> 00:12:46,680
或多或少位于同一个城市或彼此相对靠近，

283
00:12:46,680 --> 00:12:50,010
并且所有 多个

284
00:12:50,010 --> 00:12:52,560
可用性区域可能两个或

285
00:12:52,560 --> 00:12:54,180
三个彼此靠近，都

286
00:12:54,180 --> 00:12:56,340
通过冗余高速网络连接，

287
00:12:56,340 --> 00:12:58,290
因此附近总是有付款人或

288
00:12:58,290 --> 00:13:00,360
三倍的

289
00:13:00,360 --> 00:13:01,740
可用性中心，我们会看到

290
00:13:01,740 --> 00:13:03,360
购买很重要，但

291
00:13:03,360 --> 00:13:05,760
至少对于 EBS 为了

292
00:13:05,760 --> 00:13:08,040
降低使用链复制的成本，

293
00:13:08,040 --> 00:13:12,210
他们要求两个

294
00:13:12,210 --> 00:13:15,740
副本位于同一个可用区域中，

295
00:13:16,730 --> 00:13:21,900
嗯，在我

296
00:13:21,900 --> 00:13:27,630
深入了解 Aurora 实际工作原理之前，事实

297
00:13:27,630 --> 00:13:31,170
证明设计的细节是

298
00:13:31,170 --> 00:13:32,580
为了 了解它们，我们首先必须

299
00:13:32,580 --> 00:13:34,650
对典型数据库的设计类型有相当多的了解，

300
00:13:34,650 --> 00:13:36,450
因为

301
00:13:36,450 --> 00:13:40,230
它们采用的是数据库的主要机制

302
00:13:40,230 --> 00:13:42,360
，我的续集发生时

303
00:13:42,360 --> 00:13:44,940
并以有趣的方式将其拆分，因此

304
00:13:44,940 --> 00:13:46,650
我们需要了解排序 它

305
00:13:46,650 --> 00:13:48,390
是一个数据库的作用，所以我们可以

306
00:13:48,390 --> 00:13:50,880
理解它们是如何拆分它的，所以这实际上是

307
00:13:50,880 --> 00:13:58,140
一种数据库教程，真正

308
00:13:58,140 --> 00:14:01,760
关注于实现

309
00:14:01,760 --> 00:14:04,110
事务所需的内容 ns 崩溃的可恢复

310
00:14:04,110 --> 00:14:06,210
事务，所以我真正关心的

311
00:14:06,210 --> 00:14:14,430
是事务和崩溃恢复，

312
00:14:14,430 --> 00:14:17,070
数据库中还有很多其他事情，

313
00:14:17,070 --> 00:14:18,960
但这确实是本文重要的部分，

314
00:14:18,960 --> 00:14:22,320
所以首先

315
00:14:22,320 --> 00:14:24,270
你知道什么是事务，事务

316
00:14:24,270 --> 00:14:27,000
只是包装多个 对

317
00:14:27,000 --> 00:14:28,710
可能不同的数据进行操作，并

318
00:14:28,710 --> 00:14:31,380
声明整个

319
00:14:31,380 --> 00:14:33,420
操作序列

320
00:14:33,420 --> 00:14:35,970
对于正在读取或写入数据的任何其他人来说都应该是一个 Tomic，

321
00:14:35,970 --> 00:14:38,750
因此您可能会看到

322
00:14:38,750 --> 00:14:40,800
转置我们正在经营一家银行，并且我们

323
00:14:40,800 --> 00:14:43,110
希望在不同账户之间进行转账

324
00:14:43,110 --> 00:14:46,410
也许你会说我们

325
00:14:46,410 --> 00:14:48,600
会看到代码或者你知道看到一个

326
00:14:48,600 --> 00:14:50,220
交易看起来像这样你

327
00:14:50,220 --> 00:14:51,960
必须清除

328
00:14:51,960 --> 00:14:53,880
你希望在交易中成为原子的指令序列的开头

329
00:14:53,880 --> 00:14:55,890
也许我们

330
00:14:55,890 --> 00:14:59,250
要从账户转账 Y

331
00:14:59,250 --> 00:15:02,580
到帐户 X，所以我们可能会看到我将在哪里

332
00:15:02,580 --> 00:15:05,190
假装 X 是银行余额

333
00:15:05,190 --> 00:15:06,420
约旦数据库您可能会看到

334
00:15:06,420 --> 00:15:08,610
交易看起来像哦，我可以添加 10 美元

335
00:15:08,610 --> 00:15:11,589
到 X 的账户并从我的账户中

336
00:15:11,589 --> 00:15:14,029
扣除相同的 10 美元

337
00:15:14,029 --> 00:15:16,430
，这就是

338
00:15:16,430 --> 00:15:17,209
交易

339
00:15:17,209 --> 00:15:19,940
 

340
00:15:19,940 --> 00:15:21,949
 

341
00:15:21,949 --> 00:15:24,019
 

342
00:15:24,019 --> 00:15:27,230
的

343
00:15:27,230 --> 00:15:29,570
结束 此时此处某处发生崩溃，

344
00:15:29,570 --> 00:15:31,070
我们将

345
00:15:31,070 --> 00:15:32,720
确保在崩溃和恢复

346
00:15:32,720 --> 00:15:34,850
之后，值得修改的整个事务

347
00:15:34,850 --> 00:15:36,470
是可见的，或者

348
00:15:36,470 --> 00:15:40,100
它们都不可见，这就是我们

349
00:15:40,100 --> 00:15:41,389
希望从事务中获得的效果

350
00:15:41,389 --> 00:15:44,360
还有人们期望数据库

351
00:15:44,360 --> 00:15:46,639
用户期望数据库会告诉

352
00:15:46,639 --> 00:15:48,829
他们告诉提交事务的客户端

353
00:15:48,829 --> 00:15:51,199
事务

354
00:15:51,199 --> 00:15:52,880
是否真的完成和提交，

355
00:15:52,880 --> 00:15:55,329
如果事务被提交，我们期望

356
00:15:55,329 --> 00:15:58,040
客户端期望事务

357
00:15:58,040 --> 00:15:59,990
是永久的，

358
00:15:59,990 --> 00:16:02,000
即使数据库应该仍然存在 崩溃并

359
00:16:02,000 --> 00:16:05,720
 

360
00:16:05,720 --> 00:16:08,120
 

361
00:16:08,120 --> 00:16:10,010
重启 事务

362
00:16:10,010 --> 00:16:12,800
在使用它之前锁定每条数据

363
00:16:12,800 --> 00:16:15,980
，因此您可以查看它们在事务

364
00:16:15,980 --> 00:16:20,839
期间被锁定 x 和 y，

365
00:16:20,839 --> 00:16:22,490
并且这些仅

366
00:16:22,490 --> 00:16:24,560
在事务最终提交

367
00:16:24,560 --> 00:16:29,209
后才被释放，这已知是永久性的，如果您这样做，这很

368
00:16:29,209 --> 00:16:31,850
重要 对于一些

369
00:16:31,850 --> 00:16:33,260
你必须做的事情，如果你知道

370
00:16:33,260 --> 00:16:35,060
论文中的一些细节真的只有

371
00:16:35,060 --> 00:16:36,440
当你意识到

372
00:16:36,440 --> 00:16:38,720
数据库实际上

373
00:16:38,720 --> 00:16:40,220
在事务的生命周期中锁定了对数据的其他访问权限时才有意义，

374
00:16:40,220 --> 00:16:43,339
那么这实际上是如何

375
00:16:43,339 --> 00:16:47,620
实现的 数据库

376
00:16:48,699 --> 00:16:53,060
至少包含简单的

377
00:16:53,060 --> 00:16:55,250
数据库模型，其中数据库

378
00:16:55,250 --> 00:16:56,750
通常被编写为在单个

379
00:16:56,750 --> 00:16:58,190
服务器上运行，您知道一些

380
00:16:58,190 --> 00:17:00,260
直接连接的存储，并且

381
00:17:00,260 --> 00:17:01,550
Aurora 论文正在玩的游戏有点

382
00:17:01,550 --> 00:17:05,329
移动该软件，只是适度

383
00:17:05,329 --> 00:17:07,339
修改 为了在更

384
00:17:07,339 --> 00:17:09,559
复杂的网络系统上运行，但

385
00:17:09,559 --> 00:17:11,390
起点是我们只是假设我们

386
00:17:11,390 --> 00:17:16,520
有一个数据库，该数据库连接到一个磁盘

387
00:17:16,520 --> 00:17:18,819
上的磁盘结构存储 这些

388
00:17:18,819 --> 00:17:21,559
记录是某种索引

389
00:17:21,559 --> 00:17:24,190
结构，例如 b-

390
00:17:24,190 --> 00:17:25,960
 

391
00:17:25,960 --> 00:17:27,819
 

392
00:17:27,819 --> 00:17:32,260
 

393
00:17:32,260 --> 00:17:34,630
 

394
00:17:34,630 --> 00:17:36,580
tree 这些数据页

395
00:17:36,580 --> 00:17:40,260
通常保存大量记录，

396
00:17:40,260 --> 00:17:42,340
而 X 和 y 通常只是数据库中

397
00:17:42,340 --> 00:17:44,320
某个页面上的

398
00:17:44,320 --> 00:17:46,740
几口，因此在磁盘上有

399
00:17:46,740 --> 00:17:49,990
实际数据，在磁盘上

400
00:17:49,990 --> 00:17:55,660
还有一个正前方日志或 wal 和

401
00:17:55,660 --> 00:17:57,400
正前方 日志是

402
00:17:57,400 --> 00:18:00,010
系统

403
00:18:00,010 --> 00:18:03,010
在数据库服务器内部具有容错能力的关键部分

404
00:18:03,010 --> 00:18:05,530
有数据库软件

405
00:18:05,530 --> 00:18:08,230
数据库通常具有从磁盘读取的页面缓存

406
00:18:08,230 --> 00:18:11,050
 

407
00:18:11,050 --> 00:18:13,210
执行事务时它最近使用的页面

408
00:18:13,210 --> 00:18:15,250
实际执行

409
00:18:15,250 --> 00:18:16,990
这些 语句的真正含义

410
00:18:16,990 --> 00:18:19,330
是您知道 x 等于 x 加 10

411
00:18:19,330 --> 00:18:21,880
变成运行时是

412
00:18:21,880 --> 00:18:23,800
数据库从磁盘读取当前保存

413
00:18:23,800 --> 00:18:27,520
X 的页面并将 10 添加到它但是所以

414
00:18:27,520 --> 00:18:29,920
直到事务提交之前，

415
00:18:29,920 --> 00:18:31,480
它只在本地缓存中进行修改，而

416
00:18:31,480 --> 00:18:34,030
不是在磁盘上，因为我们

417
00:18:34,030 --> 00:18:35,080
不想公开我们还不想

418
00:18:35,080 --> 00:18:37,030
在磁盘上写入，并且该部分

419
00:18:37,030 --> 00:18:42,720
可能会公开部分事务，所以

420
00:18:42,990 --> 00:18:46,180
当 数据库，但之前

421
00:18:46,180 --> 00:18:47,980
因为数据库想要

422
00:18:47,980 --> 00:18:50,590
预先清除完整的事务，因此

423
00:18:50,590 --> 00:18:53,140
它在

424
00:18:53,140 --> 00:18:56,290
崩溃后和恢复期间可供软件使用，然后

425
00:18:56,290 --> 00:18:57,910
允许数据库修改

426
00:18:57,910 --> 00:18:59,950
磁盘上的实际数据页，首先需要

427
00:18:59,950 --> 00:19:03,960
添加描述的日志条目

428
00:19:03,960 --> 00:19:06,400
事务，因此它必须按顺序

429
00:19:06,400 --> 00:19:07,870
提交事务，它

430
00:19:07,870 --> 00:19:09,310
需要将一组完整的

431
00:19:09,310 --> 00:19:11,710
日志提前条目放在磁盘上的右前日志中

432
00:19:11,710 --> 00:19:13,720
我正在描述所有数据库

433
00:19:13,720 --> 00:19:15,940
修改所以让我们在这里假设

434
00:19:15,940 --> 00:19:20,740
x 和 y 开始 比如说 500 和 y

435
00:19:20,740 --> 00:19:24,040
以 750 开头，我们希望

436
00:19:24,040 --> 00:19:26,830
在提交

437
00:19:26,830 --> 00:19:29,170
之前和写入页面之前执行这个事务，数据库

438
00:19:29,170 --> 00:19:31,750
通常会添加至少 3 条日志

439
00:19:31,750 --> 00:19:34,480
记录 1 这个 tha  t 说得很好，作为

440
00:19:34,480 --> 00:19:37,380
此交易的一部分，我正在修改 X

441
00:19:37,380 --> 00:19:43,530
，它的旧值是 500 在此处腾出更多空间

442
00:19:43,530 --> 00:19:50,250
这是 on dis 日志，因此每个日志

443
00:19:50,250 --> 00:19:52,350
条目可能会说这是我正在修改的值

444
00:19:52,350 --> 00:19:56,730
这是旧值，我们是

445
00:19:56,730 --> 00:19:58,680
添加，这是新值说五十，

446
00:19:58,680 --> 00:20:02,070
所以这是一个日志记录另一个 4y

447
00:20:02,070 --> 00:20:04,800
可能是旧值是 750 我们

448
00:20:04,800 --> 00:20:07,410
减去 10 所以新值是 740

449
00:20:07,410 --> 00:20:11,310
，然后当数据库

450
00:20:11,310 --> 00:20:12,810
实际上设法到达事务结束

451
00:20:12,810 --> 00:20:14,400
时 在崩溃之前它

452
00:20:14,400 --> 00:20:18,450
会写一个提交记录说，

453
00:20:18,450 --> 00:20:20,310
通常这些都

454
00:20:20,310 --> 00:20:23,220
用事务ID标记，这样

455
00:20:23,220 --> 00:20:24,930
恢复软件最终会

456
00:20:24,930 --> 00:20:27,660
知道这个提交记录是如何引用这些

457
00:20:27,660 --> 00:20:32,420
日志记录的，是的，

458
00:20:36,590 --> 00:20:38,970
在一个简单的数据库中就

459
00:20:38,970 --> 00:20:41,610
足以存储 新值，说得好，

460
00:20:41,610 --> 00:20:43,980
这是一个崩溃，我们将重新应用

461
00:20:43,980 --> 00:20:47,240
所有新值大多数

462
00:20:47,240 --> 00:20:50,850
严肃的数据库存储旧值

463
00:20:50,850 --> 00:20:52,380
和新值的原因是给他们自由

464
00:20:52,380 --> 00:20:56,430
，即使是长期运行的牵引力

465
00:20:56,430 --> 00:20:57,840
-运行 tra  nsaction 甚至

466
00:20:57,840 --> 00:20:59,610
在事务完成之前它使

467
00:20:59,610 --> 00:21:00,900
数据库可以自由地将

468
00:21:00,900 --> 00:21:04,490
更新的页面写入磁盘，新值

469
00:21:04,490 --> 00:21:07,350
740 假设从未

470
00:21:07,350 --> 00:21:10,590
完成的事务开始，只要它已将

471
00:21:10,590 --> 00:21:11,970
日志记录写入磁盘，然后

472
00:21:11,970 --> 00:21:13,920
如果之前发生崩溃 提交

473
00:21:13,920 --> 00:21:15,420
恢复软件总是说啊哈

474
00:21:15,420 --> 00:21:17,190
这个事务从未完成

475
00:21:17,190 --> 00:21:19,050
因此我们必须撤消它的所有

476
00:21:19,050 --> 00:21:21,300
更改和这些值这些旧

477
00:21:21,300 --> 00:21:22,680
值是您需要的值

478
00:21:22,680 --> 00:21:24,330
以便撤消已

479
00:21:24,330 --> 00:21:26,610
部分写入数据页的事务所

480
00:21:26,610 --> 00:21:32,730
以极光 确实使用撤消重做日志

481
00:21:32,730 --> 00:21:35,870
能够撤消部分应用的

482
00:21:35,870 --> 00:21:40,200
事务，所以如果数据库

483
00:21:40,200 --> 00:21:42,240
设法获得

484
00:21:42,240 --> 00:21:44,190
磁盘上的事务日志记录

485
00:21:44,190 --> 00:21:46,430
并且提交记录标记完成，

486
00:21:46,430 --> 00:21:48,990
那么它有权申请

487
00:21:48,990 --> 00:21:50,160
我们所说的客户端

488
00:21:50,160 --> 00:21:51,900
提交的事务数据库可以回复

489
00:21:51,900 --> 00:21:53,850
客户端，客户端可以放心

490
00:21:53,850 --> 00:21:56,400
，它的事务将

491
00:21:56,400 --> 00:21:59,970
永远可见 d 现在发生了两件事之一，

492
00:21:59,970 --> 00:22:01,320
数据库服务器

493
00:22:01,320 --> 00:22:04,500
最终没有崩溃，所以

494
00:22:04,500 --> 00:22:08,880
它在缓存中修改了这些 X&Y

495
00:22:08,880 --> 00:22:13,020
记录为 510 和 740，最终

496
00:22:13,020 --> 00:22:15,930
数据库会将其缓存的更新

497
00:22:15,930 --> 00:22:18,180
块写入磁盘上的真实位置，而

498
00:22:18,180 --> 00:22:20,640
不是写你 知道这些是树

499
00:22:20,640 --> 00:22:22,380
节点或其他东西，然后数据库

500
00:22:22,380 --> 00:22:26,550
可以重用这部分日志，所以

501
00:22:26,550 --> 00:22:27,990
数据库往往对此很懒惰，

502
00:22:27,990 --> 00:22:30,240
因为它们喜欢累积你知道

503
00:22:30,240 --> 00:22:32,430
 

504
00:22:32,430 --> 00:22:34,820
缓存中这些页面可能会有很多更新，累积起来很好

505
00:22:34,820 --> 00:22:37,050
 

506
00:22:37,050 --> 00:22:39,900
如果数据库

507
00:22:39,900 --> 00:22:41,520
服务器在将这些页面写入磁盘的日期之前崩溃，则在被迫写入磁盘之前进行大量更新，

508
00:22:41,520 --> 00:22:43,770
因此它们

509
00:22:43,770 --> 00:22:47,160
仍然具有旧值，那么可以

510
00:22:47,160 --> 00:22:49,050
保证

511
00:22:49,050 --> 00:22:49,880
当您重新启动该

512
00:22:49,880 --> 00:22:53,600
debase 扫描日志时恢复软件会看到这些

513
00:22:53,600 --> 00:22:54,950
事务的记录看到该

514
00:22:54,950 --> 00:22:58,550
事务已提交并将

515
00:22:58,550 --> 00:23:03,970
新值应用于存储的数据，

516
00:23:03,970 --> 00:23:07,070
这称为重做它基本上完成了

517
00:23:07,070 --> 00:23:11,870
所有权利 简而言之，这

518
00:23:11,870 --> 00:23:15,260
就是事务数据库的工作方式

519
00:23:15,260 --> 00:23:18,440
，因此这是一种

520
00:23:18,440 --> 00:23:22,150
非常简略的版本，

521
00:23:22,150 --> 00:23:25,340
例如我的续集数据库如何

522
00:23:25,340 --> 00:23:28,820
工作，Aurora 基于这个

523
00:23:28,820 --> 00:23:30,170
开源软件，称为

524
00:23:30,170 --> 00:23:32,540
数据库，称为我的续集，它确实

525
00:23:32,540 --> 00:23:34,610
崩溃恢复事务和崩溃

526
00:23:34,610 --> 00:23:40,370
恢复在很大程度上是这样的，所以

527
00:23:40,370 --> 00:23:44,690
亚马逊开发的下一步是为其云客户开发一个

528
00:23:44,690 --> 00:23:46,730
越来越好的数据库基础设施，

529
00:23:46,730 --> 00:23:50,260
称为

530
00:23:50,260 --> 00:23:53,870
RDS，我只谈论 RDS，

531
00:23:53,870 --> 00:23:55,640
因为事实证明，

532
00:23:55,640 --> 00:23:56,720
即使论文没有 ' 没有完全提到它

533
00:23:56,720 --> 00:23:58,880
论文中的图 2 基本上是

534
00:23:58,880 --> 00:24:01,550
对 RDS 的描述

535
00:24:01,550 --> 00:24:04,280
，所以 RDS 是第一次

536
00:24:04,280 --> 00:24:07,160
尝试获取在多个可用区中复制的数据库，

537
00:24:07,160 --> 00:24:09,440
因此

538
00:24:09,440 --> 00:24:12,740
如果整个数据中心出现故障，您

539
00:24:12,740 --> 00:24:14,360
可以取回您的数据库内容

540
00:24:14,360 --> 00:24:16,850
而不会丢失任何权利，因此

541
00:24:16,850 --> 00:24:20,330
处理 RDS 是您有

542
00:24:20,330 --> 00:24:22,910
一个 ec2 实例，即数据库

543
00:24:22,910 --> 00:24:23,570
服务器

544
00:24:23,570 --> 00:24:24,920
你只有一个你只想

545
00:24:24,920 --> 00:24:28,490
运行一个数据库它存储它的数据

546
00:24:28,490 --> 00:24:31,690
页并基本上用这个

547
00:24:31,690 --> 00:24:34,460
而不是在本地磁盘上记录它

548
00:24:34,460 --> 00:24:36,350
把它们存储在 EBS 中所以每当

549
00:24:36,350 --> 00:24:38,090
数据库执行日志写入或页面写入或

550
00:24:38,090 --> 00:24:40,970
任何这些权利实际上 转到

551
00:24:40,970 --> 00:24:47,960
这两个 EBS 卷 EBS 副本，

552
00:24:47,960 --> 00:24:50,180
另外，这在一个

553
00:24:50,180 --> 00:24:54,230
可用区域中，此外

554
00:24:54,230 --> 00:24:55,910
，对于数据库软件所做的每次写入，

555
00:24:55,910 --> 00:24:58,100
亚马逊都会透明地进行，

556
00:24:58,100 --> 00:24:59,900
即使数据库没有意识到这种

557
00:24:59,900 --> 00:25:03,890
情况发生了，也将这些权限发送

558
00:25:03,890 --> 00:25:06,020
到特殊设置 在第二

559
00:25:06,020 --> 00:25:07,760
个机房的第二个可用区中

560
00:25:07,760 --> 00:25:13,190
- 只是从图 2 到

561
00:25:13,190 --> 00:25:14,960
显然是单独的计算机或 ec2

562
00:25:14,960 --> 00:25:16,730
实例或者其工作

563
00:25:16,730 --> 00:25:20,240
只是镜像的东西写入主数据库

564
00:25:20,240 --> 00:25:22,610
这样做，所以这种其他类型的镜像

565
00:25:22,610 --> 00:25:25,100
服务器然后只会复制这些

566
00:25:25,100 --> 00:25:30,980
对第二对 EBS 服务器的权限，因此

567
00:25:30,980 --> 00:25:33,170
通过此设置和此 RDS 设置

568
00:25:33,170 --> 00:25:36,050
，这就是数字 - 每次

569
00:25:36,050 --> 00:25:38,690
数据库附加到 th  e 日志或写入它的

570
00:25:38,690 --> 00:25:43,040
一个页面 必须将数据

571
00:25:43,040 --> 00:25:44,750
发送到这两个副本 必须

572
00:25:44,750 --> 00:25:47,210
通过网络连接

573
00:25:47,210 --> 00:25:49,490
 

574
00:25:49,490 --> 00:25:51,380
发送到城镇另一端的另一个可用区，然后发送到该镜像

575
00:25:51,380 --> 00:25:53,000
服务器 它是

576
00:25:53,000 --> 00:25:56,960
两个单独的 EBS 副本，然后

577
00:25:56,960 --> 00:25:59,210
最后这个回复会回来，

578
00:25:59,210 --> 00:26:00,590
然后才

579
00:26:00,590 --> 00:26:03,590
用 DAT bc AHA 完成我的写入完成我的写入

580
00:26:03,590 --> 00:26:07,010
完成我可以你知道计算这条日志

581
00:26:07,010 --> 00:26:08,270
记录它实际上

582
00:26:08,270 --> 00:26:09,260
是日志的附件或其他

583
00:26:09,260 --> 00:26:13,550
因此，这种 RDS 安排可以让您获得

584
00:26:13,550 --> 00:26:14,960
更好的容错能力，因为现在您

585
00:26:14,960 --> 00:26:17,060
拥有完整的最新数据库副本，

586
00:26:17,060 --> 00:26:18,770
 

587
00:26:18,770 --> 00:26:21,140
 

588
00:26:21,140 --> 00:26:23,660
即使您知道大火烧毁

589
00:26:23,660 --> 00:26:26,150
了整个数据中心的繁荣，也可以在单独的可用区中看到它们所有最新的写入 你可以

590
00:26:26,150 --> 00:26:28,670
削弱你可以在一个新

591
00:26:28,670 --> 00:26:30,860
实例和第二个可用

592
00:26:30,860 --> 00:26:36,640
区中运行数据库并且根本不丢失任何数据是

593
00:26:45,350 --> 00:26:48,869
的我不知道如何回答我的

594
00:26:48,869 --> 00:26:51,059
意思是这不是他们所做的

595
00:26:51,059 --> 00:26:54,600
我猜 对于

596
00:26:54,600 --> 00:26:56,279
大多数电动汽车客户来说，

597
00:26:56,279 --> 00:26:58,499
 

598
00:26:58,499 --> 00:27:02,399
跨两个独立的数据中心转发每个权利会非常缓慢，我

599
00:27:02,399 --> 00:27:04,289
不太确定发生了什么，但我认为

600
00:27:04,289 --> 00:27:06,539
他们不这样做的主要答案

601
00:27:06,539 --> 00:27:09,869
是

602
00:27:09,869 --> 00:27:11,879
EBS 工作方式的一些变通方法

603
00:27:11,879 --> 00:27:14,639
BS 太棘手了，实际上生产

604
00:27:14,639 --> 00:27:17,009
和使用现有的 EBS

605
00:27:17,009 --> 00:27:20,909
基础设施没有改变，我马夫特曼

606
00:27:20,909 --> 00:27:24,269
选择了这个，结果非常

607
00:27:24,269 --> 00:27:28,859
昂贵，或者无论如何它很贵，因为

608
00:27:28,859 --> 00:27:29,429
你可能认为

609
00:27:29,429 --> 00:27:30,929
你知道我们' 重新写入相当

610
00:27:30,929 --> 00:27:33,559
大量的数据，因为您甚至知道

611
00:27:33,559 --> 00:27:36,600
这个事务，它似乎

612
00:27:36,600 --> 00:27:38,789
只是修改了两个整数，比如可能是

613
00:27:38,789 --> 00:27:41,100
8 个字节，或者我不知道这里修改了什么十六个

614
00:27:41,100 --> 00:27:43,019
只知道几个字节的数据

615
00:27:43,019 --> 00:27:45,059
，这意味着

616
00:27:45,059 --> 00:27:46,889
什么 就数据库

617
00:27:46,889 --> 00:27:49,710
读写磁盘而言，我实际上这些日志

618
00:27:49,710 --> 00:27:51,720
记录也很小，所以

619
00:27:51,720 --> 00:27:53,159
这两个日志记录本身可能

620
00:27:53,159 --> 00:27:55,049
只有几十个字节长，

621
00:27:55,049 --> 00:27:57,359
这很好，但是

622
00:27:57,359 --> 00:27:58,950
实际数据页面的读取和写入可能

623
00:27:58,950 --> 00:28:02,009
远大于

624
00:28:02,009 --> 00:28:03,359
几十个字节，因为这些页面中的每一个

625
00:28:03,359 --> 00:28:05,519
都将是 8 KB

626
00:28:05,519 --> 00:28:08,129
或 16 KB 或一些相对较大的

627
00:28:08,129 --> 00:28:10,049
数字文件系统或磁盘块

628
00:28:10,049 --> 00:28:14,879
大小 这意味着当需要更新数据页面时，只需读取和

629
00:28:14,879 --> 00:28:17,399
写入这两个数字，

630
00:28:17,399 --> 00:28:19,559
就会有

631
00:28:19,559 --> 00:28:21,119
很多数据被推送到

632
00:28:21,119 --> 00:28:23,340
本地连接的磁盘上，现在

633
00:28:23,340 --> 00:28:26,460
它相当快，但我猜

634
00:28:26,460 --> 00:28:27,960
他们发现的是当他们 开始

635
00:28:27,960 --> 00:28:30,869
通过

636
00:28:30,869 --> 00:28:34,409
网络发送那些占用了太多

637
00:28:34,409 --> 00:28:37,999
网络容量而无法支持的大 8 KB 写入，所以

638
00:28:37,999 --> 00:28:40,080
这种安排这个图 2

639
00:28:40,080 --> 00:28:47,330
安排显然太慢了，是的，

640
00:28:51,209 --> 00:28:56,309
所以在这个图中设置

641
00:28:56,309 --> 00:28:58,929
你知道数据库未知 服务器

642
00:28:58,929 --> 00:29:02,469
每次调用 write 时都会侵蚀其 EBS

643
00:29:02,469 --> 00:29:05,379
磁盘，每次写入的副本都会

644
00:29:05,379 --> 00:29:08,349
跨越可用性区域，并且

645
00:29:08,349 --> 00:29:10,359
必须写入到这

646
00:29:10,359 --> 00:29:12,580
两个 EBS 服务器和 th  en

647
00:29:12,580 --> 00:29:15,269
确认，然后才

648
00:29:15,269 --> 00:29:18,009
似乎完成了对数据库的写入，所以我

649
00:29:18,009 --> 00:29:19,839
真的不得不等待整个秋天

650
00:29:19,839 --> 00:29:22,269
来更新副本以及将数据

651
00:29:22,269 --> 00:29:24,239
通过链接发送到另一个

652
00:29:24,239 --> 00:29:30,789
可用区，你知道 作为

653
00:29:30,789 --> 00:29:33,149
表一，它​​关注的是第一个

654
00:29:33,149 --> 00:29:37,979
性能表，

655
00:29:39,089 --> 00:29:42,820
为什么镜像我的

656
00:29:42,820 --> 00:29:45,579
续集线比 Aurora 线慢得多的

657
00:29:45,579 --> 00:29:47,889
原因基本上是它

658
00:29:47,889 --> 00:29:50,499
通过这些

659
00:29:50,499 --> 00:29:52,599
相对较慢的网络链接发送大量数据，这

660
00:29:52,599 --> 00:29:54,099
就是问题所在 那是

661
00:29:54,099 --> 00:29:55,929
他们真正要解决的性能问题，所以

662
00:29:55,929 --> 00:29:57,759
这对容错很有好处，因为

663
00:29:57,759 --> 00:29:59,079
现在我们有第二个副本和另一个

664
00:29:59,079 --> 00:30:02,049
可用区，但这

665
00:30:02,049 --> 00:30:05,579
对 Aurora 的性能来说是个坏消息，

666
00:30:05,579 --> 00:30:07,859
之后的下一步是 Aurora

667
00:30:07,859 --> 00:30:14,320
并在那里设置高级视图

668
00:30:14,320 --> 00:30:15,809
是我们仍然有一个数据库服务器，

669
00:30:15,809 --> 00:30:18,549
尽管现在它正在运行

670
00:30:18,549 --> 00:30:21,579
亚马逊提供的自定义软件，所以我可以

671
00:30:21,579 --> 00:30:23,979
从亚马逊租用一个 Aurora 服务器，但

672
00:30:23,979 --> 00:30:26,320
它是 不是 我没有在上面运行我的

673
00:30:26,320 --> 00:30:28,779
软件 我正在租用运行 Amazon

674
00:30:28,779 --> 00:30:32,259
Aurora 数据库软件的

675
00:30:32,259 --> 00:30:35,559
服务器 从他们那里租用 Aurora 数据库服务器，

676
00:30:35,559 --> 00:30:38,499
它只是一个实例，它位于

677
00:30:38,499 --> 00:30:44,679
某个可用区，并且有两个

678
00:30:44,679 --> 00:30:46,779
有趣的方式 它的

679
00:30:46,779 --> 00:30:52,269
设置首先是你

680
00:30:52,269 --> 00:30:54,690
知道它基本上用于 EBS 的数据

681
00:30:54,690 --> 00:30:59,640
现在涉及六个副本

682
00:30:59,640 --> 00:31:05,390
- 在三个可用区中的每一个中以

683
00:31:09,680 --> 00:31:12,180
实现超级容错，因此

684
00:31:12,180 --> 00:31:14,460
每次数据库复杂时我们都会讨论，

685
00:31:14,460 --> 00:31:15,930
但基本上是当数据库写入

686
00:31:15,930 --> 00:31:19,580
或 当数据库写入时读取

687
00:31:19,580 --> 00:31:22,710
我们不确定它是如何管理的，

688
00:31:22,710 --> 00:31:24,900
但它或多或少需要以

689
00:31:24,900 --> 00:31:27,300
一种方式发送写入，或者另一种写入

690
00:31:27,300 --> 00:31:31,280
必须发送到所有六个副本，这

691
00:31:31,280 --> 00:31:33,840
是制作的关键，所以这看起来像

692
00:31:33,840 --> 00:31:35,370
更多 副本天哪，你知道为什么它不

693
00:31:35,370 --> 00:31:37,590
慢为什么它不比

694
00:31:37,590 --> 00:31:38,970
之前只有四个

695
00:31:38,970 --> 00:31:41,190
副本的方案慢，答案

696
00:31:41,190 --> 00:31:43,110
是唯一的东西是

697
00:31:43,110 --> 00:31:44,850
通过网络写入的 rk 是日志

698
00:31:44,850 --> 00:31:47,190
记录，所以成功的关键在于

699
00:31:47,190 --> 00:31:50,010
 

700
00:31:50,010 --> 00:31:51,480
，在副本的意义上，通过这些链接的数据

701
00:31:51,480 --> 00:31:58,130
只是日志记录日志条目

702
00:31:58,130 --> 00:32:02,460
，正如您所看到的，您知道这里的日志条目

703
00:32:02,460 --> 00:32:04,200
，您至少知道并且 这是一个

704
00:32:04,200 --> 00:32:06,060
简单的例子，现在它并没有这么

705
00:32:06,060 --> 00:32:08,220
小，但它实际上并不多于

706
00:32:08,220 --> 00:32:10,350
 

707
00:32:10,350 --> 00:32:11,910
存储我们正在写入的数据的旧值和新值

708
00:32:11,910 --> 00:32:14,520
所需的几十个字节，

709
00:32:14,520 --> 00:32:16,250
因此日志条目往往相当 小

710
00:32:16,250 --> 00:32:20,250
而当你知道我们

711
00:32:20,250 --> 00:32:21,390
有一个数据库认为它正在

712
00:32:21,390 --> 00:32:23,100
写一个本地磁盘并且它正在更新

713
00:32:23,100 --> 00:32:24,900
它的数据页时，这些往往是

714
00:32:24,900 --> 00:32:26,940
巨大的，就像在论文中没有真正说的那样，

715
00:32:26,940 --> 00:32:28,170
我认为不会有 8 KB

716
00:32:28,170 --> 00:32:31,500
或更多 所以这里的设置是

717
00:32:31,500 --> 00:32:33,540
为每个事务发送

718
00:32:33,540 --> 00:32:36,570
多个 8 KB 页面到

719
00:32:36,570 --> 00:32:38,760
副本，而这个设置只是

720
00:32:38,760 --> 00:32:41,040
将这些小日志条目发送到更多

721
00:32:41,040 --> 00:32:43,770
副本，但日志条目

722
00:32:43,770 --> 00:32:46,380
比 8k 页面小得多

723
00:32:46,380 --> 00:32:51,200
净性能获胜 好吧，

724
00:32:51,200 --> 00:32:56,520
这就像他们的重要见解之一

725
00:32:56,520 --> 00:32:58,740
只是在日志条目中，当然

726
00:32:58,740 --> 00:33:00,480
，由此产生的后果是他们的存储

727
00:33:00,480 --> 00:33:01,950
系统现在不是很通用

728
00:33:01,950 --> 00:33:03,210
这是一个

729
00:33:03,210 --> 00:33:06,570
了解如何处理的存储系统 我的续集

730
00:33:06,570 --> 00:33:09,300
日志条目对，不只是您知道

731
00:33:09,300 --> 00:33:11,640
EBS 是一个非常通用的用途，只是

732
00:33:11,640 --> 00:33:13,320
模拟到磁盘您阅读它们对

733
00:33:13,320 --> 00:33:15,480
块

734
00:33:15,480 --> 00:33:17,159
除了块之外什么都不了解这是

735
00:33:17,159 --> 00:33:19,440
一个真正

736
00:33:19,440 --> 00:33:20,309
了解它位于数据库下方的存储系统，

737
00:33:20,309 --> 00:33:23,190
所以 他们所做的一件事

738
00:33:23,190 --> 00:33:25,080
是放弃通用存储

739
00:33:25,080 --> 00:33:28,320
并切换到一个非常特定于应用程序的

740
00:33:28,320 --> 00:33:31,519
存储系统

741
00:33:31,529 --> 00:33:34,289
，我还将

742
00:33:34,289 --> 00:33:36,529
更详细地介绍的另一件大事是他们不需要

743
00:33:36,529 --> 00:33:40,710
所有六个人都承认这些权利

744
00:33:40,710 --> 00:33:43,049
副本，以便数据库

745
00:33:43,049 --> 00:33:47,580
服务器继续，而不是数据库

746
00:33:47,580 --> 00:33:49,649
服务器可以继续只要一个仲裁

747
00:33:49,649 --> 00:33:51,659
，结果证明只要

748
00:33:51,659 --> 00:33:54,570
这些服务器中的任何四个重新 因此，如果

749
00:33:54,570 --> 00:33:57,350
其中一个可用区

750
00:33:57,350 --> 00:33:59,970
处于脱机状态，或者

751
00:33:59,970 --> 00:34:02,159
与它的网络连接速度很慢，或者甚至只是这些

752
00:34:02,159 --> 00:34:04,350
服务器恰好

753
00:34:04,350 --> 00:34:05,490
在我们

754
00:34:05,490 --> 00:34:08,790
尝试编写数据库服务器时执行其他操作时很慢，则

755
00:34:08,790 --> 00:34:12,270
基本上可以忽略这两个

756
00:34:12,270 --> 00:34:14,699
当服务器运行正确时，最慢或最死的两个服务器

757
00:34:14,699 --> 00:34:16,050
，所以它只需要

758
00:34:16,050 --> 00:34:17,849
六分之四的确认

759
00:34:17,849 --> 00:34:19,829
，然后它可以继续，所以这个

760
00:34:19,829 --> 00:34:25,379
仲裁方案是

761
00:34:25,379 --> 00:34:30,810
他们用来帮助​​他们在更多副本中获得更多副本的另一个大技巧

762
00:34:30,810 --> 00:34:33,359
可用区，但不会

763
00:34:33,359 --> 00:34:35,550
付出巨大的性能损失，因为

764
00:34:35,550 --> 00:34:36,839
他们永远不必等待所有这些，

765
00:34:36,839 --> 00:34:39,690
只是六个

766
00:34:39,690 --> 00:34:45,750
副本中最快的四个

767
00:34:45,750 --> 00:34:47,699
 

768
00:34:47,699 --> 00:34:49,679
 

769
00:34:49,679 --> 00:34:53,010
发送日志条目基本上是表

770
00:34:53,010 --> 00:34:54,569
一总结了结果，如果您

771
00:34:54,569 --> 00:34:56,849
通过从

772
00:34:56,849 --> 00:34:58,800
将大

773
00:34:58,800 --> 00:35:02,970
数据页面发送到此 Aurora 的四个地方的这种架构切换来查看表一

774
00:35:02,970 --> 00:35:04,800
chema 只将日志条目发送到

775
00:35:04,800 --> 00:35:08,579
六个副本，它们的性能比其他一些系统提高了惊人的 35 倍，

776
00:35:08,579 --> 00:35:11,670
 

777
00:35:11,670 --> 00:35:15,200
你在这里知道这个系统，

778
00:35:15,200 --> 00:35:17,490
但是通过玩这两个技巧和

779
00:35:17,490 --> 00:35:19,160
论文并不能很好地解释有

780
00:35:19,160 --> 00:35:21,300
多少性能是由于

781
00:35:21,300 --> 00:35:23,190
仲裁 多少是由于只是

782
00:35:23,190 --> 00:35:25,170
发送日志条目，但无论如何你

783
00:35:25,170 --> 00:35:27,250
把它切成 35

784
00:35:27,250 --> 00:35:31,330
倍改进性能是非常

785
00:35:31,330 --> 00:35:33,010
可观的，当然

786
00:35:33,010 --> 00:35:34,660
对他们的客户和他们

787
00:35:34,660 --> 00:35:37,660
来说非常有价值，这就像变革我相信

788
00:35:37,660 --> 00:35:44,040
对于亚马逊的许多客户来说都

789
00:35:44,040 --> 00:35:46,690
很好，所以 我想详细讨论的第一件事

790
00:35:46,690 --> 00:35:50,590
是他们的仲裁

791
00:35:50,590 --> 00:35:52,060
安排他们实际上所说的仲裁是

792
00:35:52,060 --> 00:35:55,180
什么所以首先仲裁是

793
00:35:55,180 --> 00:35:57,310
 

794
00:35:57,310 --> 00:35:59,290
关于这个容错存储的容错安排

795
00:35:59,290 --> 00:36:03,610
所以值得

796
00:36:03,610 --> 00:36:05,290
思考一下 他们的

797
00:36:05,290 --> 00:36:09,760
容错目标是这样的

798
00:36:09,760 --> 00:36:15,820
 

799
00:36:15,820 --> 00:36:18,970
 

800
00:36:18,970 --> 00:36:21,760
ility zone

801
00:36:21,760 --> 00:36:26,070
完全死了，所以他们会写信

802
00:36:26,070 --> 00:36:37,990
告诉你，即使他们希望

803
00:36:37,990 --> 00:36:40,780
能够读取，即使有一个死的

804
00:36:40,780 --> 00:36:43,600
可用区加上另一个死的

805
00:36:43,600 --> 00:36:46,930
服务器，原因是

806
00:36:46,930 --> 00:36:48,880
一个可用区可能会

807
00:36:48,880 --> 00:36:50,860
离线很长时间 一段时间，因为也许您

808
00:36:50,860 --> 00:36:52,780
知道遭受了洪水之类的袭击

809
00:36:52,780 --> 00:36:54,970
，而当它下降了

810
00:36:54,970 --> 00:36:56,560
几天或一周之类的时候，

811
00:36:56,560 --> 00:36:58,420
人们已经做好了洪水造成的损失准备，

812
00:36:58,420 --> 00:37:00,700
我们现在依赖于您

813
00:37:00,700 --> 00:37:01,660
知道服务器和其他 两个

814
00:37:01,660 --> 00:37:03,550
可用区 如果其中一个

815
00:37:03,550 --> 00:37:05,830
出现故障，我们仍然不希望它成为

816
00:37:05,830 --> 00:37:09,250
一场灾难，因此

817
00:37:09,250 --> 00:37:11,080
即使有一个可用区失效，他们也可以使用其中一个进行写入，

818
00:37:11,080 --> 00:37:13,090
而且他们

819
00:37:13,090 --> 00:37:16,750
希望能够使用其中一个进行读取 一个失效的

820
00:37:16,750 --> 00:37:19,540
可用区加上另一台失效的

821
00:37:19,540 --> 00:37:20,980
服务器，因此

822
00:37:20,980 --> 00:37:23,560
 

823
00:37:23,560 --> 00:37:26,500
即使有一个失效的

824
00:37:26,500 --> 00:37:28,510
可用区加上另一台服务器

825
00:37:28,510 --> 00:37:30,430
并且活动的可用区

826
00:37:30,430 --> 00:37:34,510
失效，他们仍希望能够读取您的信息并获得正确的数据，所以 你知道他们我们必须

827
00:37:34,510 --> 00:37:36,460
理所当然地认为他们

828
00:37:36,460 --> 00:37:38,680
知道他们知道自己的业务

829
00:37:38,680 --> 00:37:40,480
，这真的是

830
00:37:40,480 --> 00:37:43,130
你知道你想成为多么容错的最佳地点，

831
00:37:43,130 --> 00:37:46,580
 

832
00:37:46,580 --> 00:37:47,870
而且我已经 提到他们希望

833
00:37:47,870 --> 00:37:49,640
能够更高以摆脱

834
00:37:49,640 --> 00:37:55,550
暂时缓慢的副本我认为从

835
00:37:55,550 --> 00:37:58,940
很多来源很明显，例如，如果

836
00:37:58,940 --> 00:38:01,100
您读写 EBS，您

837
00:38:01,100 --> 00:38:03,290
不会始终获得始终如一的

838
00:38:03,290 --> 00:38:04,610
高性能，有时会出现一些小

839
00:38:04,610 --> 00:38:06,320
故障，因为 也许

840
00:38:06,320 --> 00:38:08,240
网络的某些部分超载，或者某事

841
00:38:08,240 --> 00:38:10,790
正在进行软件升级或其他任何事情，并且

842
00:38:10,790 --> 00:38:13,520
它暂时很慢，所以他们希望

843
00:38:13,520 --> 00:38:15,350
能够继续运行，尽管

844
00:38:15,350 --> 00:38:21,350
短暂的短暂缓慢或可能

845
00:38:21,350 --> 00:38:27,770
暂时不可用的存储服务器

846
00:38:27,770 --> 00:38:30,230
，最后一个要求是，如果有什么

847
00:38:30,230 --> 00:38:33,800
如果 存储服务器应该发生故障

848
00:38:33,800 --> 00:38:36,230
 

849
00:38:36,230 --> 00:38:39,020
在下一个存储服务器发生故障之前有点与时间赛跑

850
00:38:39,020 --> 00:38:42,920
总是如此，并不是统计数据

851
00:38:42,920 --> 00:38:44,450
不如 您可能希望，

852
00:38:44,450 --> 00:38:47,270
因为通常您购买基本上

853
00:38:47,270 --> 00:38:50,660
是因为服务器故障通常不是

854
00:38:50,660 --> 00:38:53,000
独立的，例如一台

855
00:38:53,000 --> 00:38:56,720
服务器停机的事实通常意味着

856
00:38:56,720 --> 00:38:58,340
 

857
00:38:58,340 --> 00:39:00,410
您的另一台服务器很快就会

858
00:39:00,410 --> 00:39:03,320
停机的可能性大大增加，因为它是相同的硬件可能

859
00:39:03,320 --> 00:39:05,540
是从 同一家公司

860
00:39:05,540 --> 00:39:07,520
一个接一个地从同一条生产线上下来

861
00:39:07,520 --> 00:39:09,650
，所以一个缺陷

862
00:39:09,650 --> 00:39:11,720
很可能会反映在一个

863
00:39:11,720 --> 00:39:14,570
缺陷和另一个缺陷上，所以人们总是很

864
00:39:14,570 --> 00:39:16,100
紧张，因为有一个失败的男孩

865
00:39:16,100 --> 00:39:17,330
很快就会出现第二次失败

866
00:39:17,330 --> 00:39:21,500
像这样的系统很好，

867
00:39:21,500 --> 00:39:24,470
结果在这些仲裁系统中，你

868
00:39:24,470 --> 00:39:26,030
知道你只能恢复它

869
00:39:26,030 --> 00:39:28,160
有点像筏子，只要

870
00:39:28,160 --> 00:39:31,460
没有太多的副本失败，你就可以恢复，所以

871
00:39:31,460 --> 00:39:35,270
他们真的需要快速我们

872
00:39:35,270 --> 00:39:37,130
复制它们 一台服务器

873
00:39:37,130 --> 00:39:38,870
似乎永久死机我们希望

874
00:39:38,870 --> 00:39:41,180
 

875
00:39:41,180 --> 00:39:43,160
能够从剩余的副本中尽快生成一个新的副本

876
00:39:43,160 --> 00:39:46,990
我的意思是快餐复制

877
00:39:48,039 --> 00:39:50,299
这些是

878
00:39:50,299 --> 00:39:56,089
窥视者列出的主要容错目标顺便说一下，这个

879
00:39:56,089 --> 00:39:57,859
讨论只是关于存储

880
00:39:57,859 --> 00:40:00,140
服务器，您知道它们的故障

881
00:40:00,140 --> 00:40:01,430
特征太兴奋了您知道

882
00:40:01,430 --> 00:40:03,589
故障如何恢复，这是一个

883
00:40:03,589 --> 00:40:05,390
完全独立的主题

884
00:40:05,390 --> 00:40:10,039
如果数据库服务器该怎么办 失败，Aurora

885
00:40:10,039 --> 00:40:17,079
有一套完全不同的机制来

886
00:40:17,079 --> 00:40:19,009
通知数据库服务器失败

887
00:40:19,009 --> 00:40:20,989
创建一个新实例在新实例上的新

888
00:40:20,989 --> 00:40:22,400
数据库服务器中运行，

889
00:40:22,400 --> 00:40:24,380
这很激烈，这不是我

890
00:40:24,380 --> 00:40:25,430
现在要谈论的，我们将谈论

891
00:40:25,430 --> 00:40:27,259
它 稍后现在它

892
00:40:27,259 --> 00:40:29,479
只是要构建一个存储系统，

893
00:40:29,479 --> 00:40:32,089
这就是存储系统容错的地方，

894
00:40:32,089 --> 00:40:36,589
好吧，所以他们使用这个

895
00:40:36,589 --> 00:40:43,940
称为仲裁的想法

896
00:40:43,940 --> 00:40:45,890
，现在我将描述

897
00:40:45,890 --> 00:40:49,039
一下经典的仲裁想法 这可以

898
00:40:49,039 --> 00:40:52,940
追溯到 70 年代后期，所以这是 quorum

899
00:40:52,940 --> 00:40:57,529
replicate quorum replication 我

900
00:40:57,529 --> 00:40:59,089
要向你描述这个或抽象的 quorum

901
00:40:59,089 --> 00:41:02,059
想法，他们使用我要解释的变体

902
00:41:02,059 --> 00:41:05,299
和

903
00:41:05,299 --> 00:41:07,339
quorum quorum 系统背后的想法是能够

904
00:41:07,339 --> 00:41:10,819
构建

905
00:41:10,819 --> 00:41:13,089
使用复制提供容错存储的存储系统，并

906
00:41:13,089 --> 00:41:15,229
保证即使某些

907
00:41:15,229 --> 00:41:18,109
副本失败，您的读取仍然会

908
00:41:18,109 --> 00:41:22,430
看到最新的写入，并且通常

909
00:41:22,430 --> 00:41:25,430
仲裁系统是一种简单的

910
00:41:25,430 --> 00:41:28,219
读写 系统放置 get 系统，

911
00:41:28,219 --> 00:41:31,009
它们通常不直接支持

912
00:41:31,009 --> 00:41:33,140
更复杂的操作，只是您可以

913
00:41:33,140 --> 00:41:34,849
读取您可以拥有可以读取

914
00:41:34,849 --> 00:41:36,349
对象的对象，或者您可以覆盖整个

915
00:41:36,349 --> 00:41:38,359
对象，因此

916
00:41:38,359 --> 00:41:48,259
如果您想写入或 你

917
00:41:48,259 --> 00:41:49,699
必须让你必须为了

918
00:41:49,699 --> 00:41:51,140
写你必须确保你的写

919
00:41:51,140 --> 00:41:53,930
被 W 确认，其中 W

920
00:41:53,930 --> 00:41:58,700
小于 n 个副本，所以 W

921
00:41:58,700 --> 00:42:02,360
正确，你必须将每个权利发送给

922
00:42:02,360 --> 00:42:04,520
这些 W 是副本，如果你想要

923
00:42:04,520 --> 00:42:07,550
要进行读取，您必须

924
00:42:07,550 --> 00:42:13,570
至少从我们的副本中获取输入读取信息

925
00:42:14,950 --> 00:42:20,240
，因此非常好的典型设置

926
00:42:20,240 --> 00:42:23,960
首先这里的关键是

927
00:42:23,960 --> 00:42:27,620
W 和 our 必须相对于 end s 进行设置

928
00:42:27,620 --> 00:42:31,070
o 您设法发送权利的 W 服务器的任何法定人数

929
00:42:31,070 --> 00:42:33,380
 

930
00:42:33,380 --> 00:42:36,260
必须与任何

931
00:42:36,260 --> 00:42:38,900
未来读者可能从中读取的我们服务器的任何法定人数重叠

932
00:42:38,900 --> 00:42:42,130
，因此这意味着

933
00:42:42,130 --> 00:42:50,030
我们的加号 W 必须大于 n，

934
00:42:50,030 --> 00:42:52,970
以便任何 W 服务器必须在

935
00:42:52,970 --> 00:42:58,930
至少一个服务器中与我们的任何服务器重叠

936
00:42:58,930 --> 00:43:01,370
，因此您可能有三个我们

937
00:43:01,370 --> 00:43:05,890
可以想象有三个服务器 s1 s2 s3

938
00:43:05,890 --> 00:43:08,060
他们每个人持有我说我们只有

939
00:43:08,060 --> 00:43:10,130
一个我们正在更新的对象我们可能会

940
00:43:10,130 --> 00:43:11,600
发送一个写入 我们希望将

941
00:43:11,600 --> 00:43:15,830
对象的值设置为 23，

942
00:43:15,830 --> 00:43:17,360
以便进行写入，我们需要将新

943
00:43:17,360 --> 00:43:22,520
值至少写入

944
00:43:22,520 --> 00:43:24,800
副本的 W 假设对于这个系统，

945
00:43:24,800 --> 00:43:29,300
R 和 W 都等于 2 和 n

946
00:43:29,300 --> 00:43:32,420
等于 3 这是进行写入的设置，我们

947
00:43:32,420 --> 00:43:35,180
需要将我们的新值放到仲裁

948
00:43:35,180 --> 00:43:38,030
服务器上的野兽上，所以也许

949
00:43:38,030 --> 00:43:40,760
我们可以对这两个有权限，所以

950
00:43:40,760 --> 00:43:43,280
他们现在都知道

951
00:43:43,280 --> 00:43:47,750
我们的数据对象的值 是 23 如果有人

952
00:43:47,750 --> 00:43:51,140
过来阅读或阅读它也

953
00:43:51,140 --> 00:43:53,150
需要 r  eader 至少检查

954
00:43:53,150 --> 00:43:55,700
服务器的读取仲裁，因此

955
00:43:55,700 --> 00:43:58,820
在此设置中也是 2，因此您知道

956
00:43:58,820 --> 00:44:00,650
仲裁可能包括

957
00:44:00,650 --> 00:44:02,510
没有看到正确的服务器，但它必须

958
00:44:02,510 --> 00:44:03,830
至少包括另一个服务器

959
00:44:03,830 --> 00:44:07,490
才能访问 这意味着任何未来的读取都

960
00:44:07,490 --> 00:44:09,500
必须咨询这台

961
00:44:09,500 --> 00:44:11,270
没有看到写入的服务器加上

962
00:44:11,270 --> 00:44:12,380
至少一个这样做的服务器，

963
00:44:12,380 --> 00:44:14,599
这是正确形式的要求，必须

964
00:44:14,599 --> 00:44:17,359
在至少一个服务器中重叠，因此任何

965
00:44:17,359 --> 00:44:20,509
读取都必须咨询看到任何写入的服务器

966
00:44:20,509 --> 00:44:31,519
以前现在

967
00:44:31,519 --> 00:44:34,430
这口井有什么很酷的实际上这里还有一个

968
00:44:34,430 --> 00:44:38,150
关键的缺失部分

969
00:44:38,150 --> 00:44:41,029
读者会取回我们的结果可能

970
00:44:41,029 --> 00:44:44,359
是不同的结果因为

971
00:44:44,359 --> 00:44:46,670
问题是读者如何知道

972
00:44:46,670 --> 00:44:48,680
它从

973
00:44:48,680 --> 00:44:51,049
我们的服务器返回了我们的哪些结果 在它的论坛中，

974
00:44:51,049 --> 00:44:54,789
实际上使用了正确的值的

975
00:44:55,029 --> 00:44:57,079
东西不起作用

976
00:44:57,079 --> 00:44:59,720
就像投票只是通过不同值的受欢迎程度来投票，

977
00:44:59,720 --> 00:45:01,670
结果

978
00:45:01,670 --> 00:45:03,619
证明它不起作用，因为我们只

979
00:45:03,619 --> 00:45:05,630
保证你 r reader

980
00:45:05,630 --> 00:45:07,400
最多在一台服务器中与 writer 重叠，因此这

981
00:45:07,400 --> 00:45:09,619
可能意味着正确的值

982
00:45:09,619 --> 00:45:11,420
仅由读者咨询的服务器之一表示，

983
00:45:11,420 --> 00:45:15,589
并且您知道

984
00:45:15,589 --> 00:45:17,509
在一个系统中，您

985
00:45:17,509 --> 00:45:19,819
知道您可能有六个副本 Reaper 可能是四个

986
00:45:19,819 --> 00:45:23,390
您可能会得到答案，其中只有

987
00:45:23,390 --> 00:45:26,779
一个是

988
00:45:26,779 --> 00:45:29,000
来自服务器的正确答案，您在其中

989
00:45:29,000 --> 00:45:31,519
与前一个权利重叠，因此

990
00:45:31,519 --> 00:45:33,079
您不能使用投票，而是这些

991
00:45:33,079 --> 00:45:35,750
仲裁系统需要版本号，因此

992
00:45:35,750 --> 00:45:38,509
每次都正确 你做对了，

993
00:45:38,509 --> 00:45:40,490
你需要伴随你的新值

994
00:45:40,490 --> 00:45:42,859
，你知道一个不断增加的版本

995
00:45:42,859 --> 00:45:45,680
号，然后阅读器从读取的仲裁中返回

996
00:45:45,680 --> 00:45:47,029
一堆不同的值

997
00:45:47,029 --> 00:45:48,619
，它只能使用它们

998
00:45:48,619 --> 00:45:51,319
我所说的最高版本号

999
00:45:51,319 --> 00:45:53,390
意味着这 21 在这里

1000
00:45:53,390 --> 00:45:57,789
你知道也许 s2 的旧值 20

1001
00:45:57,789 --> 00:45:59,869
每个都需要用

1002
00:45:59,869 --> 00:46:01,490
版本号标记所以也许这是版本

1003
00:46:01,490 --> 00:46:03,380
号 3 这也是版本

1004
00:46:03,380 --> 00:46:04,609
号 3 因为它来自

1005
00:46:04,609 --> 00:46:06,710
相同的原始权利，我们想象

1006
00:46:06,710 --> 00:46:08,480
这个没有看到

1007
00:46:08,480 --> 00:46:09,980
权利的服务器将有第二个版本

1008
00:46:09,980 --> 00:46:11,450
然后读者得到这两个

1009
00:46:11,450 --> 00:46:13,519
值这两个版本号修复

1010
00:46:13,519 --> 00:46:15,049
版本是最高的

1011
00:46:15,049 --> 00:46:18,019
版本号最高的值 在极光中，

1012
00:46:18,019 --> 00:46:23,480
这基本上是

1013
00:46:23,480 --> 00:46:26,529
关于极光的事

1014
00:46:28,570 --> 00:46:33,350
 

1015
00:46:33,350 --> 00:46:35,720
 

1016
00:46:35,720 --> 00:46:37,490
 

1017
00:46:37,490 --> 00:46:41,000
继续

1018
00:46:41,000 --> 00:46:45,200
尝试，直到服务器

1019
00:46:45,200 --> 00:46:49,370
重新启动或重新连接，所以

1020
00:46:49,370 --> 00:46:51,260
这比链复制更可取的原因

1021
00:46:51,260 --> 00:46:54,530
是它可以轻松

1022
00:46:54,530 --> 00:46:59,870
摆脱临时死机或断开连接

1023
00:46:59,870 --> 00:47:01,670
或速度缓慢的服务器，所以实际上它

1024
00:47:01,670 --> 00:47:02,900
的工作方式是，如果你 想读

1025
00:47:02,900 --> 00:47:04,790
或写，如果你想写，你会

1026
00:47:04,790 --> 00:47:06,020
说你新写的关于你

1027
00:47:06,020 --> 00:47:08,780
的新写的值加上

1028
00:47:08,780 --> 00:47:11,240
它的版本号到所有服务器

1029
00:47:11,240 --> 00:47:13,430
到所有 n 个服务器，但只有 w

1030
00:47:13,430 --> 00:47:17,090
等待他们中的 W 响应，类似地，

1031
00:47:17,090 --> 00:47:18,590
如果您想阅读，您将在

1032
00:47:18,590 --> 00:47:20,000
仲裁系统中将读取发送到

1033
00:47:20,000 --> 00:47:21,320
所有服务器，并且只

1034
00:47:21,320 --> 00:47:23,710
等待 R 的服务器

1035
00:47:23,710 --> 00:47:26,150
响应的仲裁，因为您只需要

1036
00:47:26,150 --> 00:47:29,720
等待是其中的 n 个，这

1037
00:47:29,720 --> 00:47:31,640
意味着您可以在最快

1038
00:47:31,640 --> 00:47:35,480
的响应或最快的 W 之后继续，并且

1039
00:47:35,480 --> 00:47:37,040
您不必等待慢速服务器

1040
00:47:37,040 --> 00:47:39,080
或已死的服务器并且没有

1041
00:47:39,080 --> 00:47:43,240
任何您知道的机器 忽略

1042
00:47:43,240 --> 00:47:45,800
缓慢或死机的服务器是完全

1043
00:47:45,800 --> 00:47:47,780
隐含的，这里什么都没有，

1044
00:47:47,780 --> 00:47:49,610
哦，我们必须

1045
00:47:49,610 --> 00:47:51,860
决定哪些服务器启动或关闭，或者

1046
00:47:51,860 --> 00:47:54,310
像领导者一样，或者只要法定人数可用，它就会自动进行任何事情，

1047
00:47:54,310 --> 00:47:57,590
 

1048
00:47:57,590 --> 00:48:02,480
所以我们得到

1049
00:48:02,480 --> 00:48:04,130
对死机或慢速服务器的处理非常顺利

1050
00:48:04,130 --> 00:48:07,280
，此外这里没有太多的

1051
00:48:07,280 --> 00:48:09,050
回旋余地，实际上

1052
00:48:09,050 --> 00:48:11,300
即使在这种简单的情况下，您也可以

1053
00:48:11,300 --> 00:48:14,270
调整 R 和 W 以使读取有

1054
00:48:14,270 --> 00:48:17,570
利于读取或写入，因此我们

1055
00:48:17,570 --> 00:48:19,280
可以在这里执行 lly 说，正确的

1056
00:48:19,280 --> 00:48:21,560
论坛是三个，每次写入都必须到

1057
00:48:21,560 --> 00:48:23,240
所有三个服务器，在这种情况下，

1058
00:48:23,240 --> 00:48:26,690
可能需要读取仲裁，所以如果

1059
00:48:26,690 --> 00:48:28,610
你想通过这种设置获得偏好的读取，

1060
00:48:28,610 --> 00:48:31,610
你可以读取等于一个

1061
00:48:31,610 --> 00:48:33,860
写入等于三个内存

1062
00:48:33,860 --> 00:48:35,480
速度要快得多，他们只需要等待一台

1063
00:48:35,480 --> 00:48:37,070
服务器，然后返回写入

1064
00:48:37,070 --> 00:48:38,840
速度很慢，如果您想支持正确，

1065
00:48:38,840 --> 00:48:40,670
您可以说哦，任何读者都

1066
00:48:40,670 --> 00:48:42,290
必须来自所有人，但作家

1067
00:48:42,290 --> 00:48:45,380
只需要写一个，所以我的意思是 只有一台

1068
00:48:45,380 --> 00:48:48,400
服务器可能具有最新值，但

1069
00:48:48,400 --> 00:48:53,990
读者必须咨询所有三个服务器，但

1070
00:48:53,990 --> 00:48:55,190
他们保证他们的三个服务器会

1071
00:48:55,190 --> 00:48:57,380
与此重叠，当然这些

1072
00:48:57,380 --> 00:49:00,380
特定值使写入不能

1073
00:49:00,380 --> 00:49:02,660
容错，这里读取不能

1074
00:49:02,660 --> 00:49:04,760
容错，因为所有服务器都

1075
00:49:04,760 --> 00:49:06,410
必须是 因此，

1076
00:49:06,410 --> 00:49:08,150
您可能不想在现实生活中这样做，

1077
00:49:08,150 --> 00:49:10,460
因为 Knowle Rohrer 会使用

1078
00:49:10,460 --> 00:49:13,310
大量服务器和

1079
00:49:13,310 --> 00:49:15,590
中间数量的 vinum right

1080
00:49:15,590 --> 00:49:23,030
corns Aurora 来实现 它的

1081
00:49:23,030 --> 00:49:26,990
目标是能够用

1082
00:49:26,990 --> 00:49:30,680
一个债务可用区写入并用

1083
00:49:30,680 --> 00:49:32,510
一个死可用区加上

1084
00:49:32,510 --> 00:49:35,030
另一台服务器读取它

1085
00:49:35,030 --> 00:49:45,200
使用 N 等于 6 w 等于 4 和 R 等于

1086
00:49:45,200 --> 00:49:48,140
3 的仲裁系统，因此 W 等于 4 意味着它可以做到

1087
00:49:48,140 --> 00:49:51,260
 

1088
00:49:51,260 --> 00:49:53,060
如果无法很好地联系到该可用区，则使用一个死可用区进行写入，

1089
00:49:53,060 --> 00:49:54,770
其他四台

1090
00:49:54,770 --> 00:49:58,700
服务器足以完成

1091
00:49:58,700 --> 00:50:01,550
对 3 所以 4 加上周所以 7 的改革，因此它们

1092
00:50:01,550 --> 00:50:04,190
绝对保证重叠 3 的读取

1093
00:50:04,190 --> 00:50:05,510
仲裁意味着即使 一个

1094
00:50:05,510 --> 00:50:07,640
可用性是区域已死加上另外一

1095
00:50:07,640 --> 00:50:09,560
台服务器剩余的三台服务器

1096
00:50:09,560 --> 00:50:12,080
现在足以提供读取在这种

1097
00:50:12,080 --> 00:50:15,200
情况下我们现在三台服务器已

1098
00:50:15,200 --> 00:50:17,600
关闭系统可以进行读取并且您知道

1099
00:50:17,600 --> 00:50:20,450
可以重建限制当前

1100
00:50:20,450 --> 00:50:21,980
状态 数据库，但

1101
00:50:21,980 --> 00:50:24,890
如果没有进一步的工作，它就无法进行写入，所以如果

1102
00:50:24,890 --> 00:50:28,780
他们处于那里有

1103
00:50:28,840 --> 00:50:31,880
三台死机服务器的情况，他们有

1104
00:50:31,880 --> 00:50:33,560
足够的法定人数来

1105
00:50:33,560 --> 00:50:35,960
读取数据并重建更多的

1106
00:50:35,960 --> 00:50:38,870
副本，但不会 直到他们创建了更多的

1107
00:50:38,870 --> 00:50:41,720
副本来基本上

1108
00:50:41,720 --> 00:50:45,670
替换这些无法作为权限的死副本，

1109
00:50:47,790 --> 00:50:50,670
以及我之前解释的仲裁系统

1110
00:50:50,670 --> 00:50:52,980
允许他们顺利

1111
00:50:52,980 --> 00:51:02,690
度过这些短暂的慢速副本

1112
00:51:02,690 --> 00:51:07,200
，就像之前解释的那样

1113
00:51:07,200 --> 00:51:09,839
，权限是什么 Aurora 并没有

1114
00:51:09,839 --> 00:51:12,890
像在一种经典的

1115
00:51:12,890 --> 00:51:16,950
仲裁系统中那样真正过度写入对象 Aurora 实际上它的

1116
00:51:16,950 --> 00:51:20,010
权利从不覆盖任何东西它的

1117
00:51:20,010 --> 00:51:22,680
权利只是将日志条目附加到

1118
00:51:22,680 --> 00:51:23,579
当前法律

1119
00:51:23,579 --> 00:51:25,920
所以它使用仲裁的方式

1120
00:51:25,920 --> 00:51:27,690
基本上是在数据库发送时说得好

1121
00:51:27,690 --> 00:51:29,400
取出我们的新日志记录，因为

1122
00:51:29,400 --> 00:51:31,770
它正在执行一些事务，它

1123
00:51:31,770 --> 00:51:33,780
需要确保该日志记录

1124
00:51:33,780 --> 00:51:38,280
存在于其存储服务器的至少四个存储中，

1125
00:51:38,280 --> 00:51:40,829
然后才允许

1126
00:51:40,829 --> 00:51:42,150
继续执行事务，

1127
00:51:42,150 --> 00:51:43,799
所以这确实

1128
00:51:43,799 --> 00:51:46,170
是它的另一个含义 Wars right porins 是

1129
00:51:46,170 --> 00:51:49,020
每个新的日志记录都必须附加

1130
00:51:49,020 --> 00:51:50,609
到存储中，至少对于

1131
00:51:50,609 --> 00:51:52,589
副本来说，在写入可以被

1132
00:51:52,589 --> 00:52:01,500
认为已经完成之前 ed 并且

1133
00:52:01,500 --> 00:52:03,900
当 Aurora

1134
00:52:03,900 --> 00:52:05,819
在它可以回复

1135
00:52:05,819 --> 00:52:07,530
客户端之前到达事务结束时，直到客户端告诉客户端

1136
00:52:07,530 --> 00:52:08,790
您知道您的事务已

1137
00:52:08,790 --> 00:52:10,849
提交并完成并且持久

1138
00:52:10,849 --> 00:52:14,130
Aurora 必须

1139
00:52:14,130 --> 00:52:16,319
等待每个写入仲裁的确认 组成该事务的日志

1140
00:52:16,319 --> 00:52:18,510
记录

1141
00:52:18,510 --> 00:52:24,599
，实际上是因为如果

1142
00:52:24,599 --> 00:52:25,980
在恢复过程中发生崩溃，如果

1143
00:52:25,980 --> 00:52:30,260
 

1144
00:52:30,260 --> 00:52:33,809
之前的事务没有

1145
00:52:33,809 --> 00:52:36,690
在实践中也没有恢复，则不允许恢复一个事务 Aurora 在

1146
00:52:36,690 --> 00:52:38,250
Aurora 可以确认之前已经 一个事务，它

1147
00:52:38,250 --> 00:52:42,690
必须等待存储服务器的写入仲裁

1148
00:52:42,690 --> 00:52:44,369
来响应所有

1149
00:52:44,369 --> 00:52:46,589
先前提交的事务和

1150
00:52:46,589 --> 00:52:48,750
感兴趣的事务，然后可以

1151
00:52:48,750 --> 00:52:51,799
响应客户端，

1152
00:52:54,740 --> 00:52:57,440
所以这些存储服务器正在

1153
00:52:57,440 --> 00:52:59,990
获取传入的日志记录

1154
00:52:59,990 --> 00:53:02,869
，这就是他们的权限

1155
00:53:02,869 --> 00:53:04,220
那么他们实际上做了什么你知道

1156
00:53:04,220 --> 00:53:06,410
他们没有从数据库服务器获取新的数据页

1157
00:53:06,410 --> 00:53:07,609
他们只是

1158
00:53:07,609 --> 00:53:10,700
获取刚刚描述的日志记录

1159
00:53:10,700 --> 00:53:16,010
对数据页的更改，因此在内部

1160
00:53:16,010 --> 00:53:22,369
它具有这些存储服务器中的一个，它

1161
00:53:22,369 --> 00:53:25,190
 

1162
00:53:25,190 --> 00:53:30,680
 

1163
00:53:30,680 --> 00:53:34,190
在数据库数据页演变的某个时刻具有所有数据页的所有数据的副本，因此

1164
00:53:34,190 --> 00:53:39,380
它可能在其磁盘上的缓存中具有

1165
00:53:39,380 --> 00:53:41,359
一大堆这些你知道的页面 第

1166
00:53:41,359 --> 00:53:47,450
1 页 第 2 页等等 当一个新的写入

1167
00:53:47,450 --> 00:53:52,820
进入存储服务器时，将赢得一个新的

1168
00:53:52,820 --> 00:53:54,290
日志记录 在一个新的写入到达时

1169
00:53:54,290 --> 00:53:56,599
，它只携带一个日志记录

1170
00:53:56,599 --> 00:53:58,400
某天必须发生的事情，但不正确

1171
00:53:58,400 --> 00:54:00,560
远离的是，该日志中的更改

1172
00:54:00,560 --> 00:54:02,780
记录了此处的新值必须

1173
00:54:02,780 --> 00:54:05,480
应用于相关页面，但我们

1174
00:54:05,480 --> 00:54:06,650
不需要在它的源头上不必

1175
00:54:06,650 --> 00:54:09,109
这样做，直到有人询问

1176
00:54:09,109 --> 00:54:11,240
直到数据库服务器或恢复

1177
00:54:11,240 --> 00:54:13,520
软件 要求立即查看该页面

1178
00:54:13,520 --> 00:54:15,440
新日志记录发生的情况

1179
00:54:15,440 --> 00:54:17,510
是日志记录只是

1180
00:54:17,510 --> 00:54:20,210
附加到影响每个页面的日志记录列表中，

1181
00:54:20,210 --> 00:54:23,180
因此对于

1182
00:54:23,180 --> 00:54:26,510
存储服务器存储的每个页面，如果它

1183
00:54:26,510 --> 00:54:29,270
最近被日志记录修改

1184
00:54:29,270 --> 00:54:31,310
在 ransaction 存储服务器

1185
00:54:31,310 --> 00:54:34,099
实际存储的是页面的旧版本

1186
00:54:34,099 --> 00:54:37,460
加上自上次更新

1187
00:54:37,460 --> 00:54:40,609
该页面以来从数据库服务器趋势中传入的日志记录序列的字符串，

1188
00:54:40,609 --> 00:54:42,740
 

1189
00:54:42,740 --> 00:54:45,500
因此如果

1190
00:54:45,500 --> 00:54:47,060
没有其他任何事情发生，则存储 服务器

1191
00:54:47,060 --> 00:54:49,880
只存储这些旧页面和

1192
00:54:49,880 --> 00:54:53,570
日志记录列表，如果数据库服务器

1193
00:54:53,570 --> 00:54:56,119
稍后知道从其

1194
00:54:56,119 --> 00:54:58,310
缓存中修复页面，然后需要再次读取该页面

1195
00:54:58,310 --> 00:55:00,440
以进行未来事务，它将

1196
00:55:00,440 --> 00:55:03,140
向其中一个存储服务器发送读取请求

1197
00:55:03,140 --> 00:55:04,430
然后说看你知道我

1198
00:55:04,430 --> 00:55:06,140
需要一个副本我需要一个更新的副本

1199
00:55:06,140 --> 00:55:06,789
一页

1200
00:55:06,789 --> 00:55:09,099
然后存储服务器

1201
00:55:09,099 --> 00:55:12,819
会将这些日志记录应用到你知道的页面上

1202
00:55:12,819 --> 00:55:15,849
执行这些隐含的新数据写入

1203
00:55:15,849 --> 00:55:18,039
 

1204
00:55:18,039 --> 00:55:19,390
日志中描述 记录，然后将

1205
00:55:19,390 --> 00:55:22,239
更新的页面发送回数据库服务器

1206
00:55:22,239 --> 00:55:27,999
，然后大概就像一个种族主义者

1207
00:55:27,999 --> 00:55:29,829
列表一样，只存储新更新的

1208
00:55:29,829 --> 00:55:35,549
页面，尽管它不是那么简单，

1209
00:55:35,759 --> 00:55:37,949
所以存储服务器 j 我们

1210
00:55:37,949 --> 00:55:41,289
存储这些日志记录字符串加上

1211
00:55:41,289 --> 00:55:53,380
旧的日志页面版本现在

1212
00:55:53,380 --> 00:55:54,819
我提到的数据库服务器有时需要

1213
00:55:54,819 --> 00:55:57,309
读取页面所以顺便观察一件事

1214
00:55:57,309 --> 00:55:58,660
是数据库服务器正在

1215
00:55:58,660 --> 00:56:00,969
写入日志记录但它正在读取

1216
00:56:00,969 --> 00:56:03,489
数据页面所以也有不同 我的

1217
00:56:03,489 --> 00:56:05,619
corns poram系统从某种意义上

1218
00:56:05,619 --> 00:56:07,119
说，正在读取和写入的东西

1219
00:56:07,119 --> 00:56:09,099
是完全不同的，此外

1220
00:56:09,099 --> 00:56:11,890
事实证明，在普通操作中

1221
00:56:11,890 --> 00:56:16,839
，数据库服务器知道

1222
00:56:16,839 --> 00:56:20,469
不必发送仲裁读取，因为

1223
00:56:20,469 --> 00:56:23,739
数据库服务器会跟踪每个

1224
00:56:23,739 --> 00:56:27,309
的存储服务器 实际接收到

1225
00:56:27,309 --> 00:56:29,829
存储服务器的日志前缀的多少，

1226
00:56:29,829 --> 00:56:32,169
因此

1227
00:56:32,169 --> 00:56:34,329
数据库服务器正在跟踪

1228
00:56:34,329 --> 00:56:36,099
这六个数字，所以首先所有日志

1229
00:56:36,099 --> 00:56:37,929
条目的编号只有

1230
00:56:37,929 --> 00:56:40,419
数据库服务器发送的一二三四五

1231
00:56:40,419 --> 00:56:42,669
所有存储服务器的新日志条目

1232
00:56:42,669 --> 00:56:44,229
接收它们的存储服务器

1233
00:56:44,229 --> 00:56:45,909
响应说哦，是的，我收到了日志

1234
00:56:45,909 --> 00:56:48,579
条目 79，此外，您知道我

1235
00:56:48,579 --> 00:56:51,279
有 在 79 之前的每个日志条目，

1236
00:56:51,279 --> 00:56:52,779
数据库服务器也会跟踪这些

1237
00:56:52,779 --> 00:56:56,429
数字，每个服务器已经获得了多远，或者当数据库服务器需要读取时，每个服务器已经获得

1238
00:56:56,429 --> 00:56:59,429
的最高类型的连续

1239
00:56:59,429 --> 00:57:02,349
日志条目号是

1240
00:57:02,349 --> 00:57:04,719
 

1241
00:57:04,719 --> 00:57:06,400
什么 它

1242
00:57:06,400 --> 00:57:09,880
只是选择一个最新的存储服务器并将它想要

1243
00:57:09,880 --> 00:57:12,880
的页面的读取请求发送

1244
00:57:12,880 --> 00:57:14,559
到该存储

1245
00:57:14,559 --> 00:57:18,549
服务器，因此数据库服务器确实

1246
00:57:18,549 --> 00:57:19,809
必须执行仲裁写入，但它

1247
00:57:19,809 --> 00:57:20,590
 

1248
00:57:20,590 --> 00:57:22,120
通常不需要执行仲裁

1249
00:57:22,120 --> 00:57:23,980
读取并且知道 这些存储

1250
00:57:23,980 --> 00:57:25,120
服务器中的哪一个是最新的并且只是

1251
00:57:25,120 --> 00:57:27,250
从其中一个读取，所以我保留你的原因

1252
00:57:27,250 --> 00:57:30,430
比他们在一个只读取

1253
00:57:30,430 --> 00:57:32,320
一个页面的副本并且不必

1254
00:57:32,320 --> 00:57:36,360
经历仲裁读取的费用

1255
00:57:36,450 --> 00:57:39,580
现在它有时确实使用仲裁读取

1256
00:57:39,580 --> 00:57:41,860
事实证明，在崩溃恢复期间，

1257
00:57:41,860 --> 00:57:44,170
您知道数据库服务器崩溃恢复期间是否崩溃

1258
00:57:44,170 --> 00:57:46,810
，因此

1259
00:57:46,810 --> 00:57:49,360
这与存储服务的崩溃恢复不同，

1260
00:57:49,360 --> 00:57:50,800
如果数据库

1261
00:57:50,800 --> 00:57:53,380
服务器 呃，先生，我自己崩溃了，

1262
00:57:53,380 --> 00:57:55,840
因为它在某个硬件上的 ec2 实例中运行

1263
00:57:55,840 --> 00:57:57,490
某些真正

1264
00:57:57,490 --> 00:57:58,570
的硬件可能是该

1265
00:57:58,570 --> 00:58:01,210
硬件发生故障 数据库

1266
00:58:01,210 --> 00:58:02,950
服务器崩溃 亚马逊的一些监控

1267
00:58:02,950 --> 00:58:04,510
基础设施说哦，

1268
00:58:04,510 --> 00:58:06,370
等一下，你 知道数据库

1269
00:58:06,370 --> 00:58:08,170
Aurora 数据库服务器为客户运行过度

1270
00:58:08,170 --> 00:58:12,900
或刚刚崩溃，

1271
00:58:12,900 --> 00:58:15,580
亚马逊将自动启动一个新的

1272
00:58:15,580 --> 00:58:18,010
ec2 实例 启动数据库

1273
00:58:18,010 --> 00:58:20,770
软件和该 ec2 实例并

1274
00:58:20,770 --> 00:58:23,290
告诉它看起来您的数据位于

1275
00:58:23,290 --> 00:58:26,410
这个特定的卷上 一组

1276
00:58:26,410 --> 00:58:29,340
存储系统请清理

1277
00:58:29,340 --> 00:58:32,080
 

1278
00:58:32,080 --> 00:58:34,840
存储在这些存储服务器中的日志中明显的任何部分执行的事务

1279
00:58:34,840 --> 00:58:38,950
并继续，所以我们必须这样

1280
00:58:38,950 --> 00:58:44,460
做，这就是 Aurora

1281
00:58:44,460 --> 00:58:48,550
对杂草使用仲裁逻辑的时候，因为这个

1282
00:58:48,550 --> 00:58:52,330
数据库服务器是旧

1283
00:58:52,330 --> 00:58:54,160
的 数据库服务器崩溃了，

1284
00:58:54,160 --> 00:58:56,380
几乎可以肯定是在

1285
00:58:56,380 --> 00:58:59,230
执行一组事务的过程中，

1286
00:58:59,230 --> 00:59:00,520
所以游戏状态

1287
00:59:00,520 --> 00:59:01,990
崩溃的时间很好，它完成了一些

1288
00:59:01,990 --> 00:59:03,550
事务并提交了它们，

1289
00:59:03,550 --> 00:59:06,370
它们的日志条目在仲裁加上

1290
00:59:06,370 --> 00:59:09,580
它正在执行一些

1291
00:59:09,580 --> 00:59:12,160
其他事务集，这些事务也可能

1292
00:59:12,160 --> 00:59:14,830
在仲裁上有日志条目，但是

1293
00:59:14,830 --> 00:59:16,720
因为数据库服务器崩溃了

1294
00:59:16,720 --> 00:59:18,340
在这些交易的中途，它们

1295
00:59:18,340 --> 00:59:23,200
永远无法完成，对于

1296
00:59:23,200 --> 00:59:24,940
那些尚未完成的交易，

1297
00:59:24,940 --> 00:59:27,640
您可能知道我们可能

1298
00:59:27,640 --> 00:59:30,880
会遇到这样一种情况，您知道可能

1299
00:59:30,880 --> 00:59:33,310
日志条目此服务器已登录 300

1300
00:59:33,310 --> 00:59:33,790
 

1301
00:59:33,790 --> 00:59:36,940
并且萨里已登录 302

1302
00:59:36,940 --> 00:59:41,320
并且有 104 个地方，但你不

1303
00:59:41,320 --> 00:59:42,730
知道，因为我在崩溃之前尚未提交的

1304
00:59:42,730 --> 00:59:44,470
事务让我

1305
00:59:44,470 --> 00:59:48,670
知道服务器获得了日志条目 103 的副本，

1306
00:59:48,670 --> 00:59:52,270
所以在崩溃之后并记住新的

1307
00:59:52,270 --> 00:59:54,610
数据库服务正在恢复它确实进行

1308
00:59:54,610 --> 00:59:56,590
仲裁读取以基本上找到

1309
00:59:56,590 --> 00:59:59,470
在日志中指向存储服务中某处存在的每个先前日志条目的最高日志编号，

1310
00:59:59,470 --> 01:00:02,530
 

1311
01:00:02,530 --> 01:00:04,660
因此

1312
01:00:04,660 --> 01:00:07,390
基本上它会发现第一个缺少

1313
01:00:07,390 --> 01:00:08,980
第一个丢失的日志条目的编号

1314
01:00:08,980 --> 01:00:12,430
是 103，并且说得很好，所以我们

1315
01:00:12,430 --> 01:00:14,470
丢失了一个日志条目，在此之后我们无法对日志做任何事情

1316
01:00:14,470 --> 01:00:16,540
，因为

1317
01:00:16,540 --> 01:00:20,440
我们就像错过了更新，所以

1318
01:00:20,440 --> 01:00:21,850
数据库服务器会执行这些仲裁读取

1319
01:00:21,850 --> 01:00:23,110
它发现 103 是

1320
01:00:23,110 --> 01:00:27,490
MIT 的第一个条目，我

1321
01:00:27,490 --> 01:00:28,810
不知道我查看了我的法定人数，

1322
01:00:28,810 --> 01:00:31,120
我可以达到的服务器和 103 不

1323
01:00:31,120 --> 01:00:32,890
存在，并且数据库服务器

1324
01:00:32,890 --> 01:00:34,300
将向所有服务器发送一条消息说

1325
01:00:34,300 --> 01:00:37,330
请看 只需丢弃

1326
01:00:37,330 --> 01:00:39,640
从 103 开始​​的每个日志条目，这些贻贝

1327
01:00:39,640 --> 01:00:43,030
不一定包括来自已

1328
01:00:43,030 --> 01:00:45,160
提交事务的日志条目，因为我们知道

1329
01:00:45,160 --> 01:00:46,870
事务在

1330
01:00:46,870 --> 01:00:49,390
其所有条目都在右角之前无法提交，因此我们

1331
01:00:49,390 --> 01:00:50,950
可以保证看到它们，所以我们

1332
01:00:50,950 --> 01:00:53,110
当然只丢弃来自

1333
01:00:53,110 --> 01:00:58,210
未提交事务的日志条目，所以

1334
01:00:58,210 --> 01:00:59,440
我们

1335
01:00:59,440 --> 01:01:03,190
在登录 302 处切断日志，

1336
01:01:03,190 --> 01:01:04,930
我们现在保留的这些

1337
01:01:04,930 --> 01:01:07,300
日志条目实际上可能包括来自事务的未提交事务的日志条目

1338
01:01:07,300 --> 01:01:08,860
 

1339
01:01:08,860 --> 01:01:10,720
因崩溃而中断的 ns 并且

1340
01:01:10,720 --> 01:01:12,070
数据库服务器实际上必须

1341
01:01:12,070 --> 01:01:14,110
通过查看希望您

1342
01:01:14,110 --> 01:01:16,480
知道某个事务的方式来检测那些您可以检测到的事务，它

1343
01:01:16,480 --> 01:01:18,640
在日志中具有更新条目但没有

1344
01:01:18,640 --> 01:01:20,500
提交记录，数据库服务器将

1345
01:01:20,500 --> 01:01:22,810
找到这些事务的完整集合 未完成的

1346
01:01:22,810 --> 01:01:25,480
事务并基本上发出

1347
01:01:25,480 --> 01:01:28,330
撤消操作

1348
01:01:28,330 --> 01:01:32,730
 

1349
01:01:32,730 --> 01:01:35,680
 

1350
01:01:35,680 --> 01:01:38,280
 

1351
01:01:38,280 --> 01:01:41,710
 

1352
01:01:41,710 --> 01:01:44,690
 

1353
01:01:44,690 --> 01:01:46,849
 

1354
01:01:46,849 --> 01:01:49,760
崩溃后的恢复可以从部分

1355
01:01:49,760 --> 01:02:00,400
完成的事务中恢复，好吧，

1356
01:02:00,400 --> 01:02:04,000
我想谈谈的是

1357
01:02:04,000 --> 01:02:09,020
Aurora 如何处理大型数据库

1358
01:02:09,020 --> 01:02:13,099
到目前为止，我已经解释了存储设置

1359
01:02:13,099 --> 01:02:17,020
，就好像数据库只有这六个

1360
01:02:17,020 --> 01:02:20,359
它的存储的副本，如果这就是它的

1361
01:02:20,359 --> 01:02:22,099
全部内容，那么它基本上是一个数据库

1362
01:02:22,099 --> 01:02:23,900
，你不可能知道其中的每一个只是

1363
01:02:23,900 --> 01:02:25,970
一台带有一两个磁盘或

1364
01:02:25,970 --> 01:02:28,609
其他东西的计算机 附加到它，如果这

1365
01:02:28,609 --> 01:02:31,010
是完整的情况，那么我们

1366
01:02:31,010 --> 01:02:32,329
不能有一个

1367
01:02:32,329 --> 01:02:34,400
比你

1368
01:02:34,400 --> 01:02:36,230
可以放在一台机器上

1369
01:02:36,230 --> 01:02:37,010
的存储量更大的数据库事实上我们有六台机器

1370
01:02:37,010 --> 01:02:39,319
并没有给我们六倍 尽可能多的可用

1371
01:02:39,319 --> 01:02:41,420
存储空间，因为我

1372
01:02:41,420 --> 01:02:43,220
一次又一次地存储相同旧数据的副本

1373
01:02:43,220 --> 01:02:46,700
，你知道，所以我想使用

1374
01:02:46,700 --> 01:02:48,319
固态驱动器或其他东西，我们可以

1375
01:02:48,319 --> 01:02:50,930
让你知道单台机器上的 TB 存储空间，

1376
01:02:50,930 --> 01:02:53,960
但我们可以 不要让您知道

1377
01:02:53,960 --> 01:02:55,460
单台机器上的数百 TB 数据，

1378
01:02:55,460 --> 01:02:59,510
因此为了支持

1379
01:02:59,510 --> 01:03:02,000
需要超过 10 TB 数据且

1380
01:03:02,000 --> 01:03:06,710
需要拥有庞大数据库的客户，亚马逊

1381
01:03:06,710 --> 01:03:09,079
很高兴亚马逊会将

1382
01:03:09,079 --> 01:03:12,970
数据库数据拆分为多组六个

1383
01:03:12,970 --> 01:03:19,180
副本，等等 一种

1384
01:03:19,180 --> 01:03:21,290
分片单位

1385
01:03:21,290 --> 01:03:23,960
我认为拆分数据的单位是 10 GB，因此

1386
01:03:23,960 --> 01:03:25,910
需要 20 GB 数据的数据库

1387
01:03:25,910 --> 01:03:28,400
将使用两个保护组

1388
01:03:28,400 --> 01:03:32,060
这些 PG 东西到它的数据，你知道它

1389
01:03:32,060 --> 01:03:35,569
坐在一半上，它会坐在六个上

1390
01:03:35,569 --> 01:03:41,240
保护第一组的服务器，然后

1391
01:03:41,240 --> 01:03:44,810
它们将是另外六台服务器，您

1392
01:03:44,810 --> 01:03:46,640
可能知道一组不同的六台存储

1393
01:03:46,640 --> 01:03:48,470
服务器，因为亚马逊正在运行，并且

1394
01:03:48,470 --> 01:03:49,819
就像一个庞大的存储

1395
01:03:49,819 --> 01:03:51,770
服务器舰队，由其所有 Aurora 客户共同使用，

1396
01:03:51,770 --> 01:03:54,740
第二个 10

1397
01:03:54,740 --> 01:03:57,680
GB 在数据库中 20 GB

1398
01:03:57,680 --> 01:03:58,250
的数据

1399
01:03:58,250 --> 01:04:02,740
我们将被复制到另一组

1400
01:04:02,740 --> 01:04:05,180
你知道通常不同 我会你

1401
01:04:05,180 --> 01:04:06,470
知道这些之间可能有重叠，

1402
01:04:06,470 --> 01:04:08,720
但通常只是一组不同

1403
01:04:08,720 --> 01:04:11,210
的六台服务器，所以现在我们

1404
01:04:11,210 --> 01:04:15,740
每天完成 20 GB 并且

1405
01:04:15,740 --> 01:04:18,890
随着数据库变大，我们有更多这样的数据，其中一个

1406
01:04:18,890 --> 01:04:21,050
有趣的后果是，虽然

1407
01:04:21,050 --> 01:04:25,670
很明显您可以获取数据

1408
01:04:25,670 --> 01:04:28,910
页面并将它们拆分到多个

1409
01:04:28,910 --> 01:04:30,830
独立的保护组中，但也许

1410
01:04:30,830 --> 01:04:32,450
您知道

1411
01:04:32,450 --> 01:04:35,390
b-tree 中的奇数数据页面 继续 PG 一个，偶数

1412
01:04:35,390 --> 01:04:38,060
页继续 PG - 很好，你可以

1413
01:04:38,060 --> 01:04:40,640
分片分割数据页面，这不是

1414
01:04:40,640 --> 01:04:41,960
很明显如何处理

1415
01:04:41,960 --> 01:04:44,810
日志好吧，你如何分割

1416
01:04:44,810 --> 01:04:46,910
lo  g 如果您

1417
01:04:46,910 --> 01:04:48,620
在一个口头禅组中有这两个或更多保护组中的两个或更多，

1418
01:04:48,620 --> 01:04:52,160
并且亚马逊

1419
01:04:52,160 --> 01:04:54,140
所做的答案是 Aurora 使用的

1420
01:04:54,140 --> 01:04:55,250
是数据库服务器在

1421
01:04:55,250 --> 01:04:57,200
发送日志记录时会查看日志记录的

1422
01:04:57,200 --> 01:04:59,930
数据 修改并

1423
01:04:59,930 --> 01:05:03,620
确定哪些保护组

1424
01:05:03,620 --> 01:05:06,260
存储该数据，并将每个日志

1425
01:05:06,260 --> 01:05:08,240
记录仅发送到

1426
01:05:08,240 --> 01:05:11,360
存储

1427
01:05:11,360 --> 01:05:14,540
在日志条目中修改过的数据的保护组，这

1428
01:05:14,540 --> 01:05:16,730
意味着这些保护组中的每一个都

1429
01:05:16,730 --> 01:05:19,430
存储部分数据

1430
01:05:19,430 --> 01:05:22,340
页加上

1431
01:05:22,340 --> 01:05:25,280
适用于这些数据页面的所有日志记录都会看到这些

1432
01:05:25,280 --> 01:05:27,140
保护组存储

1433
01:05:27,140 --> 01:05:36,290
与其页面相关的日志子集，因此

1434
01:05:36,290 --> 01:05:41,450
最终可能我会删除光子

1435
01:05:41,450 --> 01:05:43,820
要求，但最终要求是

1436
01:05:43,820 --> 01:05:48,260
，如果这些存储

1437
01:05:48,260 --> 01:05:50,600
服务器之一崩溃 我们希望能够

1438
01:05:50,600 --> 01:05:53,060
尽快更换它，

1439
01:05:53,060 --> 01:05:55,400
因为您知道，如果我们等待太久，

1440
01:05:55,400 --> 01:05:57,500
那么我们可能会冒险其中三个，其中

1441
01:05:57,500 --> 01:05:58,850
四个崩溃，其中四个

1442
01:05:58,850 --> 01:06:01,550
崩溃，那么我们实际上无法恢复，

1443
01:06:01,550 --> 01:06:02,750
因为那时我们不再进行改革

1444
01:06:02,750 --> 01:06:05,990
，因此如果您考虑任何一台存储服务器，我们需要尽快重新获得复制

1445
01:06:05,990 --> 01:06:08,030
，请

1446
01:06:08,030 --> 01:06:11,480
确保这样做

1447
01:06:11,480 --> 01:06:13,700
，您知道我的哪台服务器存储了 10 GB

1448
01:06:13,700 --> 01:06:15,619
数据库保护组，

1449
01:06:15,619 --> 01:06:17,810
但实际上你知道

1450
01:06:17,810 --> 01:06:19,430
这些服务器的物理设置

1451
01:06:19,430 --> 01:06:21,530
是它有一个你知道的可能

1452
01:06:21,530 --> 01:06:23,330
有一个或两个或一些

1453
01:06:23,330 --> 01:06:26,900
TB 的磁盘，用于存储 10

1454
01:06:26,900 --> 01:06:31,369
GB 或更多

1455
01:06:31,369 --> 01:06:34,670
不同 Aurora 的 10 GB 段 实例，所以

1456
01:06:34,670 --> 01:06:37,460
这台物理机器上的内容是您

1457
01:06:37,460 --> 01:06:39,410
知道 10 TB 时代字节或 10

1458
01:06:39,410 --> 01:06:42,109
TB 或任何数据，

1459
01:06:42,109 --> 01:06:44,540
因此当其中一个

1460
01:06:44,540 --> 01:06:47,600
存储服务器崩溃时，

1461
01:06:47,600 --> 01:06:50,630
它不仅会占用我数据库中的 10 GB，

1462
01:06:50,630 --> 01:06:53,359
而且还会占用 10 GB 来自

1463
01:06:53,359 --> 01:06:55,310
一百个其他人的数据库的千兆字节

1464
01:06:55,310 --> 01:06:58,100
以及必须复制的

1465
01:06:58,100 --> 01:07:00,320
不仅仅是我的 10 千兆字节，而是整个

1466
01:07:00,320 --> 01:07:03,020
TB 或任何或更多

1467
01:07:03,020 --> 01:07:05,540
存储在该服务器上的固态 - 状态驱动器

1468
01:07:05,540 --> 01:07:08,060
，如果您仔细考虑一下您知道的数字，

1469
01:07:08,060 --> 01:07:10,160
也许我们有每秒

1470
01:07:10,160 --> 01:07:15,080
 

1471
01:07:15,080 --> 01:07:18,440
10 GB 的网络接口，如果我们需要通过每秒 10 GB 的

1472
01:07:18,440 --> 01:07:19,730
网络接口将 10 TB 的数据从一

1473
01:07:19,730 --> 01:07:22,420
台机器移动到另一台机器，那将需要我

1474
01:07:22,420 --> 01:07:25,220
不知道一千 秒 一

1475
01:07:25,220 --> 01:07:26,930
万秒也许一万

1476
01:07:26,930 --> 01:07:31,100
秒，这太长了，对吧，

1477
01:07:31,100 --> 01:07:32,240
我们不想坐在那里等

1478
01:07:32,240 --> 01:07:34,580
你知道，我们不想有一个

1479
01:07:34,580 --> 01:07:37,040
策略，在这个策略中，我们可以

1480
01:07:37,040 --> 01:07:40,070
重建的弱点是 find 是让

1481
01:07:40,070 --> 01:07:41,630
另一台机器复制

1482
01:07:41,630 --> 01:07:43,609
它上面的所有内容，并让这台机器

1483
01:07:43,609 --> 01:07:46,940
向替换机器发送 10 TB

1484
01:07:46,940 --> 01:07:48,410
 

1485
01:07:48,410 --> 01:07:50,090
的数据，我们将能够比这更快地重建数据

1486
01:07:50,090 --> 01:07:52,850
，所以他们使用的实际设置是

1487
01:07:52,850 --> 01:07:56,450
，如果我有一个 特定的存储

1488
01:07:56,450 --> 01:07:57,609
服务器，

1489
01:07:57,609 --> 01:08:01,850
它存储许多段，你知道

1490
01:08:01,850 --> 01:08:04,430
许多 10 GB 保护

1491
01:08:04,430 --> 01:08:07,480
组的副本，所以也许这个保护组

1492
01:08:07,480 --> 01:08:09,830
可能是这个段，它正在

1493
01:08:09,830 --> 01:08:12,830
为另一个嫉妒存储数据

1494
01:08:12,830 --> 01:08:17,479
plicas 你知道这

1495
01:08:17,479 --> 01:08:19,819
五台机器没问题，所以它们

1496
01:08:19,819 --> 01:08:22,600
都存储

1497
01:08:22,738 --> 01:08:25,089
保护组 a 的段，所以

1498
01:08:25,089 --> 01:08:26,319
你知道还有一大堆其他机器

1499
01:08:26,319 --> 01:08:27,698
也在存储，所以我的意思是

1500
01:08:27,698 --> 01:08:29,288
我们可能是这台特定的机器也

1501
01:08:29,288 --> 01:08:33,578
存储了一个副本 用于保护组 B，

1502
01:08:33,578 --> 01:08:36,130
但 B 的数据的其他副本

1503
01:08:36,130 --> 01:08:38,979
将被放在一组不相交的

1504
01:08:38,979 --> 01:08:41,439
服务器上，因此现在有五台

1505
01:08:41,439 --> 01:08:43,269
服务器具有 B 的其他副本

1506
01:08:43,269 --> 01:08:48,788
，依此类推，用于

1507
01:08:48,788 --> 01:08:50,439
该服务器所在的所有段 坐在这个

1508
01:08:50,439 --> 01:08:52,420
存储服务器硬盘上，你知道

1509
01:08:52,420 --> 01:08:55,569
许多不同的 Aurora 实例，所以

1510
01:08:55,569 --> 01:08:57,179
这意味着这台机器出现故障

1511
01:08:57,179 --> 01:09:00,339
，替换策略是我们选择

1512
01:09:00,339 --> 01:09:01,899
如果我们说我们要在上面存储一百个

1513
01:09:01,899 --> 01:09:04,059
这样的段，我们选择一百个

1514
01:09:04,059 --> 01:09:09,460
不同的存储服务器，每一个

1515
01:09:09,460 --> 01:09:13,448
都将拾取一个新的段，

1516
01:09:13,448 --> 01:09:14,948
每个段现在都将

1517
01:09:14,948 --> 01:09:17,170
参与一个更多的保护

1518
01:09:17,170 --> 01:09:20,049
组，所以我们错过了一个

1519
01:09:20,049 --> 01:09:22,809
，就像为每一个复制一个服务器一样 10

1520
01:09:22,809 --> 01:09:24,639
GB 段，现在我们

1521
01:09:24,639 --> 01:09:28,238
知道可能有 100 种不同的段

1522
01:09:28,238 --> 01:09:29,439
服务器，你知道我可能存储

1523
01:09:29,439 --> 01:09:30,788
其他东西，但它们有

1524
01:09:30,788 --> 01:09:32,559
一点空闲磁盘空间，然后我们为每

1525
01:09:32,559 --> 01:09:35,859
一个选择一台机器，其中一个

1526
01:09:35,859 --> 01:09:38,139
副本是我们 '

1527
01:09:38,139 --> 01:09:39,908
将从剩余的副本之一复制数据，

1528
01:09:39,908 --> 01:09:41,408
所以也许我们将从那里复制

1529
01:09:41,408 --> 01:09:43,749
B 从这里你知道如果我们

1530
01:09:43,749 --> 01:09:47,738
有五个其他副本与 C 我们

1531
01:09:47,738 --> 01:09:50,889
为 C 选择不同的服务器，所以我们有 我们

1532
01:09:50,889 --> 01:09:53,408
从这台服务器复制 a 到那台服务器

1533
01:09:53,408 --> 01:09:57,849
，像这样复制 B，像这样复制 C，所以

1534
01:09:57,849 --> 01:10:01,749
现在我们有一百个不同的 10

1535
01:10:01,749 --> 01:10:03,960
GB 副本在网络上并行

1536
01:10:03,960 --> 01:10:07,360
进行，假设您知道

1537
01:10:07,360 --> 01:10:09,369
我们有足够的服务器，这些服务器

1538
01:10:09,369 --> 01:10:11,999
都可以是不相交的，并且 我们

1539
01:10:11,999 --> 01:10:14,889
在连接它们的交换网络中有足够的带宽

1540
01:10:14,889 --> 01:10:17,849
现在我们可以复制我们的

1541
01:10:17,849 --> 01:10:20,139
TB 或 10 TB 或任何

1542
01:10:20,139 --> 01:10:23,110
数据，并且以一

1543
01:10:23,110 --> 01:10:25,570
百倍的并行度并行，整个

1544
01:10:25,570 --> 01:10:27,489
事情会让你知道 10 秒之类的

1545
01:10:27,489 --> 01:10:29,289
 

1546
01:10:29,289 --> 01:10:30,729
如果只涉及两台机器，而不是花费一千秒

1547
01:10:30,729 --> 01:10:34,449
，所以

1548
01:10:34,449 --> 01:10:35,739
这就是他们使用的策略，这

1549
01:10:35,739 --> 01:10:37,090
意味着他们可以恢复你知道的

1550
01:10:37,090 --> 01:10:39,699
机器死亡如果有很多机器，他们可以非常快速地

1551
01:10:39,699 --> 01:10:41,679
从一台机器的死亡中并行恢复

1552
01:10:41,679 --> 01:10:45,340
 

1553
01:10:45,340 --> 01:10:49,090
节食法效果不佳，但它们可以

1554
01:10:49,090 --> 01:10:50,380
从单机中恢复，它们可以

1555
01:10:50,380 --> 01:10:52,179
 

1556
01:10:52,179 --> 01:10:58,119
非常快地从单机崩溃中复制，所以最后一

1557
01:10:58,119 --> 01:10:59,829
件事，如果

1558
01:10:59,829 --> 01:11:02,949
你看图三，你会发现

1559
01:11:02,949 --> 01:11:06,280
他们不仅有 数据库，但

1560
01:11:06,280 --> 01:11:09,880
他们也有副本数据库，因此对于

1561
01:11:09,880 --> 01:11:12,130
他们的许多客户来说，他们的许多

1562
01:11:12,130 --> 01:11:14,829
客户看到的

1563
01:11:14,829 --> 01:11:17,619
只读查询比他们看到的读写查询要

1564
01:11:17,619 --> 01:11:19,209
 

1565
01:11:19,209 --> 01:11:21,219
 

1566
01:11:21,219 --> 01:11:24,070
多得多 您连接的网络服务器

1567
01:11:24,070 --> 01:11:25,719
是否必须阅读

1568
01:11:25,719 --> 01:11:28,150
大量内容才能生成

1569
01:11:28,150 --> 01:11:30,190
页面上显示给您的所有内容，

1570
01:11:30,190 --> 01:11:32,019
可能有数百个不同的项目

1571
01:11:32,019 --> 01:11:33,969
要从数据库中读取或

1572
01:11:33,969 --> 01:11:35,499
从某个数据库中读取，但

1573
01:11:35,499 --> 01:11:37,630
典型网页视图的写入次数

1574
01:11:37,630 --> 01:11:39,340
通常要小得多，

1575
01:11:39,340 --> 01:11:41,260
也许必须更新一些统计数据或

1576
01:11:41,260 --> 01:11:42,639
为您更新一点历史记录或

1577
01:11:42,639 --> 01:11:44,440
其他东西，所以您可能有 100

1578
01:11:44,440 --> 01:11:48,400
比 1 的读写比率，即您

1579
01:11:48,400 --> 01:11:50,739
通常可能有

1580
01:11:50,739 --> 01:11:54,519
大量的直接只读数据库

1581
01:11:54,519 --> 01:11:57,729
查询，现在使用这种设置，写入

1582
01:11:57,729 --> 01:11:59,889
只能通过一个数据库

1583
01:11:59,889 --> 01:12:01,150
服务器，因为我们真的只能

1584
01:12:01,150 --> 01:12:03,130
支持一个写入器 这种存储

1585
01:12:03,130 --> 01:12:06,070
策略，我想你知道一个

1586
01:12:06,070 --> 01:12:07,479
地方，橡胶真正上路

1587
01:12:07,479 --> 01:12:09,489
了，日志条目必须

1588
01:12:09,489 --> 01:12:11,769
按顺序编号，

1589
01:12:11,769 --> 01:12:13,479
如果所有写入都通过单个

1590
01:12:13,479 --> 01:12:15,459
服务器，这很容易做到，如果我们

1591
01:12:15,459 --> 01:12:17,440
有很多 不同的服务器

1592
01:12:17,440 --> 01:12:19,090
以一种不协调的方式

1593
01:12:19,090 --> 01:12:21,880
写入同一个数据库，所以写入确实

1594
01:12:21,880 --> 01:12:24,329
必须通过一个数据库，但

1595
01:12:24,329 --> 01:12:27,429
我们可以设置，亚马逊确实

1596
01:12:27,429 --> 01:12:29,469
设置了一个位置 我们已经

1597
01:12:29,469 --> 01:12:32,709
只读了可以

1598
01:12:32,709 --> 01:12:35,469
从这些存储服务器读取的数据库副本，因此

1599
01:12:35,469 --> 01:12:38,530
图 3 的全部优点是，

1600
01:12:38,530 --> 01:12:40,719
除了处理写入请求的主数据库服务器

1601
01:12:40,719 --> 01:12:42,880
之外，

1602
01:12:42,880 --> 01:12:48,280
还有一组只读

1603
01:12:48,280 --> 01:12:50,960
数据库，他们说 最多可以支持

1604
01:12:50,960 --> 01:12:53,030
15 个，因此您实际上可以让

1605
01:12:53,030 --> 01:12:56,510
很多人知道，如果您的上级，我们会让您

1606
01:12:56,510 --> 01:12:58,850
工作量很大，您可能知道

1607
01:12:58,850 --> 01:13:01,190
其中大部分可以被分成

1608
01:13:01,190 --> 01:13:02,960
一大堆只读的 数据库

1609
01:13:02,960 --> 01:13:05,450
，当客户端向只读数据库发送读取请求时

1610
01:13:05,450 --> 01:13:07,160
，会发生什么情况

1611
01:13:07,160 --> 01:13:09,470
是只读数据库计算出您

1612
01:13:09,470 --> 01:13:11,780
知道它需要哪些数据页来服务

1613
01:13:11,780 --> 01:13:14,120
该请求并将读取

1614
01:13:14,120 --> 01:13:15,920
直接发送到存储系统而不

1615
01:13:15,920 --> 01:13:21,500
打扰主读写数据库所以

1616
01:13:21,500 --> 01:13:23,180
只读副本数据库

1617
01:13:23,180 --> 01:13:25,640
提升页面请求

1618
01:13:25,640 --> 01:13:27,560
直接向存储服务器请求读取请求，然后

1619
01:13:27,560 --> 01:13:31,490
它们将不会缓存这些页面，以便

1620
01:13:31,490 --> 01:13:33,680
他们可以知道它们

1621
01:13:33,680 --> 01:13:35,810
直接从缓存中响应未来的读取请求

1622
01:13:35,810 --> 01:13:36,830
当然，他们需要能够更新

1623
01:13:36,830 --> 01:13:40,370
这些缓存，因此 Aurora

1624
01:13:40,370 --> 01:13:43,280
还将其日志副本发送

1625
01:13:43,280 --> 01:13:46,790
到每个只读

1626
01:13:46,790 --> 01:13:49,130
数据库，这就是

1627
01:13:49,130 --> 01:13:51,260
您在蓝色框和

1628
01:13:51,260 --> 01:13:52,970
图三之间看到的水平线 主数据库

1629
01:13:52,970 --> 01:13:55,490
发送所有日志条目，这些是否意味着

1630
01:13:55,490 --> 01:13:57,550
它们仅用于更新

1631
01:13:57,550 --> 01:14:03,740
其缓存副本以反映

1632
01:14:03,740 --> 01:14:05,420
数据库中最近的事务的数据库，这

1633
01:14:05,420 --> 01:14:07,940
意味着它确实意味着只读

1634
01:14:07,940 --> 01:14:09,530
数据库落后于主数据库一点点，

1635
01:14:09,530 --> 01:14:12,260
但它变成了

1636
01:14:12,260 --> 01:14:13,820
如果

1637
01:14:13,820 --> 01:14:15,650
您查看网页并且您知道

1638
01:14:15,650 --> 01:14:17,330
20 毫秒过期这

1639
01:14:17,330 --> 01:14:24,230
通常不是一个大问题 这会带来一些

1640
01:14:24,230 --> 01:14:26,750
复杂性，就像一个问题

1641
01:14:26,750 --> 01:14:28,340
是我们不想要这些 中继

1642
01:14:28,340 --> 01:14:31,010
数据库以查看尚未提交的

1643
01:14:31,010 --> 01:14:34,310
事务中的数据，因此在此

1644
01:14:34,310 --> 01:14:36,980
日志条目流中，数据库可能需要

1645
01:14:36,980 --> 01:14:39,470
在某种程度上表示哪些事务

1646
01:14:39,470 --> 01:14:42,050
已提交并且它们是只读

1647
01:14:42,050 --> 01:14:43,510
数据库 小心不要将

1648
01:14:43,510 --> 01:14:44,800
不常见的

1649
01:14:44,800 --> 01:14:47,870
未提交事务应用到他们的缓存中，

1650
01:14:47,870 --> 01:14:49,670
他们等到事务提交

1651
01:14:49,670 --> 01:14:54,770
这些只读副本强加的另一个复杂性

1652
01:14:54,770 --> 01:14:59,410
是

1653
01:14:59,410 --> 01:15:03,430
，这些结构中的这些

1654
01:15:03,430 --> 01:15:05,380
结构非常复杂，这

1655
01:15:05,380 --> 01:15:06,670
可能是一个 b-tree 它可能 需要

1656
01:15:06,670 --> 01:15:09,520
定期重新平衡，例如我

1657
01:15:09,520 --> 01:15:10,720
的重新平衡是一个相当复杂的

1658
01:15:10,720 --> 01:15:12,430
操作，其中很多树必须

1659
01:15:12,430 --> 01:15:15,580
以原子方式修改，因此

1660
01:15:15,580 --> 01:15:17,350
树在平衡时是不正确的

1661
01:15:17,350 --> 01:15:19,000
，你只允许在

1662
01:15:19,000 --> 01:15:21,520
之后查看它 如果

1663
01:15:21,520 --> 01:15:23,950
这些只读副本直接

1664
01:15:23,950 --> 01:15:25,390
从数据库中读取页面，则完成重新平衡存在

1665
01:15:25,390 --> 01:15:28,120
风险他们可能会

1666
01:15:28,120 --> 01:15:30,190
看到存储在

1667
01:15:30,190 --> 01:15:31,810
这些数据页面中的数据库的 be 树 他们可能会看到

1668
01:15:31,810 --> 01:15:34,030
重新平衡中间的蜜蜂树 或

1669
01:15:34,030 --> 01:15:37,450
其他一些操作，数据

1670
01:15:37,450 --> 01:15:39,070
是完全非法的，它们可能会

1671
01:15:39,070 --> 01:15:43,360
崩溃或只是故障，当

1672
01:15:43,360 --> 01:15:45,640
论文谈论迷你交易

1673
01:15:45,640 --> 01:15:49,720
和 vdl verses vcl dis 它

1674
01:15:49,720 --> 01:15:51,760
所说的是一种机制

1675
01:15:51,760 --> 01:15:54,700
，数据库服务器可以通过该机制告诉存储

1676
01:15:54,700 --> 01:15:57,550
服务器看起来这个复杂的

1677
01:15:57,550 --> 01:16:02,560
日志条目序列只能以原子方式全部或全部显示

1678
01:16:02,560 --> 01:16:04,690
给任何只读

1679
01:16:04,690 --> 01:16:07,420
事务，这就是迷你

1680
01:16:07,420 --> 01:16:09,250
事务和 VDL 的意义所在，并且

1681
01:16:09,250 --> 01:16:10,780
基本上是读取，当只读

1682
01:16:10,780 --> 01:16:13,600
数据库要求查看

1683
01:16:13,600 --> 01:16:15,580
来自存储服务器的数据页时，存储服务器

1684
01:16:15,580 --> 01:16:17,800
会小心地显示来自

1685
01:16:17,800 --> 01:16:20,650
这些序列之一之前的数据，许多

1686
01:16:20,650 --> 01:16:23,740
事务序列的日志条目，或者

1687
01:16:23,740 --> 01:16:28,630
只是之后但不在中间

1688
01:16:28,630 --> 01:16:33,370
好的，这就是

1689
01:16:33,370 --> 01:16:34,840
我要讨论的所有技术内容，只是

1690
01:16:34,840 --> 01:16:36,430
为了总结一下

1691
01:16:36,430 --> 01:16:37,720
这篇论文的有趣之处以及可以从论文中学到什么

1692
01:16:37,720 --> 01:16:41,470
 

1693
01:16:41,470 --> 01:16:43,540
 

1694
01:16:43,540 --> 01:16:45,400
系统

1695
01:16:45,400 --> 01:16:48,360
应该知道事务处理数据库如何工作的基础知识以及

1696
01:16:48,360 --> 01:16:50,620
事务处理数据库

1697
01:16:50,620 --> 01:16:53,520
之间的交互所产生的影响

1698
01:16:53,520 --> 01:16:55,920
 

1699
01:16:55,920 --> 01:16:58,450
es 和存储

1700
01:16:58,450 --> 01:17:00,340
系统，因为这经常出现它

1701
01:17:00,340 --> 01:17:01,900
就像一个普遍存在的东西，你知道运行真实数据库的

1702
01:17:01,900 --> 01:17:05,160
性能和崩溃可恢复

1703
01:17:05,160 --> 01:17:07,240
性的复杂性

1704
01:17:07,240 --> 01:17:10,050
只是在

1705
01:17:10,050 --> 01:17:13,210
系统设计中一遍又一遍地出现，本文要学习的另一件事

1706
01:17:13,210 --> 01:17:15,820
是仲裁的想法和

1707
01:17:15,820 --> 01:17:18,700
重叠重叠

1708
01:17:18,700 --> 01:17:20,950
读/写 quorum 的技术，以便始终

1709
01:17:20,950 --> 01:17:22,540
能够看到最新的数据，但也能获得

1710
01:17:22,540 --> 01:17:24,250
容错，当然

1711
01:17:24,250 --> 01:17:27,250
这在 raft 中也出现了 raft 具有强烈

1712
01:17:27,250 --> 01:17:29,070
的 quorum 风味，

1713
01:17:29,070 --> 01:17:31,570
这是本文的另一个有趣的想法

1714
01:17:31,570 --> 01:17:33,760
是数据库和

1715
01:17:33,760 --> 01:17:35,830
存储系统基本上是共同设计

1716
01:17:35,830 --> 01:17:37,870
的一种

1717
01:17:37,870 --> 01:17:39,460
集成 跨数据库层

1718
01:17:39,460 --> 01:17:41,170
和存储层的集成，或者几乎

1719
01:17:41,170 --> 01:17:43,480
重新设计以尝试设计系统，以便

1720
01:17:43,480 --> 01:17:45,370
他们知道

1721
01:17:45,370 --> 01:17:49,180
服务消费者和那种服务之间的良好分离

1722
01:17:49,180 --> 01:17:50,770
基础设施服务，比如

1723
01:17:50,770 --> 01:17:52,840
通常的存储，是非常

1724
01:17:52,840 --> 01:17:54,880
通用的，不是针对

1725
01:17:54,880 --> 01:17:57,780
特定应用程序的，只是你知道，

1726
01:17:57,780 --> 01:18:00,010
因为 这是一个令人愉快的设计，这

1727
01:18:00,010 --> 01:18:01,930
也意味着

1728
01:18:01,930 --> 01:18:03,460
可以对相同的基础架构进行许多不同的用途，

1729
01:18:03,460 --> 01:18:06,100
但是这里的性能问题非常

1730
01:18:06,100 --> 01:18:07,360
严重，你知道他们必须

1731
01:18:07,360 --> 01:18:09,820
通过模糊这个边界来获得 35 倍的性能提升

1732
01:18:09,820 --> 01:18:13,540
这是

1733
01:18:13,540 --> 01:18:14,830
一种情况 其中通用

1734
01:18:14,830 --> 01:18:16,900
存储实际上并没有什么

1735
01:18:16,900 --> 01:18:19,260
优势，他们通过

1736
01:18:19,260 --> 01:18:22,930
放弃这个想法和最后一组

1737
01:18:22,930 --> 01:18:24,540
东西从论文中

1738
01:18:24,540 --> 01:18:26,770
 

1739
01:18:26,770 --> 01:18:30,040
获得了巨大

1740
01:18:30,040 --> 01:18:32,560
的胜利 你

1741
01:18:32,560 --> 01:18:35,320
真的知道他们在做

1742
01:18:35,320 --> 01:18:37,300
什么 他们对云

1743
01:18:37,300 --> 01:18:41,050
基础设施有什么顾虑 比如

1744
01:18:41,050 --> 01:18:42,970
他们对

1745
01:18:42,970 --> 01:18:45,610
整个可用区可能失败的担忧程度 这是

1746
01:18:45,610 --> 01:18:48,250
一个重要

1747
01:18:48,250 --> 01:18:51,550
的消息 单个存储

1748
01:18:51,550 --> 01:18:53,980
服务器的瞬时缓慢很重要这一事实 另一

1749
01:18:53,980 --> 01:18:57,720
件事实际上也经常出现，

1750
01:18:57,720 --> 01:19:00,490
最后暗示网络

1751
01:19:00,490 --> 01:19:02,530
是主要瓶颈 因为毕竟

1752
01:19:02,530 --> 01:19:04,660
他们竭尽全力

1753
01:19:04,660 --> 01:19:06,610
通过网络发送更少的数据，

1754
01:19:06,610 --> 01:19:08,050
但作为回报，存储服务器

1755
01:19:08,050 --> 01:19:10,810
必须做更多的工作，他们说他们

1756
01:19:10,810 --> 01:19:12,610
愿意告诉你 6 个数据副本，

1757
01:19:12,610 --> 01:19:16,800
并且有 6 个 CPU 全部复制

1758
01:19:16,800 --> 01:19:19,480
执行应用这些重做日志

1759
01:19:19,480 --> 01:19:21,400
条目显然 CPU

1760
01:19:21,400 --> 01:19:24,460
对他们来说相对便宜，而网络

1761
01:19:24,460 --> 01:19:26,560
容量非常重要

1762
01:19:26,560 --> 01:19:31,630
，这就是我要说的，

1763
01:19:31,900 --> 01:19:35,290
下周见

