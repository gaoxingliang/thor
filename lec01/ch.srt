1
00:00:00,800 --> 00:00:05,210
【翻译：Cyru1s / Halcyon】
让我们开始课程

2
00:00:05,210 --> 00:00:11,820
【翻译：Cyru1s / Halcyon】
本课程是 6.824 分布式系统

3
00:00:11,820 --> 00:00:13,230
本节课我们从分布式系统的

4
00:00:13,230 --> 00:00:14,639
整体概要开始讲起

5
00:00:14,639 --> 00:00:18,960
大家都知道本课程的核心是

6
00:00:18,960 --> 00:00:21,630
一系列计算集群通过网络

7
00:00:21,630 --> 00:00:23,190
共同完成

8
00:00:23,190 --> 00:00:26,190
某一串连贯的任务

9
00:00:26,190 --> 00:00:29,730
因此，我们在本课程中

10
00:00:29,730 --> 00:00:31,530
重点介绍的一些案例包括：

11
00:00:31,530 --> 00:00:34,970
大型网站的储存系统

12
00:00:34,970 --> 00:00:38,660
大规模数据集运算，如 MapReduce

13
00:00:38,660 --> 00:00:41,760
以及一些更为奇妙的技术

14
00:00:41,760 --> 00:00:43,950
比如点对点的文件共享

15
00:00:43,950 --> 00:00:45,870
这只是我们学习过程中的一些例子

16
00:00:45,870 --> 00:00:48,329
我们同样会关注

17
00:00:48,329 --> 00:00:49,800
为何分布式计算之所以如此重要

18
00:00:49,800 --> 00:00:51,600
是因为许多重要的基础设施

19
00:00:51,600 --> 00:00:53,489
都是在此基础上建立的

20
00:00:53,489 --> 00:00:56,250
他们都需要多台计算机

21
00:00:56,250 --> 00:00:57,570
或者说本质上是

22
00:00:57,570 --> 00:00:59,579
多台物理隔离的计算机

23
00:00:59,579 --> 00:01:04,019
共同完成自己的工作

24
00:01:04,019 --> 00:01:06,300
以及为何人们要创建这种运算架构

25
00:01:06,300 --> 00:01:08,190
我会先介绍分布式系统

26
00:01:08,190 --> 00:01:10,500
也是提醒大家

27
00:01:10,500 --> 00:01:12,420
在你设计一个系统时

28
00:01:12,420 --> 00:01:14,280
或者面对一个你需要解决的问题时

29
00:01:14,280 --> 00:01:16,409
你需要知道他是否可以在

30
00:01:16,409 --> 00:01:18,570
不需要分布式系统的单机上解决

31
00:01:18,570 --> 00:01:20,100
如果可以那就应该用单机解决

32
00:01:20,100 --> 00:01:23,340
因为很多的工作都可以在

33
00:01:23,340 --> 00:01:25,080
一台计算机上完成

34
00:01:25,080 --> 00:01:29,220
这通常比分布式系统简单很多

35
00:01:29,220 --> 00:01:30,780
在选择使用分布式系统解决问题前

36
00:01:30,780 --> 00:01:32,400
你需要充分尝试别的思路

37
00:01:32,400 --> 00:01:34,020
因为分布式系统会让问题解决

38
00:01:34,020 --> 00:01:36,630
变得复杂

39
00:01:36,630 --> 00:01:39,060
我们也会说是什么促使了人们

40
00:01:39,060 --> 00:01:41,640
通过计算集群来达到

41
00:01:41,640 --> 00:01:43,350
更高的计算性能

42
00:01:43,350 --> 00:01:45,180
以及思考他们是如何实现

43
00:01:45,180 --> 00:01:50,520
并行管理大量CPU 大量内存

44
00:01:50,520 --> 00:01:52,409
大量磁盘臂也在同时移动

45
00:01:52,409 --> 00:01:56,580
以及为何要在

46
00:01:56,580 --> 00:01:58,290
计算集群中处理

47
00:01:58,290 --> 00:02:01,070
容错问题

48
00:02:05,310 --> 00:02:07,900
比如两台计算机运行

49
00:02:07,900 --> 00:02:09,580
完全相同的任务

50
00:02:09,580 --> 00:02:12,610
以防在其中一台发生问题

51
00:02:12,610 --> 00:02:15,070
以及一些

52
00:02:15,070 --> 00:02:17,560
物理上的问题

53
00:02:17,560 --> 00:02:19,420
比如你在用网银转账之类的操作

54
00:02:19,420 --> 00:02:21,820
我们假设

55
00:02:21,820 --> 00:02:23,980
银行A在纽约有一台服务器

56
00:02:23,980 --> 00:02:26,110
银行B在伦敦有一台服务器

57
00:02:26,110 --> 00:02:27,790
这就需要一种

58
00:02:27,790 --> 00:02:29,709
克服两个银行服务器之间

59
00:02:29,709 --> 00:02:31,330
物理距离的

60
00:02:31,330 --> 00:02:36,310
通信方式

61
00:02:36,310 --> 00:02:37,360
这是一个不可避免

62
00:02:37,360 --> 00:02:40,000
的空间问题

63
00:02:40,000 --> 00:02:42,040
最后人们为了解决

64
00:02:42,040 --> 00:02:44,320
一些安全问题

65
00:02:44,320 --> 00:02:46,660
比如有一些代码并不被信任

66
00:02:46,660 --> 00:02:49,090
但是你有需要和他进行交互

67
00:02:49,090 --> 00:02:50,920
这些代码不会立刻做出坏事

68
00:02:50,920 --> 00:02:53,170
或者说这些代码只是

69
00:02:53,170 --> 00:02:55,420
可能会有一些bug导致不被信任

70
00:02:55,420 --> 00:02:57,160
你可能需要将代码

71
00:02:57,160 --> 00:02:59,350
分多处运行

72
00:02:59,350 --> 00:03:01,000
在你的计算机上

73
00:03:01,000 --> 00:03:02,500
和我的计算机上都会运行

74
00:03:02,500 --> 00:03:04,150
两份代码需要通过

75
00:03:04,150 --> 00:03:06,580
某个狭义的网络协议通信

76
00:03:06,580 --> 00:03:10,330
我们可能会担心

77
00:03:10,330 --> 00:03:13,570
这里的安全问题

78
00:03:13,570 --> 00:03:14,980
我们把它分成更多的计算机

79
00:03:14,980 --> 00:03:16,420
就可能出现孤立的问题

80
00:03:16,420 --> 00:03:21,459
这门课我们会一直讨论

81
00:03:21,459 --> 00:03:23,920
性能和容错

82
00:03:23,920 --> 00:03:26,410
剩下两点我们会通过

83
00:03:26,410 --> 00:03:28,630
对某些案例的研究

84
00:03:28,630 --> 00:03:30,070
来学习

85
00:03:30,070 --> 00:03:32,799
下面我们来看

86
00:03:32,799 --> 00:03:34,390
这些分布式系统的问题

87
00:03:34,390 --> 00:03:36,430
因为系统中存在很多部分

88
00:03:36,430 --> 00:03:39,810
这些部分又在并发执行

89
00:03:39,810 --> 00:03:42,220
正因为有多台计算机

90
00:03:42,220 --> 00:03:43,510
所以才会遇到并发编程

91
00:03:43,510 --> 00:03:45,190
以及各种复杂交互

92
00:03:45,190 --> 00:03:46,720
所带来的各种问题

93
00:03:46,720 --> 00:03:49,660
我们还要考虑一些时序问题

94
00:03:49,660 --> 00:03:51,780
这让分布式系统这门课变得很难

95
00:03:51,780 --> 00:03:54,340
另一个很难的问题是

96
00:03:54,340 --> 00:03:56,920
你会有多个实例

97
00:03:56,920 --> 00:03:59,410
再加上网络

98
00:03:59,410 --> 00:04:02,440
所以会遇到一些意想不到的报错

99
00:04:02,440 --> 00:04:04,540
如果只有一台计算机

100
00:04:04,540 --> 00:04:06,280
通常它只会正常工作

101
00:04:06,280 --> 00:04:08,350
或者可能会崩溃

102
00:04:08,350 --> 00:04:11,050
或者是电源有问题之类的

103
00:04:11,050 --> 00:04:12,280
工作或崩溃 这相对简单

104
00:04:12,280 --> 00:04:14,470
分布式系统却不是这样

105
00:04:14,470 --> 00:04:15,940
因为多台计算机中

106
00:04:15,940 --> 00:04:18,399
可能会遇到一部分实例停止

107
00:04:18,399 --> 00:04:20,140
导致的局部错误

108
00:04:20,140 --> 00:04:22,450
但是其他部分依旧在正常运行

109
00:04:22,450 --> 00:04:24,280
或者这些计算机都在正常运行

110
00:04:24,280 --> 00:04:28,000
但是网络断了或者不稳定

111
00:04:28,000 --> 00:04:30,870
局部错误也是使这门课

112
00:04:30,870 --> 00:04:50,229
很难的原因之一

113
00:04:50,229 --> 00:04:51,880
最后一点很难的问题是

114
00:04:51,880 --> 00:04:53,289
人们设计分布式系统

115
00:04:53,289 --> 00:04:54,780
的根本原因是为了

116
00:04:54,780 --> 00:04:57,610
获得更高的性能

117
00:04:57,610 --> 00:04:59,380
比如一千台计算机

118
00:04:59,380 --> 00:05:01,659
一千个磁盘臂达到的性能

119
00:05:01,659 --> 00:05:03,580
但是实际上

120
00:05:03,580 --> 00:05:06,820
一千台机器到底有几千台性能

121
00:05:06,820 --> 00:05:09,310
是一个棘手的问题

122
00:05:09,310 --> 00:05:12,010
这有很多难点

123
00:05:12,010 --> 00:05:20,080
人们倍加小心地设计

124
00:05:20,080 --> 00:05:22,960
实际的系统 让你觉得

125
00:05:22,960 --> 00:05:24,270
它的性能达到了你投入的预期

126
00:05:24,270 --> 00:05:26,440
那么解决这些问题

127
00:05:26,440 --> 00:05:27,690
就是本课的全部

128
00:05:27,690 --> 00:05:31,960
我想选择来上这门课

129
00:05:31,960 --> 00:05:33,729
来解决这些问题

130
00:05:33,729 --> 00:05:35,409
是因为问题和解决方案

131
00:05:35,409 --> 00:05:38,320
在技术上都很有趣

132
00:05:38,320 --> 00:05:40,330
有些很难的问题

133
00:05:40,330 --> 00:05:42,640
有着很漂亮的解决方案

134
00:05:42,640 --> 00:05:44,500
但是有些问题就没有那么好的

135
00:05:44,500 --> 00:05:47,740
解决方案

136
00:05:47,740 --> 00:05:50,919
分布式系统正在现实生活中被运用

137
00:05:50,919 --> 00:05:53,349
像很多大型网站

138
00:05:53,349 --> 00:05:55,240
他们把大量的计算机

139
00:05:55,240 --> 00:05:57,970
放在一起作为分布式系统

140
00:05:57,970 --> 00:06:00,430
当我刚开始教这门课的时候

141
00:06:00,430 --> 00:06:03,490
分布式系统还是一种

142
00:06:03,490 --> 00:06:05,229
学术上的好奇尝试

143
00:06:05,229 --> 00:06:07,659
人们只是发现

144
00:06:07,659 --> 00:06:09,760
有时需要一些小型扩容

145
00:06:09,760 --> 00:06:11,080
并且预感在未来

146
00:06:11,080 --> 00:06:14,740
这可能很重要

147
00:06:14,740 --> 00:06:16,690
但是随着大型网站的兴起和推动

148
00:06:16,690 --> 00:06:18,970
出现了大量的数据

149
00:06:18,970 --> 00:06:21,960
和充满服务器的仓库

150
00:06:21,960 --> 00:06:23,650
再过去的二十年中

151
00:06:23,650 --> 00:06:25,860
分布式系统已经是

152
00:06:25,860 --> 00:06:29,259
计算架构中很重要的一部分

153
00:06:29,259 --> 00:06:32,889
这意味着

154
00:06:32,889 --> 00:06:34,479
大量的精力投入到

155
00:06:34,479 --> 00:06:36,250
解决相关问题的工作中

156
00:06:36,250 --> 00:06:37,690
但是同样有少数问题

157
00:06:37,690 --> 00:06:39,940
没有被解决

158
00:06:39,940 --> 00:06:42,490
如果你对这方面研究感兴趣

159
00:06:42,490 --> 00:06:45,310
还有很多关于分布式系统的问题

160
00:06:45,310 --> 00:06:47,289
等着你去解决

161
00:06:47,289 --> 00:06:49,720
你们可以关注相关研究

162
00:06:49,720 --> 00:06:51,639
最后 如果你是一位热衷动手的同学

163
00:06:51,639 --> 00:06:54,220
这会是一门不错的课程

164
00:06:54,220 --> 00:06:56,050
因为他有一系列实验

165
00:06:56,050 --> 00:06:58,690
你会编写出重点为高性能和容错的

166
00:06:58,690 --> 00:07:00,610
相当真实的

167
00:07:00,610 --> 00:07:01,180
分布式系统

168
00:07:01,180 --> 00:07:04,600
所以你会有很多机会

169
00:07:04,600 --> 00:07:06,789
去构建一个分布式系统

170
00:07:06,789 --> 00:07:09,550
并且让他们正常工作

171
00:07:09,550 --> 00:07:12,419
好了 让我们在说技术内容之前

172
00:07:12,419 --> 00:07:16,539
说一下课程结构

173
00:07:16,539 --> 00:07:19,060
你们可能是通过百度找到了

174
00:07:19,060 --> 00:07:22,780
这门课的网站

175
00:07:22,780 --> 00:07:24,820
网站上有一些实验作业

176
00:07:24,820 --> 00:07:28,150
课程时间表 和一个Piazza（某国外课程论坛）页面链接

177
00:07:28,150 --> 00:07:31,210
你可以在那里发布问题并获得解答

178
00:07:31,210 --> 00:07:35,320
课程主要的教学人员有

179
00:07:35,320 --> 00:07:36,970
我 Robert Morris 会进行课堂授课

180
00:07:36,970 --> 00:07:39,250
也有四个助教

181
00:07:39,250 --> 00:07:44,349
你们想站起来和大家打个招呼嘛

182
00:07:44,349 --> 00:07:47,949
助教会重点解决实验问题

183
00:07:47,949 --> 00:07:49,690
在工作时间

184
00:07:49,690 --> 00:07:51,400
他们也会在办公室解答

185
00:07:51,400 --> 00:07:53,080
各位关于实验的问题

186
00:07:53,080 --> 00:07:55,360
你可以去办公室或将课程相关问题

187
00:07:55,360 --> 00:07:59,650
发到Piazza上

188
00:07:59,650 --> 00:08:04,030
这门课有几个重要组成部分

189
00:08:04,030 --> 00:08:09,099
一个是课堂授课

190
00:08:09,099 --> 00:08:16,380
几乎每节课都有论文阅读 以及两次考试

191
00:08:17,789 --> 00:08:22,650
两次编程实验

192
00:08:22,650 --> 00:08:25,479
以及一个可选的期末大作业

193
00:08:25,479 --> 00:08:28,740
你可以用一个实验来代替它

194
00:08:36,039 --> 00:08:38,320
授课内容会围绕分布式系统

195
00:08:38,320 --> 00:08:42,070
主要是上面两个问题（性能和容错）

196
00:08:42,070 --> 00:08:43,809
同样也有几堂课会说一些关于

197
00:08:43,809 --> 00:08:47,140
编程实验的内容

198
00:08:47,140 --> 00:08:48,640
许多课程我们以案例分析为

199
00:08:48,640 --> 00:08:50,589
主要形式

200
00:08:50,589 --> 00:08:53,650
我会在课前提供一些

201
00:08:53,650 --> 00:08:55,210
关于分布式系统的论文

202
00:08:55,210 --> 00:08:58,110
有些学术研究 也有一些工业界

203
00:08:58,110 --> 00:09:01,960
关于现实问题的

204
00:09:01,960 --> 00:09:05,100
现实解决方案

205
00:09:05,589 --> 00:09:07,589
授课内容会被录像

206
00:09:07,589 --> 00:09:10,270
我希望课程可以上传到网络

207
00:09:10,270 --> 00:09:12,940
这样你们可以在别的地方

208
00:09:12,940 --> 00:09:15,279
观看授课视频

209
00:09:15,279 --> 00:09:16,270
你们也可以回顾课程视频

210
00:09:16,270 --> 00:09:20,110
这里的论文每周会发布一次

211
00:09:20,110 --> 00:09:22,060
主要为学术研究中

212
00:09:22,060 --> 00:09:24,610
的一些经典论文

213
00:09:24,610 --> 00:09:26,440
比如像今天我希望你们阅读

214
00:09:26,440 --> 00:09:28,390
关于MapReduce的论文 这篇论文很老

215
00:09:28,390 --> 00:09:31,390
但是这篇论文不论在学术界还是工业界

216
00:09:31,390 --> 00:09:33,310
都激发了巨大的

217
00:09:33,310 --> 00:09:35,860
关于分布式系统的兴趣

218
00:09:35,860 --> 00:09:37,029
有一些经典论文 也有一些最近发布的论文

219
00:09:37,029 --> 00:09:40,060
他们会讨论一些

220
00:09:40,060 --> 00:09:41,500
最近人们关心的

221
00:09:41,500 --> 00:09:44,529
最新研究成果

222
00:09:44,529 --> 00:09:46,060
我希望这些论文可以让弄清楚

223
00:09:46,060 --> 00:09:49,120
一些基本问题 比如研究者们有哪些想法

224
00:09:49,120 --> 00:09:50,529
这可能会也可能不会

225
00:09:50,529 --> 00:09:52,180
对解决分布式系统的问题有用

226
00:09:52,180 --> 00:09:54,970
我们有时会讨论这些论文中的

227
00:09:54,970 --> 00:09:56,650
一些实施细节

228
00:09:56,650 --> 00:09:58,720
因为包括很多

229
00:09:58,720 --> 00:10:01,120
软件系统的实际组成

230
00:10:01,120 --> 00:10:03,430
我们同样需要花一些时间

231
00:10:03,430 --> 00:10:04,900
去看对人们对系统的评价

232
00:10:04,900 --> 00:10:07,540
人们是如何通过

233
00:10:07,540 --> 00:10:09,310
评估系统容错性

234
00:10:09,310 --> 00:10:11,200
评估系统性能

235
00:10:11,200 --> 00:10:12,790
或者是否有性能提升

236
00:10:12,790 --> 00:10:17,950
来评价这个系统

237
00:10:17,950 --> 00:10:19,810
我希望你们可以在来到课堂之前

238
00:10:19,810 --> 00:10:22,660
完成论文的阅读

239
00:10:22,660 --> 00:10:24,220
如果没有提前阅读

240
00:10:24,220 --> 00:10:26,110
课堂授课不一定有足够的时间

241
00:10:26,110 --> 00:10:28,209
我们没有足够的时间来解释

242
00:10:28,209 --> 00:10:30,820
论文中的每一个概念

243
00:10:30,820 --> 00:10:32,830
同时还要兼顾一些

244
00:10:32,830 --> 00:10:35,050
有趣的拓展

245
00:10:35,050 --> 00:10:37,209
我认真的希望大家来

246
00:10:37,209 --> 00:10:38,620
课堂之前阅读论文

247
00:10:38,620 --> 00:10:40,030
我也希望快速高效的读论文

248
00:10:40,030 --> 00:10:42,470
会是这堂课的一个收获

249
00:10:42,470 --> 00:10:44,940
比如跳过一些

250
00:10:44,940 --> 00:10:47,430
并不太重要的部分

251
00:10:47,430 --> 00:10:51,360
而琢磨作者重要的想法

252
00:10:51,360 --> 00:10:53,730
我们课程网站上每一个日程的链接

253
00:10:53,730 --> 00:10:56,730
都有一个思考问题

254
00:10:56,730 --> 00:10:59,160
你应该在读完每篇论文后

255
00:10:59,160 --> 00:11:00,750
回答这个问题

256
00:11:00,750 --> 00:11:02,790
最好在零点前提交

257
00:11:02,790 --> 00:11:04,020
我们也需要你在网站上提出

258
00:11:04,020 --> 00:11:08,070
关于论文的一些问题

259
00:11:08,070 --> 00:11:09,390
也可以让我思考一下我对课程的准备

260
00:11:09,390 --> 00:11:11,280
如果我有时间

261
00:11:11,280 --> 00:11:13,890
我会至少通过电子邮件

262
00:11:13,890 --> 00:11:17,280
回答一部分问题

263
00:11:17,280 --> 00:11:18,600
这些问题和回答都需要

264
00:11:18,600 --> 00:11:22,140
在零点前提交

265
00:11:22,140 --> 00:11:24,660
有两次考试

266
00:11:24,660 --> 00:11:26,850
一次是随堂期中

267
00:11:26,850 --> 00:11:32,640
大概在春假前最后一节课

268
00:11:32,640 --> 00:11:36,000
并且会在学期期末周

269
00:11:36,000 --> 00:11:37,770
迎来期末考试

270
00:11:37,770 --> 00:11:42,120
考试内容主要为论文和实验中的内容

271
00:11:42,120 --> 00:11:44,130
这是我建议最好的准备方式

272
00:11:44,130 --> 00:11:46,320
当然参加课堂授课

273
00:11:46,320 --> 00:11:49,230
阅读论文

274
00:11:49,230 --> 00:11:51,360
应该是大家这20年

275
00:11:51,360 --> 00:11:55,680
准备期末考的好方法

276
00:11:55,680 --> 00:11:57,240
你们应该可以了解

277
00:11:57,240 --> 00:11:58,710
我会在考试中

278
00:11:58,710 --> 00:12:01,350
提出哪一类问题

279
00:12:01,350 --> 00:12:03,170
因为我们不可避免地会读到

280
00:12:03,170 --> 00:12:05,550
一些重复的论文

281
00:12:05,550 --> 00:12:08,910
会有一些类似的问题

282
00:12:08,910 --> 00:12:15,420
出现在历年的题目中

283
00:12:15,420 --> 00:12:17,490
关于四次实验

284
00:12:17,490 --> 00:12:25,650
第一次实验需要在下周五前完成

285
00:12:25,650 --> 00:12:31,980
这是一个简单的MapReduce实验

286
00:12:31,980 --> 00:12:33,810
根据你们在论文中读到的来写

287
00:12:33,810 --> 00:12:35,100
我们几分钟后会讨论

288
00:12:35,100 --> 00:12:36,050
这篇论文

289
00:12:36,050 --> 00:12:40,320
第二个实验使用Raft算法

290
00:12:40,320 --> 00:12:43,620
为了实现容错

291
00:12:43,620 --> 00:12:47,190
这是一个理论上

292
00:12:47,190 --> 00:12:49,680
通过复制来让系统容错的算法

293
00:12:49,680 --> 00:12:51,210
这就是Raft算法

294
00:12:51,210 --> 00:12:53,850
他管理复制

295
00:12:53,850 --> 00:12:55,250
管理一种自动剔除

296
00:12:55,250 --> 00:12:57,660
有问题的副本服务器

297
00:12:57,660 --> 00:13:00,150
这个就是Raft算法的容错实验

298
00:13:00,150 --> 00:13:08,700
在第三个实验中

299
00:13:08,700 --> 00:13:11,370
你需要使用你的Raft算法实现

300
00:13:11,370 --> 00:13:18,990
来建立一个可以容错的KV服务器

301
00:13:18,990 --> 00:13:22,640
他可以完成复制并容错

302
00:13:22,640 --> 00:13:25,950
在第四个实验中你需要

303
00:13:25,950 --> 00:13:28,200
把你写的KV服务器分发到

304
00:13:28,200 --> 00:13:30,390
一系列的独立集群中

305
00:13:30,390 --> 00:13:33,870
这样你会切分你的KV存储系统

306
00:13:33,870 --> 00:13:35,160
通过这些独立的副本集群

307
00:13:35,160 --> 00:13:36,780
进行加速

308
00:13:36,780 --> 00:13:39,660
并行的对集群进行多个复制

309
00:13:39,660 --> 00:13:42,240
你同样需要负责

310
00:13:42,240 --> 00:13:47,790
不同服务期间

311
00:13:47,790 --> 00:13:50,070
许多数据块的移动

312
00:13:50,070 --> 00:13:52,500
来让他们在运行过程中不损失

313
00:13:52,500 --> 00:13:54,810
任何的数据

314
00:13:54,810 --> 00:14:03,330
我们通常把它叫做 分片式KV服务

315
00:14:03,330 --> 00:14:04,830
分片是指我们将数据放到了

316
00:14:04,830 --> 00:14:07,410
多个服务器上的多个分区

317
00:14:07,410 --> 00:14:10,290
来实现并行加速

318
00:14:10,290 --> 00:14:16,610
如果你不想做实验四

319
00:14:16,610 --> 00:14:19,740
你也可以选择你自己的项目

320
00:14:19,740 --> 00:14:21,480
如果你对分布式系统

321
00:14:21,480 --> 00:14:23,700
有一些自己的想法

322
00:14:23,700 --> 00:14:26,010
比如我们课堂上讨论到的

323
00:14:26,010 --> 00:14:27,330
某个类型的分布式系统

324
00:14:27,330 --> 00:14:28,530
或者说你有一些

325
00:14:28,530 --> 00:14:30,300
自己的追求

326
00:14:30,300 --> 00:14:32,100
并且对这个想法进行评估

327
00:14:32,100 --> 00:14:34,500
看他们能不能正确运行

328
00:14:34,500 --> 00:14:38,370
你可以选择做这个项目

329
00:14:38,370 --> 00:14:40,170
这个项目中你需要联系一些你的同学

330
00:14:40,170 --> 00:14:44,070
因为我们需要以2-3人的

331
00:14:44,070 --> 00:14:47,430
小组形式完成

332
00:14:47,430 --> 00:14:49,050
其中有人需要把想法发给我

333
00:14:49,050 --> 00:14:50,940
我来确定下是否合适

334
00:14:50,940 --> 00:14:53,580
或者是给你一些建议

335
00:14:53,580 --> 00:14:55,230
如果我觉得合适

336
00:14:55,230 --> 00:14:56,610
你也想做这个项目

337
00:14:56,610 --> 00:14:59,160
你就可以用它在本学期末

338
00:14:59,160 --> 00:15:00,870
代替实验四

339
00:15:00,870 --> 00:15:05,250
你需要做一些系统设计

340
00:15:05,250 --> 00:15:06,960
并构建一个真实的系统

341
00:15:06,960 --> 00:15:08,940
在最后一节课前演示

342
00:15:08,940 --> 00:15:11,370
同时需要交一个简短的

343
00:15:11,370 --> 00:15:12,900
关于你如何构建它的书面报告

344
00:15:12,900 --> 00:15:17,730
我会在课程网站上

345
00:15:17,730 --> 00:15:20,070
提出一些或许对你们有帮助的

346
00:15:20,070 --> 00:15:22,350
大胆的想法

347
00:15:22,350 --> 00:15:25,140
关于你应该如何构建这个项目

348
00:15:25,140 --> 00:15:27,690
当然最好的项目应该是

349
00:15:27,690 --> 00:15:30,090
你自己有一个很好的想法

350
00:15:30,090 --> 00:15:32,700
你需要选择一个

351
00:15:32,700 --> 00:15:34,920
和课程讨论内容

352
00:15:34,920 --> 00:15:36,810
相关的系统

353
00:15:36,810 --> 00:15:39,150
作为你的

354
00:15:39,150 --> 00:15:40,640
项目

355
00:15:40,640 --> 00:15:44,040
回到实验部分

356
00:15:44,040 --> 00:15:46,020
实验成绩会有一系列

357
00:15:46,020 --> 00:15:47,940
针对你代码的测试构成

358
00:15:47,940 --> 00:15:49,710
你的成绩就是在我们所有的测试中

359
00:15:49,710 --> 00:15:51,870
你通过了多少个

360
00:15:51,870 --> 00:15:55,170
我们会公开全部的测试数据

361
00:15:55,170 --> 00:15:56,850
如果你完成的实验

362
00:15:56,850 --> 00:15:58,950
可靠的通过了全部测试

363
00:15:58,950 --> 00:16:00,750
全部通过很有可能的

364
00:16:00,750 --> 00:16:02,310
除非出现一些有趣的问题

365
00:16:02,310 --> 00:16:04,650
一般来说

366
00:16:04,650 --> 00:16:06,060
只要你在运行时通过了全部测试

367
00:16:06,060 --> 00:16:07,560
你提交给我们运行也会通过全部测试

368
00:16:07,560 --> 00:16:10,320
这样就会得到满分

369
00:16:10,320 --> 00:16:11,520
希望你们不会有任何

370
00:16:11,520 --> 00:16:13,830
关于实验的问题

371
00:16:13,830 --> 00:16:18,780
我需要提醒你的是

372
00:16:18,780 --> 00:16:21,930
debug这些代码很耗时间

373
00:16:21,930 --> 00:16:23,550
因为他们是分布式系统

374
00:16:23,550 --> 00:16:26,820
他们有很多并发和通信的问题

375
00:16:26,820 --> 00:16:30,000
可能发生一些奇怪而困难的错误

376
00:16:30,000 --> 00:16:34,020
你们应该尽早开始实验

377
00:16:34,020 --> 00:16:37,380
不要在提交实验的

378
00:16:37,380 --> 00:16:39,210
最后时刻还要

379
00:16:39,210 --> 00:16:41,370
处理很多麻烦

380
00:16:41,370 --> 00:16:43,680
如果有对实验有问题

381
00:16:43,680 --> 00:16:45,780
可以在工作时间来到助教办公室

382
00:16:45,780 --> 00:16:49,080
你可以在Piazza上自由提问

383
00:16:49,080 --> 00:16:51,270
当然我也希望

384
00:16:51,270 --> 00:16:52,770
如果你知道一个问题的答案

385
00:16:52,770 --> 00:16:56,339
你可以在Piazza回答别人的提问

386
00:16:56,339 --> 00:17:04,760
还有什么关于课程的问题吗

387
00:17:10,339 --> 00:17:13,140
你问了这些部分

388
00:17:13,140 --> 00:17:15,329
在总成绩的占比是多少

389
00:17:15,329 --> 00:17:17,550
我其实不记得了

390
00:17:17,550 --> 00:17:20,180
不过你在课程网站上

391
00:17:20,180 --> 00:17:24,900
应该能找到答案

392
00:17:24,900 --> 00:17:29,570
我想实验应该是占比最大的

393
00:17:29,570 --> 00:17:36,350
那我们开始 我们这门课是

394
00:17:36,350 --> 00:17:39,780
关于应用的基础设施的

395
00:17:39,780 --> 00:17:41,460
所以即便课程中我们会

396
00:17:41,460 --> 00:17:42,809
分开说一些

397
00:17:42,809 --> 00:17:45,179
不同的应用

398
00:17:45,179 --> 00:17:47,550
别人 或者一些用户之类

399
00:17:47,550 --> 00:17:49,980
在这些基础设施上

400
00:17:49,980 --> 00:17:51,390
编写的应用

401
00:17:51,390 --> 00:17:53,160
但是我们在本课程中

402
00:17:53,160 --> 00:17:55,740
应该关注的是这些基础设施

403
00:17:55,740 --> 00:17:58,950
这些基础设施可能会

404
00:17:58,950 --> 00:18:13,620
涉及许多储存 通信

405
00:18:13,620 --> 00:18:16,920
和计算问题

406
00:18:16,920 --> 00:18:19,050
我们会讨论包含所有

407
00:18:19,050 --> 00:18:23,370
这三个部分的基础设施

408
00:18:23,370 --> 00:18:24,900
但事实证明我们最关注的

409
00:18:24,900 --> 00:18:27,990
是储存部分

410
00:18:27,990 --> 00:18:30,980
这是一个定义明确并有用的抽象概念

411
00:18:30,980 --> 00:18:32,820
并且通常比较直白

412
00:18:32,820 --> 00:18:34,320
人们对于如何构建和使用储存系统

413
00:18:34,320 --> 00:18:36,230
人们对于如何构建和使用储存系统

414
00:18:36,230 --> 00:18:40,350
包括去构建一种

415
00:18:40,350 --> 00:18:41,670
可复制容错的 高性能的分布式储存实例

416
00:18:41,670 --> 00:18:43,679
可复制容错的 高性能的分布式储存实例

417
00:18:43,679 --> 00:18:46,410
我们还会讨论一些

418
00:18:46,410 --> 00:18:48,720
我们现在正在使用的计算系统

419
00:18:48,720 --> 00:18:50,970
比如 MapReduce

420
00:18:50,970 --> 00:18:54,750
我们也会说一些

421
00:18:54,750 --> 00:18:57,120
关于通信的问题

422
00:18:57,120 --> 00:18:58,710
但是出发点是我们

423
00:18:58,710 --> 00:19:00,510
建立分布式系统所用的工具

424
00:19:00,510 --> 00:19:01,980
比如一台计算机可能

425
00:19:01,980 --> 00:19:03,750
需要通过网络相互通信

426
00:19:03,750 --> 00:19:06,330
但是可能需要保证一定的可靠性

427
00:19:06,330 --> 00:19:08,670
所以我们会提到一点

428
00:19:08,670 --> 00:19:11,970
实际上我们更多是

429
00:19:11,970 --> 00:19:12,980
使用已有的通信方式

430
00:19:12,980 --> 00:19:17,040
如果你想了解更多关于通信系统的问题

431
00:19:17,040 --> 00:19:20,780
可以参与6.829的课程

432
00:19:20,780 --> 00:19:24,750
因此对于储存和计算

433
00:19:24,750 --> 00:19:27,200
很多学习目标都是

434
00:19:27,200 --> 00:19:31,620
需要研究一些抽象方法

435
00:19:31,620 --> 00:19:34,440
比如如何简化这些

436
00:19:34,440 --> 00:19:36,660
分布式储存和计算基础设施的接口设计

437
00:19:36,660 --> 00:19:38,760
分布式储存和计算基础设施的接口设计

438
00:19:38,760 --> 00:19:40,860
我们就能以此构建应用

439
00:19:40,860 --> 00:19:43,500
最重要的是

440
00:19:43,500 --> 00:19:45,270
我们希望通过构建这种抽象的接口

441
00:19:45,270 --> 00:19:47,370
将这些分布式特性隐藏在整个系统内而不被用户感知

442
00:19:47,370 --> 00:19:51,240
将这些分布式特性隐藏在整个系统内而不被用户感知

443
00:19:51,240 --> 00:19:54,300
这是个几乎无法完全实现的梦想

444
00:19:54,300 --> 00:19:56,580
但是我们确实希望建立这样的

445
00:19:56,580 --> 00:19:58,710
一个看上去完全是非分布式系统的储存接口

446
00:19:58,710 --> 00:20:00,630
一个看上去完全是非分布式系统的储存接口

447
00:20:00,630 --> 00:20:02,310
就像一个普通的文件系统

448
00:20:02,310 --> 00:20:03,750
或者是一个大家都已经熟知如何写代码

449
00:20:03,750 --> 00:20:05,280
或者是一个大家都已经熟知如何写代码

450
00:20:05,280 --> 00:20:08,100
或者是一个大家都已经熟知如何写代码

451
00:20:08,100 --> 00:20:09,990
我们希望有一个看上去

452
00:20:09,990 --> 00:20:13,770
具有正常非分布式行为的

453
00:20:13,770 --> 00:20:17,600
文件系统和计算系统

454
00:20:17,600 --> 00:20:20,370
但是实际上其中又有着

455
00:20:20,370 --> 00:20:22,590
极高的计算性能和容错的分布式系统

456
00:20:22,590 --> 00:20:27,890
我们都需要建立这个抽象

457
00:20:30,020 --> 00:20:33,030
但是随着课程进行

458
00:20:33,030 --> 00:20:37,950
我们会知道

459
00:20:37,950 --> 00:20:39,810
很少有人能找到一个抽象

460
00:20:39,810 --> 00:20:41,820
觉有这些分布式系统的

461
00:20:41,820 --> 00:20:44,730
储存和计算特性

462
00:20:44,730 --> 00:20:49,110
又有着非分布式系统一样

463
00:20:49,110 --> 00:20:51,120
人人都能理解的

464
00:20:51,120 --> 00:20:52,920
简单的行为

465
00:20:52,920 --> 00:20:59,640
这方便我们还在尝试努力

466
00:20:59,640 --> 00:21:01,680
课程中我们会学习人们在

467
00:21:01,680 --> 00:21:03,860
建立这些抽象的过程中做的努力

468
00:21:03,860 --> 00:21:08,760
那么我们在考虑抽象时

469
00:21:08,760 --> 00:21:10,170
首先需要看一个怎样的话题呢

470
00:21:10,170 --> 00:21:13,590
第一个话题

471
00:21:13,590 --> 00:21:15,840
也是一个概括性话题

472
00:21:15,840 --> 00:21:18,690
我们会看到的很多系统

473
00:21:18,690 --> 00:21:24,920
都和他们的实现有关

474
00:21:24,920 --> 00:21:27,570
比如你看到很多人

475
00:21:27,570 --> 00:21:30,150
在构建他们的系统时会用到

476
00:21:30,150 --> 00:21:31,650
类似远程过程调用（RPC）

477
00:21:31,650 --> 00:21:32,590
类似远程过程调用（RPC）

478
00:21:32,590 --> 00:21:35,529
RPC 的目标就是

479
00:21:35,529 --> 00:21:36,970
试图掩盖我们正在

480
00:21:36,970 --> 00:21:44,850
不可靠网络上通信的事实

481
00:21:44,850 --> 00:21:49,230
另一个我们会看到的实现是线程

482
00:21:49,230 --> 00:21:51,940
这是一种编程技术

483
00:21:51,940 --> 00:21:55,029
让我们可以驾驭多核心计算机

484
00:21:55,029 --> 00:21:56,860
让我们可以驾驭多核心计算机

485
00:21:56,860 --> 00:21:58,749
但是对于本课程而言 更重要的是

486
00:21:58,749 --> 00:22:00,309
线程提供了一种结构化的并发操作方式

487
00:22:00,309 --> 00:22:03,100
线程提供了一种结构化的并发操作方式

488
00:22:03,100 --> 00:22:06,279
为的是简化程序员对这些

489
00:22:06,279 --> 00:22:09,100
并发操作的视角

490
00:22:09,100 --> 00:22:10,330
因为我们会经常用到线程

491
00:22:10,330 --> 00:22:12,279
我们知道

492
00:22:12,279 --> 00:22:13,779
在实现这个层次上

493
00:22:13,779 --> 00:22:15,159
我们需要花费许多时间

494
00:22:15,159 --> 00:22:16,840
来思考并发控制

495
00:22:16,840 --> 00:22:25,179
比如锁

496
00:22:25,179 --> 00:22:26,590
关于这些实现思想会在课程中涉及

497
00:22:26,590 --> 00:22:28,600
我们也会在许多论文里看到

498
00:22:28,600 --> 00:22:30,190
但是你需要在实验里面对大多数这些问题

499
00:22:30,190 --> 00:22:31,869
但是你需要在实验里面对大多数这些问题

500
00:22:31,869 --> 00:22:34,210
你需要构建分布式系统统

501
00:22:34,210 --> 00:22:35,710
如何进行分布式系统的编程

502
00:22:35,710 --> 00:22:38,080
就像很多大家都知道的重要工具一样

503
00:22:38,080 --> 00:22:41,080
就像很多大家都知道的重要工具一样

504
00:22:41,080 --> 00:22:43,659
当然不是普通的编程

505
00:22:43,659 --> 00:22:45,009
这是一些你构建分布式系统

506
00:22:45,009 --> 00:22:50,279
需要使用的关键工具

507
00:22:50,279 --> 00:22:54,129
另一个重要主题

508
00:22:54,129 --> 00:22:55,389
很多论文里都会提到的：性能

509
00:22:55,389 --> 00:23:05,440
构建分布式系统的更高目标

510
00:23:05,440 --> 00:23:07,570
是具有人们所谓的 可扩展的速度提升

511
00:23:07,570 --> 00:23:11,850
是具有人们所谓的 可扩展的速度提升

512
00:23:11,850 --> 00:23:17,460
我们正在努力提高可扩展性

513
00:23:17,460 --> 00:23:21,039
我这里说的可扩展性 和

514
00:23:21,039 --> 00:23:23,529
可扩展的速度提升 指的是

515
00:23:23,529 --> 00:23:26,110
如果我用一台计算机解决了一些问题

516
00:23:26,110 --> 00:23:29,559
当我买第二台计算机

517
00:23:29,559 --> 00:23:31,779
去计算这个问题时

518
00:23:31,779 --> 00:23:34,090
只要一半的时间

519
00:23:34,090 --> 00:23:37,450
或者说比如说是每分钟内

520
00:23:37,450 --> 00:23:39,850
可以解决两倍数量的问题

521
00:23:39,850 --> 00:23:42,340
两台计算机有两倍算力 就是我说的可扩展性

522
00:23:42,340 --> 00:23:44,320
两台计算机有两倍算力 就是我说的可扩展性

523
00:23:44,320 --> 00:23:47,560
（板书）2 x 计算资源数量

524
00:23:47,560 --> 00:23:54,090
可以得到两倍的性能 或者说吞吐量

525
00:23:54,090 --> 00:24:01,090
可以得到两倍的性能 或者说吞吐量

526
00:24:01,090 --> 00:24:02,920
这是一个很强的工具

527
00:24:02,920 --> 00:24:05,170
如果你真的构建了一个系统

528
00:24:05,170 --> 00:24:07,330
只要提高几倍的机器的数量

529
00:24:07,330 --> 00:24:08,830
只要提高几倍的机器的数量

530
00:24:08,830 --> 00:24:12,190
系统就能同样提高几倍的性能或者吞吐量

531
00:24:12,190 --> 00:24:14,650
系统就能同样提高几倍的性能或者吞吐量

532
00:24:14,650 --> 00:24:17,890
这是一个巨大的胜利

533
00:24:17,890 --> 00:24:21,010
因为只要有钱就可以为所欲为买计算机

534
00:24:21,010 --> 00:24:23,410
就能达到这种效果

535
00:24:23,410 --> 00:24:27,040
这种性能的提升

536
00:24:27,040 --> 00:24:28,630
否则就需要去给程序员

537
00:24:28,630 --> 00:24:31,380
付钱去重构这些软件

538
00:24:31,380 --> 00:24:33,550
来优化它的运行

539
00:24:33,550 --> 00:24:35,920
或者提供一些特殊的技术

540
00:24:35,920 --> 00:24:37,900
比如一个更好的算法之类

541
00:24:37,900 --> 00:24:39,970
或者就要花高价雇程序员

542
00:24:39,970 --> 00:24:42,940
来修补这些代码

543
00:24:42,940 --> 00:24:45,460
从而提高运行速度

544
00:24:45,460 --> 00:24:47,590
我们都希望比如从十台计算机

545
00:24:47,590 --> 00:24:49,690
提升到一千台计算机

546
00:24:49,690 --> 00:24:51,610
就能扛住一百倍的流量

547
00:24:51,610 --> 00:24:53,740
那这也太棒了

548
00:24:53,740 --> 00:24:56,830
因此当人们构建一个

549
00:24:56,830 --> 00:24:58,060
巨大的购物网站的时候

550
00:24:58,060 --> 00:24:59,560
有一整栋楼的计算机在运行

551
00:24:59,560 --> 00:25:01,600
他们共同完成网站的运行

552
00:25:01,600 --> 00:25:04,510
这是一个很棒的

553
00:25:04,510 --> 00:25:06,670
可扩展性的思路

554
00:25:06,670 --> 00:25:09,610
但是另一方面

555
00:25:09,610 --> 00:25:12,040
你需要仔细设计系统

556
00:25:12,040 --> 00:25:13,450
才能获得这样的性能

557
00:25:13,450 --> 00:25:19,780
呃 我在课程中可能会画图

558
00:25:19,780 --> 00:25:21,910
比如我们来看这样一个图

559
00:25:21,910 --> 00:25:23,530
比如我们来看这样一个图

560
00:25:23,530 --> 00:25:25,480
我们假设我们在

561
00:25:25,480 --> 00:25:27,700
建立一个常规网站

562
00:25:27,700 --> 00:25:32,080
一般来说一个网站有一个 HTTP 服务器

563
00:25:32,080 --> 00:25:36,390
让我们先写一些用户

564
00:25:36,900 --> 00:25:42,190
和很多浏览器

565
00:25:42,190 --> 00:25:44,890
他们在和一台web服务器通信

566
00:25:44,890 --> 00:25:49,300
比如是Python或者PHP写的服务

567
00:25:49,300 --> 00:25:52,740
以及访问一些数据库

568
00:25:54,230 --> 00:25:56,490
网站只有一两个用户的时候

569
00:25:56,490 --> 00:25:58,620
一台计算机就可以负担

570
00:25:58,620 --> 00:26:00,720
或者是一台跑web服务

571
00:26:00,720 --> 00:26:02,399
一台跑数据库

572
00:26:02,399 --> 00:26:03,840
但是有可能你的网站

573
00:26:03,840 --> 00:26:05,340
一夜之间火了起来

574
00:26:05,340 --> 00:26:08,580
你发现可能有一亿人

575
00:26:08,580 --> 00:26:13,500
注册你网站的账户

576
00:26:13,500 --> 00:26:15,179
你怎么去维护你的网站

577
00:26:15,179 --> 00:26:17,899
一台机器承受一亿用户的流量不太可能

578
00:26:17,899 --> 00:26:20,639
当然如果做了特殊的

579
00:26:20,639 --> 00:26:24,629
劳动密集型优化除外

580
00:26:24,629 --> 00:26:27,779
但很显然你没有那个时间

581
00:26:27,779 --> 00:26:29,519
所以你要做的第一件事情

582
00:26:29,519 --> 00:26:31,110
就是购买更多的web服务器

583
00:26:31,110 --> 00:26:33,539
然后把不同用户分到不同机器上

584
00:26:33,539 --> 00:26:35,580
一些用户或者特定的用户

585
00:26:35,580 --> 00:26:37,230
去访问第一台服务器

586
00:26:37,230 --> 00:26:39,750
另一半用户则去访问第二台

587
00:26:39,750 --> 00:26:45,960
然而因为一些原因

588
00:26:45,960 --> 00:26:47,759
比如你在建立reddit这种网站

589
00:26:47,759 --> 00:26:49,440
所有的用户都需要

590
00:26:49,440 --> 00:26:51,210
最终查看相同的数据

591
00:26:51,210 --> 00:26:54,029
你所有的web服务器都开始

592
00:26:54,029 --> 00:26:55,559
和数据库通信

593
00:26:55,559 --> 00:27:01,679
当然你可以一直加web服务器

594
00:27:01,679 --> 00:27:03,029
提高后端代码并行效率

595
00:27:03,029 --> 00:27:04,259
但是如果你是在跑

596
00:27:04,259 --> 00:27:05,909
PHP或Python代码

597
00:27:05,909 --> 00:27:09,570
效率可能提高不了多少

598
00:27:09,570 --> 00:27:11,490
因为单台服务器没有提高多少效率

599
00:27:11,490 --> 00:27:12,840
在数据库这里你也要

600
00:27:12,840 --> 00:27:17,700
加同样多的机器避免问题

601
00:27:17,700 --> 00:27:20,669
但是不幸的是

602
00:27:20,669 --> 00:27:23,610
这种可扩展性很少是无限的

603
00:27:23,610 --> 00:27:25,289
这种可扩展性很少是无限的

604
00:27:25,289 --> 00:27:26,700
这个系统慢慢会变成

605
00:27:26,700 --> 00:27:29,309
你现在有了10台 20台 甚至100台web服务器

606
00:27:29,309 --> 00:27:31,379
你现在有了10台 20台 甚至100台web服务器

607
00:27:31,379 --> 00:27:33,450
都在和同一个数据库通信

608
00:27:33,450 --> 00:27:35,100
突然数据库这里成了瓶颈

609
00:27:35,100 --> 00:27:37,049
再加更多的web服务器也无济于事

610
00:27:37,049 --> 00:27:38,909
所以很少有一个

611
00:27:38,909 --> 00:27:42,710
你可以通过无限制添加服务器

612
00:27:42,710 --> 00:27:44,850
就能完全解决扩展性的问题

613
00:27:44,850 --> 00:27:46,710
随着你加了

614
00:27:46,710 --> 00:27:48,600
越来越多的机器

615
00:27:48,600 --> 00:27:51,419
机器本身的数量已经不是瓶颈了

616
00:27:51,419 --> 00:27:52,740
因为你有了很多的web服务器

617
00:27:52,740 --> 00:27:54,269
瓶颈转移到了别的地方

618
00:27:54,269 --> 00:27:56,549
我想是web服务器到数据库

619
00:27:56,549 --> 00:28:01,649
限制了性能

620
00:28:01,649 --> 00:28:03,450
实际上你不可避免地

621
00:28:03,450 --> 00:28:05,730
要做一些架构设计

622
00:28:05,730 --> 00:28:07,590
因为很少有

623
00:28:07,590 --> 00:28:09,929
这么直接的从一台数据库

624
00:28:09,929 --> 00:28:13,409
读数据的例子

625
00:28:13,409 --> 00:28:17,460
一台数据库你可以轻易排序

626
00:28:17,460 --> 00:28:19,350
但你需要重构

627
00:28:19,350 --> 00:28:23,090
把它分成多台数据库服务器

628
00:28:23,840 --> 00:28:26,840
但这同样需要大量工作

629
00:28:26,840 --> 00:28:29,309
因为他很笨重

630
00:28:29,309 --> 00:28:32,070
但是很多人确实需要这样做

631
00:28:32,070 --> 00:28:33,389
我们在本课程中

632
00:28:33,389 --> 00:28:34,889
会看到很多例子

633
00:28:34,889 --> 00:28:37,529
人们讨论的一个分布式系统

634
00:28:37,529 --> 00:28:40,860
是一个储存系统

635
00:28:40,860 --> 00:28:42,659
因为作者在运行大型网站

636
00:28:42,659 --> 00:28:45,809
并且单个服务器或者是

637
00:28:45,809 --> 00:28:49,429
储存服务器都用光了

638
00:28:49,429 --> 00:28:51,600
于是这个扩展的故事是

639
00:28:51,600 --> 00:28:56,330
我们希望可以这样简单的加钱买机器实现可扩展性

640
00:28:56,330 --> 00:28:59,100
但是这点很难实现

641
00:28:59,100 --> 00:29:01,950
于是这些设计工作

642
00:29:01,950 --> 00:29:11,879
其实会一直把这些想法推进下去

643
00:29:11,879 --> 00:29:16,249
另一个重要的话题是容错

644
00:29:22,249 --> 00:29:24,690
如果你建立了一个单机系统

645
00:29:24,690 --> 00:29:27,450
其实很好的使用单台计算机

646
00:29:27,450 --> 00:29:29,549
可以让他保持运行很多年

647
00:29:29,549 --> 00:29:31,139
就像我办公室的服务器已经

648
00:29:31,139 --> 00:29:33,529
运行了很多年而不会崩溃一样

649
00:29:33,529 --> 00:29:35,909
电脑是可靠的

650
00:29:35,909 --> 00:29:37,740
操作系统是可靠的

651
00:29:37,740 --> 00:29:39,690
我办公室的电源也是可靠的

652
00:29:39,690 --> 00:29:41,639
所以一台计算机

653
00:29:41,639 --> 00:29:43,139
正常工作很长时间

654
00:29:43,139 --> 00:29:46,590
是并不少见的

655
00:29:46,590 --> 00:29:48,149
然而如果你建立了一个

656
00:29:48,149 --> 00:29:50,820
数千台计算机组成的集群

657
00:29:50,820 --> 00:29:53,700
那么即使每台计算机可以与一千台计算机一起运行一年

658
00:29:53,700 --> 00:29:55,320
那么即使每台计算机可以与一千台计算机一起运行一年

659
00:29:55,320 --> 00:29:57,119
这也意味着这一千台计算机中

660
00:29:57,119 --> 00:30:00,029
每天大约有3台计算机故障

661
00:30:00,029 --> 00:30:02,549
所以大型分布式系统中的一个大问题是

662
00:30:02,549 --> 00:30:04,379
所以大型分布式系统中的一个大问题是

663
00:30:04,379 --> 00:30:07,830
我们把一个很罕见的错误

664
00:30:07,830 --> 00:30:10,529
我们把一个很罕见的错误

665
00:30:10,529 --> 00:30:12,179
转变成了一个在一千台的

666
00:30:12,179 --> 00:30:14,549
分布式系统中

667
00:30:14,549 --> 00:30:15,809
常见的错误

668
00:30:15,809 --> 00:30:18,029
甚至在这种集群中

669
00:30:18,029 --> 00:30:20,580
一直在发生的错误

670
00:30:20,580 --> 00:30:23,070
总有一些机器会崩溃

671
00:30:23,070 --> 00:30:24,840
或者神秘地错误运行了

672
00:30:24,840 --> 00:30:26,940
或者卡顿 执行错误任务 之类

673
00:30:26,940 --> 00:30:28,890
再有一千台计算机的网络中

674
00:30:28,890 --> 00:30:31,230
有许多的网络电缆

675
00:30:31,230 --> 00:30:33,600
许多的网络交换机

676
00:30:33,600 --> 00:30:35,100
你要知道总有人会踩着电缆

677
00:30:35,100 --> 00:30:37,200
所以这是不可靠的

678
00:30:37,200 --> 00:30:38,820
或者网络电缆掉线了

679
00:30:38,820 --> 00:30:40,740
或者某些交换机风扇坏了

680
00:30:40,740 --> 00:30:43,260
然后他们过热就不工作了

681
00:30:43,260 --> 00:30:44,850
在你构建分布式系统的过程中

682
00:30:44,850 --> 00:30:48,769
各种地方总有一些小问题

683
00:30:48,769 --> 00:30:52,559
因此这个这个分布式系统的扩容

684
00:30:52,559 --> 00:30:54,029
把一个几乎不必要考虑的小问题

685
00:30:54,029 --> 00:30:56,549
变成了一个持续不断的问题

686
00:30:56,549 --> 00:30:59,279
这意味着对错误而言

687
00:30:59,279 --> 00:31:02,070
正确回复 或者掩盖错误

688
00:31:02,070 --> 00:31:03,720
以及继续处理的能力

689
00:31:03,720 --> 00:31:05,639
必须要在架构设计时就建立

690
00:31:05,639 --> 00:31:08,899
因为错误总会发生

691
00:31:08,899 --> 00:31:12,899
毕竟为应用开发者

692
00:31:12,899 --> 00:31:14,460
提供方便的抽象接口

693
00:31:14,460 --> 00:31:16,620
是我们真正要做的

694
00:31:16,620 --> 00:31:17,639
但是我们需要构建

695
00:31:17,639 --> 00:31:19,350
尽可能多的基础设施

696
00:31:19,350 --> 00:31:21,899
才可能向应用开发者

697
00:31:21,899 --> 00:31:23,929
隐藏和掩盖

698
00:31:23,929 --> 00:31:26,460
这样每个应用开发者

699
00:31:26,460 --> 00:31:28,080
就不需要一个复杂的代码

700
00:31:28,080 --> 00:31:30,510
来处理各种各样的

701
00:31:30,510 --> 00:31:35,100
类型的错误

702
00:31:35,100 --> 00:31:37,830
比如说容错到底指什么

703
00:31:37,830 --> 00:31:41,159
这会有一些不同的概念表述

704
00:31:41,159 --> 00:31:43,559
这会有一些不同的概念表述

705
00:31:43,559 --> 00:31:46,679
但你应该明确的知道

706
00:31:46,679 --> 00:31:48,090
尽管表述有很多

707
00:31:48,090 --> 00:31:50,880
尽管表述有很多

708
00:31:50,880 --> 00:31:58,350
有一个共同的思想就是可用性

709
00:31:58,350 --> 00:32:01,470
某些系统经过精心设计

710
00:32:01,470 --> 00:32:03,929
以便在某种特定类型的错误下

711
00:32:03,929 --> 00:32:05,460
当然特定类型不可能是所有类型

712
00:32:05,460 --> 00:32:09,120
系统可以正常运行

713
00:32:09,120 --> 00:32:13,139
他们可以提供给你完整的服务

714
00:32:13,139 --> 00:32:16,409
他们可以提供给你完整的服务

715
00:32:16,409 --> 00:32:17,820
就像他们没有发生任何错误

716
00:32:17,820 --> 00:32:19,500
就像他们没有发生任何错误

717
00:32:19,500 --> 00:32:21,289
某些系统的有这样一个可用的场景

718
00:32:21,289 --> 00:32:24,149
你建立了冗余的服务

719
00:32:24,149 --> 00:32:25,950
比如说有两个备份

720
00:32:25,950 --> 00:32:28,909
即便一个备份发生了问题

721
00:32:28,909 --> 00:32:31,770
即便一个备份发生了问题

722
00:32:31,770 --> 00:32:34,530
可能另一个服务器还能正常运行

723
00:32:34,530 --> 00:32:37,050
除非这两个都发生了错误

724
00:32:37,050 --> 00:32:40,530
我们不能在这个例子中

725
00:32:40,530 --> 00:32:42,150
给出可用性的承诺

726
00:32:42,150 --> 00:32:44,670
我们的可用性都是建立在特定错误类型上的

727
00:32:44,670 --> 00:32:46,140
我们的可用性都是建立在特定错误类型上的

728
00:32:46,140 --> 00:32:48,450
这样才能继续正常服务

729
00:32:48,450 --> 00:32:50,790
如果出现了超出范围的错误

730
00:32:50,790 --> 00:32:52,730
就不再可用了

731
00:32:52,730 --> 00:32:55,080
另一种容错

732
00:32:55,080 --> 00:32:57,930
在除了可用性之外

733
00:32:57,930 --> 00:32:59,130
他们自身的可恢复性也是一方面

734
00:32:59,130 --> 00:33:06,480
他们自身的可恢复性也是一方面

735
00:33:06,480 --> 00:33:08,160
这意味着如果出现问题

736
00:33:08,160 --> 00:33:10,200
他会停止工作

737
00:33:10,200 --> 00:33:13,040
他只是单纯的不响应请求了

738
00:33:13,040 --> 00:33:15,780
等到有人来进行修复后

739
00:33:15,780 --> 00:33:17,430
在修复完成后

740
00:33:17,430 --> 00:33:19,650
如果没有发生一些更糟糕的事情

741
00:33:19,650 --> 00:33:21,900
系统将可以继续正常运行

742
00:33:21,900 --> 00:33:24,420
系统将可以继续正常运行

743
00:33:24,420 --> 00:33:25,590
这比可用性要弱一些

744
00:33:25,590 --> 00:33:27,810
因为在出现故障的组件

745
00:33:27,810 --> 00:33:29,640
被修复之前

746
00:33:29,640 --> 00:33:31,140
他不会做任何事情

747
00:33:31,140 --> 00:33:33,720
但是这一切都建立在没有损失正确性的前提下

748
00:33:33,720 --> 00:33:37,230
但是这一切都建立在没有损失正确性的前提下

749
00:33:37,230 --> 00:33:39,510
但是这一切都建立在没有损失正确性的前提下

750
00:33:39,510 --> 00:33:41,880
所以这仍然是一个重要的要求

751
00:33:41,880 --> 00:33:43,500
对于一个可恢复的系统

752
00:33:43,500 --> 00:33:45,690
你通常要在系统崩溃前做一些事情

753
00:33:45,690 --> 00:33:48,000
比如将最新日期存盘

754
00:33:48,000 --> 00:33:49,230
才能在恢复后取回来

755
00:33:49,230 --> 00:33:51,090
比如供电恢复之后

756
00:33:51,090 --> 00:33:56,010
对于一个高可用的系统

757
00:33:56,010 --> 00:33:57,870
在实际生活中

758
00:33:57,870 --> 00:34:01,890
我们为了让一个系统好用

759
00:34:01,890 --> 00:34:04,290
我们让系统保持可用

760
00:34:04,290 --> 00:34:07,350
直到一定量的错误发生

761
00:34:07,350 --> 00:34:09,149
如果有太多的错误发生

762
00:34:09,149 --> 00:34:11,668
这个系统就会停止工作

763
00:34:11,668 --> 00:34:14,820
或者停止对一切的响应

764
00:34:14,820 --> 00:34:18,870
但是一旦足够的问题被修复

765
00:34:18,870 --> 00:34:21,330
系统会继续工作

766
00:34:21,330 --> 00:34:23,429
所以一个好的高可用系统

767
00:34:23,429 --> 00:34:25,139
应该也是可恢复的

768
00:34:25,139 --> 00:34:26,820
敏感的察觉发生了很多错误

769
00:34:26,820 --> 00:34:28,469
然后停止响应

770
00:34:28,469 --> 00:34:35,520
但是在之后依旧正确工作

771
00:34:35,520 --> 00:34:38,429
我们很喜欢这一点

772
00:34:38,429 --> 00:34:43,290
我们会看到的最有效的工具是

773
00:34:43,290 --> 00:34:45,120
解决这种问题的多种方法

774
00:34:45,120 --> 00:34:47,780
解决这种问题的多种方法

775
00:34:47,780 --> 00:34:50,179
实际上在这一部分中

776
00:34:50,179 --> 00:34:52,639
最重要的工具是

777
00:34:52,639 --> 00:34:55,850
非易失性存储

778
00:34:55,850 --> 00:34:58,420
一些类似于电源崩溃故障

779
00:34:58,420 --> 00:35:01,310
即便是整栋楼的电源故障

780
00:35:01,310 --> 00:35:02,750
我们可以用非易失性存储

781
00:35:02,750 --> 00:35:05,330
像硬盘 闪存 SSD 之类的储存工具

782
00:35:05,330 --> 00:35:07,430
像硬盘 闪存 SSD 之类的储存工具

783
00:35:07,430 --> 00:35:12,680
我们存放一些检查点

784
00:35:12,680 --> 00:35:14,480
或者关于系统状态的日志

785
00:35:14,480 --> 00:35:16,760
在备用电源恢复或者故障修好了

786
00:35:16,760 --> 00:35:18,020
我们得到通知可以去

787
00:35:18,020 --> 00:35:20,510
读取最新的硬盘状态

788
00:35:20,510 --> 00:35:24,620
并且继续从那里继续操作

789
00:35:24,620 --> 00:35:29,390
（板书）非易失性存储

790
00:35:29,390 --> 00:35:31,010
于是出现了许多非易失性存储的管理工具

791
00:35:31,010 --> 00:35:32,840
于是出现了许多非易失性存储的管理工具

792
00:35:32,840 --> 00:35:35,000
因为非易失性存储更新起来很昂贵

793
00:35:35,000 --> 00:35:37,460
因此构建高性能容错系统非常繁琐

794
00:35:37,460 --> 00:35:39,140
因此构建高性能容错系统非常繁琐

795
00:35:39,140 --> 00:35:42,470
因此构建高性能容错系统非常繁琐

796
00:35:42,470 --> 00:35:45,290
所以一个聪明的方法是

797
00:35:45,290 --> 00:35:47,600
避免写入非易失性存储

798
00:35:47,600 --> 00:35:49,970
这在过去很常用

799
00:35:49,970 --> 00:35:53,000
即便在今天 写入非易失性存储

800
00:35:53,000 --> 00:35:55,790
也需要移动磁盘臂

801
00:35:55,790 --> 00:35:58,060
等待磁盘盘面旋转

802
00:35:58,060 --> 00:36:00,920
这两个过程都很缓慢

803
00:36:00,920 --> 00:36:04,220
现在3GHz的微处理器

804
00:36:04,220 --> 00:36:06,970
即便已经在闪存读写上好了很多

805
00:36:06,970 --> 00:36:08,990
即便已经在闪存读写上好了很多

806
00:36:08,990 --> 00:36:10,760
依旧会遇到很多性能不够的情况

807
00:36:10,760 --> 00:36:12,950
我们拥有的另一个重要的容错的工具

808
00:36:12,950 --> 00:36:14,360
我们拥有的另一个重要的容错的工具

809
00:36:14,360 --> 00:36:20,000
是复制

810
00:36:20,000 --> 00:36:22,760
复制的管理对你们可能有些棘手

811
00:36:22,760 --> 00:36:26,510
任何一个复制系统中

812
00:36:26,510 --> 00:36:28,490
都有一个非常关键的问题

813
00:36:28,490 --> 00:36:30,800
比如我们有两台本应该有着

814
00:36:30,800 --> 00:36:34,160
完全相同的副本的系统

815
00:36:34,160 --> 00:36:36,020
这个关键的问题就是

816
00:36:36,020 --> 00:36:38,600
这两个副本总会意外的

817
00:36:38,600 --> 00:36:41,330
偏离同步的状态 不再正确

818
00:36:41,330 --> 00:36:43,310
实际上对于任何一个设计

819
00:36:43,310 --> 00:36:45,410
我们都能看到这种

820
00:36:45,410 --> 00:36:47,780
通过使用复制实现的容错

821
00:36:47,780 --> 00:36:51,260
实验2就是一个

822
00:36:51,260 --> 00:36:53,800
通过管理管理复制实现的容错

823
00:36:53,800 --> 00:36:57,450
通过管理管理复制实现的容错

824
00:36:57,450 --> 00:37:02,359
你们会看到这非常复杂

825
00:37:03,740 --> 00:37:10,230
最后一个话题 也是一个跨领域的话题

826
00:37:10,230 --> 00:37:17,549
是一致性

827
00:37:17,549 --> 00:37:19,430
例如我们正在构建分布式存储系统

828
00:37:19,430 --> 00:37:22,079
例如我们正在构建分布式存储系统

829
00:37:22,079 --> 00:37:24,420
假设这是一个键/值服务(KV服务)

830
00:37:24,420 --> 00:37:26,609
它只支持两种操作

831
00:37:26,609 --> 00:37:29,819
一个是「放入」(Put)

832
00:37:29,819 --> 00:37:33,089
提供一个key和一个value放入

833
00:37:33,089 --> 00:37:36,210
系统背后可能是一个

834
00:37:36,210 --> 00:37:38,069
通过一个大型的表之类

835
00:37:38,069 --> 00:37:40,079
实现了这种操作

836
00:37:40,079 --> 00:37:43,920
另一个是「取出」(Get)

837
00:37:43,920 --> 00:37:47,250
你用客户端发送一个key

838
00:37:47,250 --> 00:37:49,530
储存服务找到这个key对应的value

839
00:37:49,530 --> 00:37:50,819
作为返回值发回来

840
00:37:50,819 --> 00:37:52,799
除了KV系统之外

841
00:37:52,799 --> 00:37:54,780
我很难找到把别的例子作为

842
00:37:54,780 --> 00:37:56,490
分布式系统的例子

843
00:37:56,490 --> 00:38:00,480
这是一个还不错的例子

844
00:38:00,480 --> 00:38:01,950
这个例子也很实用

845
00:38:01,950 --> 00:38:05,309
这可以算是一种

846
00:38:05,309 --> 00:38:09,299
简单版本的储存系统

847
00:38:09,299 --> 00:38:11,700
当然如果你是以为应用程序员

848
00:38:11,700 --> 00:38:15,150
如果对这两个操作有解释

849
00:38:15,150 --> 00:38:16,799
是非常有帮助的

850
00:38:16,799 --> 00:38:18,630
你可以去查手册

851
00:38:18,630 --> 00:38:21,299
手册会向你解释

852
00:38:21,299 --> 00:38:23,520
以及你正确调用Get后

853
00:38:23,520 --> 00:38:25,530
它会返回什么

854
00:38:25,530 --> 00:38:28,109
以及正确的调用Put后 这很棒

855
00:38:28,109 --> 00:38:29,430
因为它们的含义对应着某种规范

856
00:38:29,430 --> 00:38:31,440
没有这些关于Put/Get的描述

857
00:38:31,440 --> 00:38:32,880
你又应该怎么写代码呢

858
00:38:32,880 --> 00:38:35,250
你又应该怎么写代码呢

859
00:38:35,250 --> 00:38:38,369
这就是我们关于一致性的话题

860
00:38:38,369 --> 00:38:40,200
以及为何这是一个

861
00:38:40,200 --> 00:38:42,329
在分布式系统中有趣的话题

862
00:38:42,329 --> 00:38:46,200
处于性能和容错两方面考虑

863
00:38:46,200 --> 00:38:48,299
处于性能和容错两方面考虑

864
00:38:48,299 --> 00:38:50,400
我们通常有多个数据副本

865
00:38:50,400 --> 00:38:53,880
我们通常有多个数据副本

866
00:38:53,880 --> 00:38:55,500
所以在一个非分布式系统中

867
00:38:55,500 --> 00:38:59,130
我们只有一台服务器一张表

868
00:38:59,130 --> 00:39:02,579
他们通常（虽然也不总是）

869
00:39:02,579 --> 00:39:04,200
是没有相对而言没有歧义的

870
00:39:04,200 --> 00:39:05,940
当你做 Put Get 的时候

871
00:39:05,940 --> 00:39:07,360
一般就是正确的

872
00:39:07,360 --> 00:39:08,980
你知道Put操作就是

873
00:39:08,980 --> 00:39:10,870
更新这个表

874
00:39:10,870 --> 00:39:12,550
Get操作就是从当前版本的表里取回值

875
00:39:12,550 --> 00:39:17,050
但是在分布式系统中

876
00:39:17,050 --> 00:39:18,640
数据可能有超过一个副本

877
00:39:18,640 --> 00:39:20,590
可能是因为复制或缓存的原因

878
00:39:20,590 --> 00:39:23,890
可能是因为复制或缓存的原因

879
00:39:23,890 --> 00:39:30,130
于是有了很多个不同版本的KV对出现

880
00:39:30,130 --> 00:39:32,380
于是有了很多个不同版本的KV对出现

881
00:39:32,380 --> 00:39:34,030
如果其中有一个客户端

882
00:39:34,030 --> 00:39:36,910
Put进了一个新的副本

883
00:39:36,910 --> 00:39:43,030
在服务器就有了两个副本

884
00:39:43,030 --> 00:39:48,070
（板书）他们都有KV表

885
00:39:48,070 --> 00:39:51,550
比如两个表1对应的值是20

886
00:39:51,550 --> 00:39:55,360
比如两个表1对应的值是20

887
00:39:55,360 --> 00:39:58,990
这里有一个客户端

888
00:39:58,990 --> 00:40:00,310
他希望更新

889
00:40:00,310 --> 00:40:03,490
把1对应的值改成了21

890
00:40:03,490 --> 00:40:04,960
比如这可能是一个计数器

891
00:40:04,960 --> 00:40:09,550
于是他发送一个Put

892
00:40:09,550 --> 00:40:13,750
Key为1 Value为21

893
00:40:13,750 --> 00:40:15,840
他发送给了第一台服务器

894
00:40:15,840 --> 00:40:18,010
他需要同步每一个副本

895
00:40:18,010 --> 00:40:20,380
就在他正准备给第二台服务器

896
00:40:20,380 --> 00:40:22,300
发送同样的请求时

897
00:40:22,300 --> 00:40:23,530
这个客户端崩溃了

898
00:40:23,530 --> 00:40:26,950
可能是电源故障

899
00:40:26,950 --> 00:40:28,690
或者操作系统bug之类

900
00:40:28,690 --> 00:40:30,640
现在留下了一个不太好的状态

901
00:40:30,640 --> 00:40:35,470
我们发送的Put值更新了

902
00:40:35,470 --> 00:40:37,300
两个副本中一个的状态

903
00:40:37,300 --> 00:40:38,590
一个是21 另一个仍是20

904
00:40:38,590 --> 00:40:40,870
现在有人来尝试用一个Get来读取

905
00:40:40,870 --> 00:40:42,910
他们想要得到Key为1对应的值

906
00:40:42,910 --> 00:40:45,070
他们想要得到Key为1对应的值

907
00:40:45,070 --> 00:40:46,420
他们可能得到了21或者20

908
00:40:46,420 --> 00:40:48,100
这取决于他们的请求

909
00:40:48,100 --> 00:40:50,350
发送到了哪个服务器

910
00:40:50,350 --> 00:40:52,600
即便始终把第一台服务器放在首位

911
00:40:52,600 --> 00:40:53,830
我们构建容错系统时

912
00:40:53,830 --> 00:40:56,020
实际规则应该是

913
00:40:56,020 --> 00:40:58,000
你先去请求第一台服务器

914
00:40:58,000 --> 00:41:00,810
遇到某些情况再请求下面这台

915
00:41:00,810 --> 00:41:03,640
所以不管怎么说 你有总有一天

916
00:41:03,640 --> 00:41:06,610
有风险遇到陈旧的数据副本

917
00:41:06,610 --> 00:41:08,650
很有可能的是

918
00:41:08,650 --> 00:41:10,630
许多的Get都得到了21

919
00:41:10,630 --> 00:41:12,730
但是比如下周突然有一个Get

920
00:41:12,730 --> 00:41:14,920
请求到了一周前的旧数据

921
00:41:14,920 --> 00:41:19,370
这就会导致不一致

922
00:41:19,370 --> 00:41:23,720
这显然是会发生的

923
00:41:23,720 --> 00:41:25,870
我们总会有不小心

924
00:41:25,870 --> 00:41:29,210
所以我们需要实际写下

925
00:41:29,210 --> 00:41:32,420
关于Put和Get操作的一些规则

926
00:41:32,420 --> 00:41:33,920
关于Put和Get操作的一些规则

927
00:41:33,920 --> 00:41:36,650
就像在这种危险的复制中

928
00:41:36,650 --> 00:41:39,230
实际上

929
00:41:39,230 --> 00:41:42,650
关于一致性的不同定义有很多

930
00:41:42,650 --> 00:41:47,030
许多听起来相对直白

931
00:41:47,030 --> 00:41:48,470
许多听起来相对直白

932
00:41:48,470 --> 00:41:52,940
比如我这里说的

933
00:41:52,940 --> 00:41:55,250
Put一定要是一个完整的Put

934
00:41:55,250 --> 00:42:00,170
这就是所谓的强一致性

935
00:42:00,170 --> 00:42:02,960
这就是所谓的强一致性

936
00:42:02,960 --> 00:42:05,390
事实证明 构建一个

937
00:42:05,390 --> 00:42:06,740
相对弱的一致性也很有用

938
00:42:06,740 --> 00:42:08,660
比如说

939
00:42:08,660 --> 00:42:11,990
我们不保证任何类似Get的操作

940
00:42:11,990 --> 00:42:15,170
可以看到最新的Put写入的值

941
00:42:15,170 --> 00:42:18,440
（板书）强一致性

942
00:42:18,440 --> 00:42:23,030
（板书）强一致性

943
00:42:23,030 --> 00:42:25,130
是可以保证Get得到最新的Put的版本

944
00:42:25,130 --> 00:42:27,290
是可以保证Get得到最新的Put的版本

945
00:42:27,290 --> 00:42:28,820
当然还有很多别的工作要做

946
00:42:28,820 --> 00:42:32,180
另一方面还有弱一致性

947
00:42:32,180 --> 00:42:33,830
对于弱一致性系统

948
00:42:33,830 --> 00:42:36,650
他们不会做任何保证

949
00:42:36,650 --> 00:42:38,870
这些保证可能是

950
00:42:38,870 --> 00:42:41,690
某个人做了Put

951
00:42:41,690 --> 00:42:43,610
你可能看不到这个Put的结果 而是旧的值

952
00:42:43,610 --> 00:42:45,740
你可能看不到这个Put的结果 而是旧的值

953
00:42:45,740 --> 00:42:49,070
甚至可能在一个无限的时间里都是这样

954
00:42:49,070 --> 00:42:51,290
人们之所以对弱一致性感兴趣

955
00:42:51,290 --> 00:42:53,860
人们之所以对弱一致性方案感兴趣

956
00:42:53,860 --> 00:42:57,020
因为强一致性虽然可以

957
00:42:57,020 --> 00:43:00,860
让我看到的就是

958
00:43:00,860 --> 00:43:02,690
保证是最新的值

959
00:43:02,690 --> 00:43:07,190
但是这个实现可能很昂贵

960
00:43:07,190 --> 00:43:08,810
因为这意味着

961
00:43:08,810 --> 00:43:10,490
总有部分需要做很多的通信

962
00:43:10,490 --> 00:43:12,470
来完成某一种强一致性概念的实现

963
00:43:12,470 --> 00:43:14,180
来完成某一种强一致性概念的实现

964
00:43:14,180 --> 00:43:16,450
如果你有多个副本

965
00:43:16,450 --> 00:43:20,750
这意味着不管是写入还是读取

966
00:43:20,750 --> 00:43:22,490
都需要询问每一个副本

967
00:43:22,490 --> 00:43:26,330
比如在我们的例子中

968
00:43:26,330 --> 00:43:28,340
我们要知道客户端崩溃了

969
00:43:28,340 --> 00:43:30,470
更新了一个值 但另一个没更新

970
00:43:30,470 --> 00:43:31,820
如果我们要实现强一致性

971
00:43:31,820 --> 00:43:33,710
有一个简单的方法是

972
00:43:33,710 --> 00:43:35,210
让客户端同时读取两个副本

973
00:43:35,210 --> 00:43:37,010
如果有一个更大一些

974
00:43:37,010 --> 00:43:39,560
那这个就是最新的值

975
00:43:39,560 --> 00:43:41,270
我们这样就找到了

976
00:43:41,270 --> 00:43:44,870
但这十分昂贵

977
00:43:44,870 --> 00:43:49,640
客户端要很多交流才得到一个值

978
00:43:49,640 --> 00:43:51,620
所以为了尽可能地避免通信

979
00:43:51,620 --> 00:43:54,680
特别是副本隔得足够远

980
00:43:54,680 --> 00:43:56,810
人们会建立一个弱一致性系统

981
00:43:56,810 --> 00:43:59,480
在这种情况下

982
00:43:59,480 --> 00:44:02,840
它实际上允许读取这个旧的值

983
00:44:02,840 --> 00:44:05,540
当然为了让弱一致性更有用

984
00:44:05,540 --> 00:44:08,980
人们还会定义许多语义

985
00:44:08,980 --> 00:44:10,370
我们这里其实是一个通信问题

986
00:44:10,370 --> 00:44:13,420
强一致性需要更昂贵的通信

987
00:44:13,420 --> 00:44:16,850
强一致性需要更昂贵的通信

988
00:44:16,850 --> 00:44:19,370
这会让人陷入麻烦

989
00:44:19,370 --> 00:44:21,500
如果我们把副本用于容错

990
00:44:21,500 --> 00:44:24,530
我们实际上希望他们可以

991
00:44:24,530 --> 00:44:26,600
有着不同的故障概率

992
00:44:26,600 --> 00:44:29,210
也就是不相关的故障

993
00:44:29,210 --> 00:44:31,850
比如

994
00:44:31,850 --> 00:44:34,850
把所有的副本放在同一个机房的

995
00:44:34,850 --> 00:44:37,100
同一个机架上

996
00:44:37,100 --> 00:44:38,360
这可能是一个糟糕的主意

997
00:44:38,360 --> 00:44:39,830
因为如果有人绊倒了

998
00:44:39,830 --> 00:44:42,410
那台机架的电源线

999
00:44:42,410 --> 00:44:44,090
我们的两个副本都会完蛋

1000
00:44:44,090 --> 00:44:46,190
因为它们都连接到同一

1001
00:44:46,190 --> 00:44:49,730
机架中的同一电源线上了

1002
00:44:49,730 --> 00:44:53,240
因此，为了使副本

1003
00:44:53,240 --> 00:44:54,980
尽可能独立且容错

1004
00:44:54,980 --> 00:44:57,860
以获得良好的容错能力

1005
00:44:57,860 --> 00:45:00,320
人们希望将不同的副本尽可能地分开远放

1006
00:45:00,320 --> 00:45:02,960
例如放在不同的城市

1007
00:45:02,960 --> 00:45:05,210
或大陆的相对的两侧

1008
00:45:05,210 --> 00:45:07,100
这样，能摧毁一个数据中心的地震

1009
00:45:07,100 --> 00:45:09,260
就极不可能

1010
00:45:09,260 --> 00:45:11,840
也摧毁另一个作为备份的数据中心

1011
00:45:11,840 --> 00:45:15,860
如大家所知，我们希望

1012
00:45:15,860 --> 00:45:17,420
能够做到这一点，如果你这样做

1013
00:45:17,420 --> 00:45:20,660
那么另一个副本是在数千

1014
00:45:20,660 --> 00:45:23,660
英里开外

1015
00:45:23,660 --> 00:45:26,480
按光传播的速度来算，它可能会耗费

1016
00:45:26,480 --> 00:45:28,550
几毫秒或几十毫秒

1017
00:45:28,550 --> 00:45:31,670
与横跨洲际的数据中心进行通信

1018
00:45:31,670 --> 00:45:33,380
与横跨洲际的数据中心进行通信

1019
00:45:33,380 --> 00:45:36,590
只为更新数据的另一个副本

1020
00:45:36,590 --> 00:45:38,450
这使得通信

1021
00:45:38,450 --> 00:45:40,610
需要强一致性和

1022
00:45:40,610 --> 00:45:42,350
高一致性，极可能非常耗时

1023
00:45:42,350 --> 00:45:44,450
就像每次你想要执行其中一项put操作一样

1024
00:45:44,450 --> 00:45:45,319
就像每次你想要执行其中一项put操作一样

1025
00:45:45,319 --> 00:45:46,999
又或者取决于你如何实现它

1026
00:45:46,999 --> 00:45:49,099
你可能必须坐在那里

1027
00:45:49,099 --> 00:45:50,509
等待10或20或30毫秒

1028
00:45:50,509 --> 00:45:52,940
去同时通信到两个

1029
00:45:52,940 --> 00:45:54,650
数据中心的副本，用来确保

1030
00:45:54,650 --> 00:45:56,749
它们都已更新或已被检查

1031
00:45:56,749 --> 00:46:01,359
以便获得最新的副本

1032
00:46:01,359 --> 00:46:04,039
那当然耗损巨大

1033
00:46:04,039 --> 00:46:06,079
这可是机器上的10或20或30毫秒

1034
00:46:06,079 --> 00:46:07,789
毕竟（用这些时间）我可以执行约十亿

1035
00:46:07,789 --> 00:46:09,499
每秒的指令数，故而我们浪费了

1036
00:46:09,499 --> 00:46:11,539
过多的潜在可执行指令

1037
00:46:11,539 --> 00:46:14,509
在我们等待人们用比较差的系统时

1038
00:46:14,509 --> 00:46:16,009
你只能更新

1039
00:46:16,009 --> 00:46:17,779
仅向你轮询的

1040
00:46:17,779 --> 00:46:20,089
最近的副本，我的意思是

1041
00:46:20,089 --> 00:46:23,140
现实世界的很多学术研究

1042
00:46:23,140 --> 00:46:26,839
都在研究如何构建

1043
00:46:26,839 --> 00:46:28,099
弱一致性保证，那样他们

1044
00:46:28,099 --> 00:46:30,380
对应用程序才真正有用，以及如何

1045
00:46:30,380 --> 00:46:31,759
利用它们来

1046
00:46:31,759 --> 00:46:36,349
实质性获得高性能

1047
00:46:36,349 --> 00:46:40,150
这些就是本课程中技术思想的快速预览

1048
00:46:40,150 --> 00:46:43,729
这些就是本课程中技术思想的快速预览

1049
00:46:43,729 --> 00:46:46,339
有没有对刚才所讲的内容不懂的

1050
00:46:46,339 --> 00:46:50,869
在我讲MapReduce之前，好吧

1051
00:46:50,869 --> 00:46:54,049
我想切换到MapReduce（的内容）

1052
00:46:54,049 --> 00:46:55,519
主要是详细案例研究

1053
00:46:55,519 --> 00:46:57,949
这些案例实际上会阐明

1054
00:46:57,949 --> 00:47:02,420
我们现在在这里所讲内容的大部分思想

1055
00:47:02,420 --> 00:47:07,779
现在有一个系统

1056
00:47:07,779 --> 00:47:11,989
该系统由Google 设计，构造和使用

1057
00:47:11,989 --> 00:47:15,140
我认为这篇论文可以追溯到2004年

1058
00:47:15,140 --> 00:47:17,269
那时他们面临的问题是

1059
00:47:17,269 --> 00:47:20,900
他们要在TB级的数据上进行大量计算

1060
00:47:20,900 --> 00:47:22,759
他们要在TB级的数据上进行大量计算

1061
00:47:22,759 --> 00:47:27,170
比如创建所有网页内容的索引

1062
00:47:27,170 --> 00:47:29,660
或分析整个网络的链接结构

1063
00:47:29,660 --> 00:47:32,359
或分析整个网络的链接结构

1064
00:47:32,359 --> 00:47:35,029
以便识别出最重要的页面或

1065
00:47:35,029 --> 00:47:37,219
最权威的页面，正如大家知道的那样

1066
00:47:37,219 --> 00:47:39,140
那时，整个网络甚至有

1067
00:47:39,140 --> 00:47:45,079
数十TB的数据，构建

1068
00:47:45,079 --> 00:47:47,029
网络索引基本上等于

1069
00:47:47,029 --> 00:47:49,729
跑遍所有的数据

1070
00:47:49,729 --> 00:47:52,069
大家知道，这些相当

1071
00:47:52,069 --> 00:47:55,339
耗时，还有对整个内容进行排序

1072
00:47:55,339 --> 00:47:56,630
就像我一直用

1073
00:47:56,630 --> 00:47:58,130
单台电脑那样

1074
00:47:58,130 --> 00:47:59,990
要花多长时间，但，你知道

1075
00:47:59,990 --> 00:48:01,940
那（可能是）几周，几个月或几年，甚至更多

1076
00:48:01,940 --> 00:48:04,309
Google当时是

1077
00:48:04,309 --> 00:48:06,200
极其渴望能

1078
00:48:06,200 --> 00:48:08,539
在数以千计的计算机上进行巨型数据计算

1079
00:48:08,539 --> 00:48:10,670
以便

1080
00:48:10,670 --> 00:48:12,980
计算可以快速完成

1081
00:48:12,980 --> 00:48:14,210
对他们来说购买大量计算机是值得的

1082
00:48:14,210 --> 00:48:16,400
那样他们的工程师

1083
00:48:16,400 --> 00:48:17,720
就不必浪费很多时间

1084
00:48:17,720 --> 00:48:19,519
在看报纸或看其他东西上

1085
00:48:19,519 --> 00:48:22,039
在等待他们的大型计算任务完成时

1086
00:48:22,039 --> 00:48:27,410
所以，有一段时间，他们让他们的

1087
00:48:27,410 --> 00:48:29,630
聪明的工程师，手写

1088
00:48:29,630 --> 00:48:30,619
如果你需要写一个网站

1089
00:48:30,619 --> 00:48:32,930
索引器或某种Lincoln支出

1090
00:48:32,930 --> 00:48:35,809
眨眼分析工具

1091
00:48:35,809 --> 00:48:37,130
Google买了电脑，他们那时说

1092
00:48:37,130 --> 00:48:38,599
工程师确实会写

1093
00:48:38,599 --> 00:48:39,890
但他们从不写你在电脑上喜欢的任何软件

1094
00:48:39,890 --> 00:48:41,269
但他们从不写你在电脑上喜欢的任何软件

1095
00:48:41,269 --> 00:48:44,230
他们费力写那种一次性的

1096
00:48:44,230 --> 00:48:46,279
手动咬合的软件

1097
00:48:46,279 --> 00:48:47,660
来入手他们正在解决的任何问题

1098
00:48:47,660 --> 00:48:49,609
所以以某种方式将其分包到大量

1099
00:48:49,609 --> 00:48:51,470
电脑上，管理

1100
00:48:51,470 --> 00:48:56,809
运算，再取回数据，如果你

1101
00:48:56,809 --> 00:48:58,539
只雇用熟练分布式系统专家的工程师

1102
00:48:58,539 --> 00:49:01,789
就够了

1103
00:49:01,789 --> 00:49:04,190
尽管即使那样也很

1104
00:49:04,190 --> 00:49:07,490
浪费工程任务量，但他们

1105
00:49:07,490 --> 00:49:09,289
想雇用有其他方面特长的人

1106
00:49:09,289 --> 00:49:15,009
不一定是

1107
00:49:15,160 --> 00:49:16,910
想把所有时间花在

1108
00:49:16,910 --> 00:49:18,559
编写分布式系统软件的工程师

1109
00:49:18,559 --> 00:49:20,359
他们实际上需要某种

1110
00:49:20,359 --> 00:49:22,309
框架，那将很容易

1111
00:49:22,309 --> 00:49:26,089
让他们的工程师

1112
00:49:26,089 --> 00:49:28,130
写出他们想做的任何分析的内容

1113
00:49:28,130 --> 00:49:30,140
诸如排序算法、网络索引

1114
00:49:30,140 --> 00:49:32,990
链接分析器或其他任何的东西

1115
00:49:32,990 --> 00:49:34,549
就写写那个应用程序的内容

1116
00:49:34,549 --> 00:49:36,740
但无法在数千个电脑上运行它

1117
00:49:36,740 --> 00:49:39,710
不用考虑

1118
00:49:39,710 --> 00:49:41,539
如何在数千台计算机上分发任务的详细信息

1119
00:49:41,539 --> 00:49:43,730
如何在数千台计算机上分发任务的详细信息

1120
00:49:43,730 --> 00:49:45,950
如何组织所有的数据移动也是必需（考虑）的

1121
00:49:45,950 --> 00:49:48,349
如何应对不可避免的错误

1122
00:49:48,349 --> 00:49:50,630
于是他们找寻

1123
00:49:50,630 --> 00:49:52,009
易于使用的框架

1124
00:49:52,009 --> 00:49:54,740
让非专家也能够撰写和

1125
00:49:54,740 --> 00:50:00,319
运行巨型分布式计算

1126
00:50:00,319 --> 00:50:03,609
这就是MapReduce的全部意义

1127
00:50:03,609 --> 00:50:06,470
设计思想是程序员只

1128
00:50:06,470 --> 00:50:09,930
编写应用程序，设计师

1129
00:50:09,930 --> 00:50:12,000
分布式计算的使用者

1130
00:50:12,000 --> 00:50:14,369
我就能写简单的Map

1131
00:50:14,369 --> 00:50:16,079
函数和简单的Reduce函数

1132
00:50:16,079 --> 00:50:18,240
即使不知道任何分布式相关的内容

1133
00:50:18,240 --> 00:50:20,640
MapReduce框架

1134
00:50:20,640 --> 00:50:25,079
会处理剩下的

1135
00:50:25,079 --> 00:50:27,869
什么是MapReduce的抽象视图

1136
00:50:27,869 --> 00:50:30,900
取决于它启动时是否假设

1137
00:50:30,900 --> 00:50:33,030
有一些输入，这些输入

1138
00:50:33,030 --> 00:50:35,430
以某种方式被分成一堆

1139
00:50:35,430 --> 00:50:37,559
不同的文件或块

1140
00:50:37,559 --> 00:50:43,109
我们假设

1141
00:50:43,109 --> 00:50:51,119
输入文件一，放入文件二，依此类推

1142
00:50:51,119 --> 00:50:54,240
这些输入也许是

1143
00:50:54,240 --> 00:50:55,920
从网上抓取的网页或更

1144
00:50:55,920 --> 00:50:58,020
可能是包含了许多网站的大文件

1145
00:50:58,020 --> 00:51:00,180
每个都包含许多

1146
00:51:00,180 --> 00:51:03,420
从网上抓取的网页文件

1147
00:51:03,420 --> 00:51:04,819
MapReduce启动的方式

1148
00:51:04,819 --> 00:51:07,950
是你要查找Map函数

1149
00:51:07,950 --> 00:51:09,660
MapReduce框架

1150
00:51:09,660 --> 00:51:15,890
会在每个输入文件上运行Map函数

1151
00:51:15,890 --> 00:51:22,200
当然可以

1152
00:51:22,200 --> 00:51:23,190
这里我们可以看到一些明显的可用的并行

1153
00:51:23,190 --> 00:51:26,970
可以并行地运行Maps

1154
00:51:26,970 --> 00:51:28,349
每个Map

1155
00:51:28,349 --> 00:51:30,059
函数只关注输入和输出

1156
00:51:30,059 --> 00:51:32,400
函数只关注输入和输出

1157
00:51:32,400 --> 00:51:33,990
Map函数输出列表

1158
00:51:33,990 --> 00:51:36,750
它将文件作为输入

1159
00:51:36,750 --> 00:51:39,750
该文件是输入数据的一部分

1160
00:51:39,750 --> 00:51:42,180
它生成一个key value对列表

1161
00:51:42,180 --> 00:51:45,619
用做输出，Map函数

1162
00:51:45,619 --> 00:51:48,510
例如，假设，我们

1163
00:51:48,510 --> 00:51:50,579
在编写最简单的MapReduce示例

1164
00:51:50,579 --> 00:51:56,400
单词计数，MapReduce的任务目标

1165
00:51:56,400 --> 00:51:58,170
是计算每个单词出现的次数

1166
00:51:58,170 --> 00:52:00,390
你的Map函数可能

1167
00:52:00,390 --> 00:52:02,819
emit key value对，其中key是

1168
00:52:02,819 --> 00:52:06,930
单词而value是1

1169
00:52:06,930 --> 00:52:08,910
对于c的每个单词，Map

1170
00:52:08,910 --> 00:52:10,410
函数会将输入分割成

1171
00:52:10,410 --> 00:52:11,760
单词或随处可见

1172
00:52:11,760 --> 00:52:14,309
它emit该单词作为key，并把1作为value

1173
00:52:14,309 --> 00:52:16,170
然后再进行整体计算

1174
00:52:16,170 --> 00:52:18,359
得出最终输出

1175
00:52:18,359 --> 00:52:21,420
也许输入1中

1176
00:52:21,420 --> 00:52:23,229
有单词a

1177
00:52:23,229 --> 00:52:26,469
和单词b

1178
00:52:26,469 --> 00:52:28,569
Map的输出将会是

1179
00:52:28,569 --> 00:52:32,680
key a value 1，key b value 1

1180
00:52:32,680 --> 00:52:35,650
也许第二个Map通信是一个文件

1181
00:52:35,650 --> 00:52:38,890
其中只有一个b

1182
00:52:38,890 --> 00:52:43,119
输出则是b 1

1183
00:52:43,119 --> 00:52:46,089
也许第三个输入中有一个a和一个c

1184
00:52:46,089 --> 00:52:50,140
我们在所有输入文件上运行Map

1185
00:52:50,140 --> 00:52:53,380
得到一个中间量

1186
00:52:53,380 --> 00:52:55,059
这篇论文中叫做

1187
00:52:55,059 --> 00:52:57,130
中间输出

1188
00:52:57,130 --> 00:53:00,420
每个Map用一组key value对作为输出

1189
00:53:00,420 --> 00:53:03,130
第二阶段的计算

1190
00:53:03,130 --> 00:53:07,059
是运行Reduces，想法是

1191
00:53:07,059 --> 00:53:09,459
MapReduce框架收集

1192
00:53:09,459 --> 00:53:12,609
每个key词的所有Map的所有实例

1193
00:53:12,609 --> 00:53:15,130
所以MapReduce框架

1194
00:53:15,130 --> 00:53:16,869
会收集所有a的（Map实例）

1195
00:53:16,869 --> 00:53:20,739
从每个Map中

1196
00:53:20,739 --> 00:53:22,599
每个key为a的key value对

1197
00:53:22,599 --> 00:53:28,289
全部都会被收集并供

1198
00:53:30,390 --> 00:53:33,069
程序员调用

1199
00:53:33,069 --> 00:53:35,529
以便寻找Reduce函数

1200
00:53:35,529 --> 00:53:38,319
然后是所有的b，收集在一起

1201
00:53:38,319 --> 00:53:39,699
当然，需要真正的收集

1202
00:53:39,699 --> 00:53:42,339
因为它们是key b的不同的实例

1203
00:53:42,339 --> 00:53:44,019
因为它们是key b的不同的实例

1204
00:53:44,019 --> 00:53:46,989
是由不同计算机上的不同Map生成的

1205
00:53:46,989 --> 00:53:48,609
所以我们不讨论

1206
00:53:48,609 --> 00:53:50,680
数据移动，我，我们要

1207
00:53:50,680 --> 00:53:53,339
收集所有b keys，把他们给

1208
00:53:53,339 --> 00:53:58,719
另一个Reduce调用

1209
00:53:58,719 --> 00:54:01,959
那把所有的b keys作为参数

1210
00:54:01,959 --> 00:54:07,630
c也一样

1211
00:54:07,630 --> 00:54:09,160
MapReduce框架给每个key安排了一个Reduce调用

1212
00:54:09,160 --> 00:54:11,769
这些key

1213
00:54:11,769 --> 00:54:17,140
出现在我们这些简单计数示例的每个数学输出中

1214
00:54:17,140 --> 00:54:19,449
出现在我们这些简单计数示例的每个数学输出中

1215
00:54:19,449 --> 00:54:23,499
所有这些Reduce必须

1216
00:54:23,499 --> 00:54:25,059
做或其中任何一个必须做的，就只是

1217
00:54:25,059 --> 00:54:28,329
计算传递给它的项目数

1218
00:54:28,329 --> 00:54:29,650
甚至不用看具体的项目

1219
00:54:29,650 --> 00:54:31,059
因为它知道每个都是

1220
00:54:31,059 --> 00:54:34,479
单词，都负责加1，即value

1221
00:54:34,479 --> 00:54:35,769
你不必看我们刚刚计数的这些value

1222
00:54:35,769 --> 00:54:36,880
你不必看我们刚刚计数的这些value

1223
00:54:36,880 --> 00:54:41,590
所以这个Reduce将输出一个a

1224
00:54:41,590 --> 00:54:44,580
然后是它的输入数量，这个Reduce

1225
00:54:44,580 --> 00:54:47,680
它会生成与之关联的key

1226
00:54:47,680 --> 00:54:50,350
然后计算其value

1227
00:54:50,350 --> 00:54:57,040
也是2，这是一个

1228
00:54:57,040 --> 00:55:01,990
典型的看起来高级别的MapReduce任务

1229
00:55:01,990 --> 00:55:07,200
为了完整性

1230
00:55:07,200 --> 00:55:09,100
一些术语

1231
00:55:09,100 --> 00:55:12,480
这整个计算称为作业（job）

1232
00:55:12,480 --> 00:55:16,900
MapReduce的每个调用都称为一个任务（task）

1233
00:55:16,900 --> 00:55:19,000
我们有整个作业

1234
00:55:19,000 --> 00:55:21,010
它由一堆map任务以及

1235
00:55:21,010 --> 00:55:27,220
一堆reduce任务组成

1236
00:55:27,220 --> 00:55:29,860
这是单词计数的一个例子

1237
00:55:29,860 --> 00:55:31,150
大家知道Map和Reduce

1238
00:55:31,150 --> 00:55:40,750
函数长什么样

1239
00:55:40,750 --> 00:55:45,130
Map函数用key和value作为参数

1240
00:55:45,130 --> 00:55:46,420
我们现在讨论的函数

1241
00:55:46,420 --> 00:55:48,070
是用普通的编程语言写的

1242
00:55:48,070 --> 00:55:51,520
诸如C ++或Java或其他各种语言

1243
00:55:51,520 --> 00:55:54,820
这使得程序员和

1244
00:55:54,820 --> 00:55:57,160
普通人都可以写这些函数

1245
00:55:57,160 --> 00:55:58,870
字数统计Map函数可以做的是分割

1246
00:55:58,870 --> 00:56:02,920
k是文件名

1247
00:56:02,920 --> 00:56:05,110
通常会被忽略，我们真正在意的是

1248
00:56:05,110 --> 00:56:07,600
文件名，而v是

1249
00:56:07,600 --> 00:56:12,250
该Map输入文件的内容，v

1250
00:56:12,250 --> 00:56:14,400
包含了所有的文本

1251
00:56:14,400 --> 00:56:21,760
我们将把v分割成单词

1252
00:56:21,760 --> 00:56:24,630
每个词

1253
00:56:30,890 --> 00:56:34,130
我们都会emit，emit需要两个参数

1254
00:56:34,130 --> 00:56:36,890
emit，只调用Map，

None
00:56:36,890 --> 00:56:38,420
make emit provided by the MapReduce
emit，只调用Map，

1256
00:56:38,420 --> 00:56:41,299
我们生成的框架

1257
00:56:41,299 --> 00:56:44,890
我们给emit传递一个key（也就是该单词）

1258
00:56:44,890 --> 00:56:49,730
和一个value（也就是字符串'1'）

1259
00:56:49,730 --> 00:56:53,089
这就是Map函数和字数统计的Map函数

1260
00:56:53,089 --> 00:56:54,859
MapReduce从字面上看

1261
00:56:54,859 --> 00:56:56,559
可能就这么简单

1262
00:56:56,559 --> 00:57:00,309
有希望做一些..

1263
00:57:00,309 --> 00:57:02,599
这个Map函数并不知道

1264
00:57:02,599 --> 00:57:04,190
任何分布式和

1265
00:57:04,190 --> 00:57:06,170
多台计算机或...事实上我们需要

1266
00:57:06,170 --> 00:57:07,970
我们需要跨网络移动数据

1267
00:57:07,970 --> 00:57:09,020
或谁知道的什么

1268
00:57:09,020 --> 00:57:13,400
这非常简单明了

1269
00:57:13,400 --> 00:57:19,549
字数统计的Reduce函数

1270
00:57:19,549 --> 00:57:21,890
Reduce被调用，记住，

1271
00:57:21,890 --> 00:57:23,329
每个Reduce都会和所有有给定key的实例一起被调用

1272
00:57:23,329 --> 00:57:25,430
每个Reduce都会和所有有给定key的实例一起被调用

1273
00:57:25,430 --> 00:57:27,170
MapReduce框架调用Reduce

1274
00:57:27,170 --> 00:57:30,079
同时调用其负责的key

1276
00:57:33,410 --> 00:57:38,390
同时调用其负责的key

1277
00:57:38,390 --> 00:57:40,640
key是单词，而value全是1

1278
00:57:40,640 --> 00:57:41,960
这里我们不关心他们，我们只是

1279
00:57:41,960 --> 00:57:44,510
关心他们有多少

1280
00:57:44,510 --> 00:57:47,420
Reduce有它自己的emit函数

1281
00:57:47,420 --> 00:57:51,200
该函数只emit一个value

1282
00:57:51,200 --> 00:57:53,779
作为最终输出，作为这个key的value

1283
00:57:53,779 --> 00:57:57,829
我们要emit这个数字的长度

1284
00:57:57,829 --> 00:58:01,789
这个数组，这就是关于，有..是..

1285
00:58:01,789 --> 00:58:04,279
MapReduce中的最简单的Reduce函数的全部

1286
00:58:04,279 --> 00:58:08,049
非常简单

1287
00:58:08,049 --> 00:58:11,480
不需要容错知识

1288
00:58:11,480 --> 00:58:15,859
或其他任何知识

1289
00:58:15,859 --> 00:58:20,529
对基本框架有什么疑惑吗

1290
00:58:27,390 --> 00:58:30,550
[音乐]

1291
00:58:36,099 --> 00:58:39,229
你的意思是你可以给出Reduce的输出

1292
00:58:39,229 --> 00:58:48,289
有点..哦是..哦是..

1293
00:58:48,289 --> 00:58:50,059
在现实生活中可以

1294
00:58:50,059 --> 00:58:53,269
在现实生活中这是日常的

1295
00:58:53,269 --> 00:58:55,939
MapReduce用户定义一个

1296
00:58:55,939 --> 00:58:58,219
MapReduce作业，需要一些输入和

1297
00:58:58,219 --> 00:59:00,169
生成一些输出

1298
00:59:00,169 --> 00:59:01,969
第二个MapReduce作业

1299
00:59:01,969 --> 00:59:03,939
做一些非常复杂的多阶段

1300
00:59:03,939 --> 00:59:08,899
分析或迭代算法

1301
00:59:08,899 --> 00:59:10,429
例如PageRank

1302
00:59:10,429 --> 00:59:13,119
Google所用的评估算法

1303
00:59:13,119 --> 00:59:16,189
估测不同的网页有多重要或多有影响力

1304
00:59:16,189 --> 00:59:18,229
估测不同的网页有多重要或多有影响力

1305
00:59:18,229 --> 00:59:21,079
迭代算法是渐进的

1306
00:59:21,079 --> 00:59:22,939
收敛于答案

1307
00:59:22,939 --> 00:59:24,439
如果你用MapReduce实现

1308
00:59:24,439 --> 00:59:26,539
我想他们最初就是这样

1309
00:59:26,539 --> 00:59:28,909
你必须多次运行MapReduce作业

1310
00:59:28,909 --> 00:59:30,619
每个输出都是

1311
00:59:30,619 --> 00:59:34,359
更新的网页列表

1312
00:59:34,359 --> 00:59:36,649
更新的内容是每个网页的价值，权重或重要性

1313
00:59:36,649 --> 00:59:38,359
得到一个输出

1314
00:59:38,359 --> 00:59:40,279
并用它作为另一个MapReduce作业的输入是很日常的

1315
00:59:40,279 --> 00:59:53,749
哦，是的，是的

1316
00:59:53,749 --> 00:59:56,029
你需要根据输出设定一些内容

1317
00:59:56,029 --> 00:59:58,279
你需要评估Reduce函数

1318
00:59:58,279 --> 00:59:59,269
在某种程度上了解

1319
00:59:59,269 --> 01:00:02,659
哦，我需要按一定格式或信息

1320
01:00:02,659 --> 01:00:05,419
所需生成数据

1321
01:00:05,419 --> 01:00:07,939
给下一个MapReduce作业，我的意思是这

1322
01:00:07,939 --> 01:00:09,229
实际上引出了一些

1323
01:00:09,229 --> 01:00:11,499
MapReduce框架的缺点

1324
01:00:11,499 --> 01:00:16,309
这很棒，如果你..

1325
01:00:16,309 --> 01:00:18,679
如果你需要运行的算法很容易

1326
01:00:18,679 --> 01:00:20,809
表达成数学形式，随后是

1327
01:00:20,809 --> 01:00:23,869
按key对数据进行洗牌

1328
01:00:23,869 --> 01:00:26,179
接着是Reduce，仅此而已

1329
01:00:26,179 --> 01:00:28,069
我的MapReduce有极好的算法

1330
01:00:28,069 --> 01:00:30,589
可以以这种形式展示

1331
01:00:30,589 --> 01:00:32,119
此外我们...每个Map都必须

1332
01:00:32,119 --> 01:00:33,400
完全独立

1333
01:00:33,400 --> 01:00:39,520
必须是纯函数性的

1334
01:00:39,520 --> 01:00:42,760
函数性函数

1335
01:00:42,760 --> 01:00:44,470
只需看看他们的参数，仅此而已

1336
01:00:44,470 --> 01:00:46,480
那就像一个限制

1337
01:00:46,480 --> 01:00:48,640
事实证明，很多人想要

1338
01:00:48,640 --> 01:00:49,990
运行更长的管道

1339
01:00:49,990 --> 01:00:51,430
涉及很多很多不同种类的

1340
01:00:51,430 --> 01:00:53,170
处理过程，并与MapReduce一起使用

1341
01:00:53,170 --> 01:00:54,370
你不得不拼装

1342
01:00:54,370 --> 01:00:58,390
多个MapReduce，不同的

1343
01:00:58,390 --> 01:01:00,730
MapReduce作业和更高级的系统

1344
01:01:00,730 --> 01:01:02,050
这些我们将在后面讨论

1345
01:01:02,050 --> 01:01:04,870
这节课更擅长让你

1346
01:01:04,870 --> 01:01:06,520
指定完整的计算管道

1347
01:01:06,520 --> 01:01:08,410
他们会做优化

1348
01:01:08,410 --> 01:01:10,900
框架实现了所有

1349
01:01:10,900 --> 01:01:13,000
你要做的事情和组织

1350
01:01:13,000 --> 01:01:15,670
更复杂有效地优化

1351
01:01:15,670 --> 01:01:19,590
更复杂的计算

1352
01:01:39,660 --> 01:01:41,650
从程序员的角度来看

1353
01:01:41,650 --> 01:01:44,080
只是Map和Reduce，从我们的角度来看

1354
01:01:44,080 --> 01:01:45,610
这将关乎

1355
01:01:45,610 --> 01:01:49,320
任务进程和任务服务器

1356
01:01:49,320 --> 01:01:53,320
他们是MapReduce框架的一部分

1357
01:01:53,320 --> 01:01:55,390
除其他情况外

1358
01:01:55,390 --> 01:02:00,000
调用Map和Reduce函数

1359
01:02:00,000 --> 01:02:01,930
是的，从我们的角度来看，我们比较关心

1360
01:02:01,930 --> 01:02:04,240
环境框架是如何组织这些的

1361
01:02:04,240 --> 01:02:06,190
环境框架是如何组织这些的

1362
01:02:06,190 --> 01:02:08,380
从程序员的角度来看

1363
01:02:08,380 --> 01:02:14,340
所有分发的内容都弄完了

1364
01:02:15,960 --> 01:02:25,150
对不起，我得..再说一遍，哦，你的意思是

1365
01:02:25,150 --> 01:02:32,170
实时数据是什么情况

1366
01:02:32,170 --> 01:02:35,440
现在有两个问题，一个是当你

1367
01:02:35,440 --> 01:02:38,020
调用Map，数据会发生什么变化，

1368
01:02:38,020 --> 01:02:42,330
另一个问题是函数怎样运行

1369
01:02:46,910 --> 01:02:50,240
实际答案是，首先

1370
01:02:50,240 --> 01:02:53,029
这些东西是如何运行

1371
01:02:53,029 --> 01:02:56,539
有许多，比如一千台服务器，实际上

1372
01:02:56,539 --> 01:02:58,190
这里需要关注的内容是在这篇论文里找出一个

1373
01:02:58,190 --> 01:03:02,660
在这个基础上，现实世界里

1374
01:03:02,660 --> 01:03:04,430
有许多

1375
01:03:04,430 --> 01:03:09,019
服务器集群，我们称它们为

1376
01:03:09,019 --> 01:03:12,410
工作服务器或工作站

1377
01:03:12,410 --> 01:03:14,660
同时也有单台master服务器

1378
01:03:14,660 --> 01:03:16,519
来管理整个计算过程

1379
01:03:16,519 --> 01:03:18,890
这时发生的情况是master

1380
01:03:18,890 --> 01:03:22,490
服务器知道有

1381
01:03:22,490 --> 01:03:24,559
许多输入文件

1382
01:03:24,559 --> 01:03:27,799
如五千个输入文件

1383
01:03:27,799 --> 01:03:29,539
通过Map分包到不同的worker服务器

1384
01:03:29,539 --> 01:03:30,890
它将消息发送给

1385
01:03:30,890 --> 01:03:34,180
worker服务器，说请运行吧

1386
01:03:34,180 --> 01:03:37,759
Map函数，在某某输入文件上

1387
01:03:37,759 --> 01:03:41,750
接着worker函数

1388
01:03:41,750 --> 01:03:43,400
MapReduce的一部分

1389
01:03:43,400 --> 01:03:47,170
非常了解MapReduce

1390
01:03:47,170 --> 01:03:50,089
会读取文件，读取输入，无论是什么

1391
01:03:50,089 --> 01:03:54,109
无论是哪个，输入文件，然后调用Map函数

1392
01:03:54,109 --> 01:03:56,599
同时以文件名value作为其函数参数

1393
01:03:56,599 --> 01:04:00,400
然后工作进程

1394
01:04:00,400 --> 01:04:02,750
会进行内部实现

1395
01:04:02,750 --> 01:04:05,960
每次Map调用emit

1396
01:04:05,960 --> 01:04:10,279
工作进程会将这些数据写到本地磁盘的文件

1397
01:04:10,279 --> 01:04:12,769
Map emits是什么情况呢

1398
01:04:12,769 --> 01:04:17,420
它们在

1399
01:04:17,420 --> 01:04:19,819
在Map worker服务器的本地磁盘上生成文件

1400
01:04:19,819 --> 01:04:21,950
累计worker上的Map生成的所有的key和value

1401
01:04:21,950 --> 01:04:26,529
累计worker上的Map生成的所有的key和value

1402
01:04:26,529 --> 01:04:30,200
在Map阶段结束时

1403
01:04:30,200 --> 01:04:32,089
留给我们的就是那些worker机器

1404
01:04:32,089 --> 01:04:35,089
每台机器有

1405
01:04:35,089 --> 01:04:37,970
一些在上面运行的Map

1406
01:04:37,970 --> 01:04:42,369
worker机器上，然后MapReduce

1407
01:04:42,369 --> 01:04:45,710
worker安排将数据移到

1408
01:04:45,710 --> 01:04:46,819
它需要的地方

1409
01:04:46,819 --> 01:04:50,240
供Reduce调用

1410
01:04:50,240 --> 01:04:53,240
在典型的大型计算中

1411
01:04:53,240 --> 01:04:55,220
Reduce指令需要

1412
01:04:55,220 --> 01:04:59,089
所有提到了key a的Map输出

1413
01:04:59,089 --> 01:05:01,559
那会变成事实的

1414
01:05:01,559 --> 01:05:04,289
这是一个简单的例子

1415
01:05:04,289 --> 01:05:08,599
但一般来说，每个Map

1416
01:05:08,599 --> 01:05:10,470
指令会生成很多

1417
01:05:10,470 --> 01:05:12,960
key，包括a的某些实例

1418
01:05:12,960 --> 01:05:15,390
所以通常，在我们

1419
01:05:15,390 --> 01:05:17,460
运行MapReduce框架的Reduce函数之前

1420
01:05:17,460 --> 01:05:20,190
是MapReduce worker

1421
01:05:20,190 --> 01:05:22,589
在我们数千台服务器中的一台上运行

1422
01:05:22,589 --> 01:05:24,269
将不得不去与

1423
01:05:24,269 --> 01:05:26,579
上千个服务器中的另外的每个单个服务器进行通信

1424
01:05:26,579 --> 01:05:28,529
说，看，我要运行Reduce

1425
01:05:28,529 --> 01:05:31,170
获取key a，请看一下

1426
01:05:31,170 --> 01:05:33,210
存储在你的磁盘上的中间Map输出

1427
01:05:33,210 --> 01:05:35,880
完成 key a 的所有实例

1428
01:05:35,880 --> 01:05:38,160
把他们通过网络发送给我

1429
01:05:38,160 --> 01:05:41,069
Reduce worker将执行指令

1430
01:05:41,069 --> 01:05:43,529
它会从每个worker获取

1431
01:05:43,529 --> 01:05:45,960
key的所有实例

1432
01:05:45,960 --> 01:05:47,400
它负责

1433
01:05:47,400 --> 01:05:50,339
master让它去做的事

1434
01:05:50,339 --> 01:05:51,839
一旦它收集完所有数据

1435
01:05:51,839 --> 01:05:55,819
它就可以调用Reduce

1436
01:05:55,819 --> 01:05:58,470
Reduce函数本身调用Reduce emit

1437
01:05:58,470 --> 01:06:01,890
Reduce emit与Map emit不同

1438
01:06:01,890 --> 01:06:04,710
Reduces emit 把输出写到

1439
01:06:04,710 --> 01:06:12,150
谷歌使用的集群文件服务中的文件里

1440
01:06:12,150 --> 01:06:14,519
这里有些东西

1441
01:06:14,519 --> 01:06:17,970
我还没提过，我没有提到

1442
01:06:17,970 --> 01:06:21,329
输入所在的位置以及

1443
01:06:21,329 --> 01:06:25,529
输出所在的位置，他们都在文件里，因为

1444
01:06:25,529 --> 01:06:28,799
一段输入，我们需要灵活性

1445
01:06:28,799 --> 01:06:31,319
需要它能在任何worker服务器上读取任意一段输入

1446
01:06:31,319 --> 01:06:34,589
也就是

1447
01:06:34,589 --> 01:06:36,799
我们需要某种网络文件系统

1448
01:06:36,799 --> 01:06:42,509
存储输入数据

1449
01:06:42,509 --> 01:06:44,099
实际上这篇论文谈到了这个，即

1450
01:06:44,099 --> 01:06:50,160
GFS或Google文件系统，而GFS是

1451
01:06:50,160 --> 01:06:51,990
集群文件系统，GFS实际上

1452
01:06:51,990 --> 01:06:54,210
在完全相同的一组worker上运行

1453
01:06:54,210 --> 01:06:56,720
这些worker servers运行MapReduce

1454
01:06:56,720 --> 01:07:00,630
输入GFS只是自动...

1455
01:07:00,630 --> 01:07:02,220
这是一个你能读取我的文件的文件系统

1456
01:07:02,220 --> 01:07:03,839
这是一个你能读取我的文件的文件系统

1457
01:07:03,839 --> 01:07:06,119
GFS会自动拆分你的任何大文件

1458
01:07:06,119 --> 01:07:08,490
将其存储在跨服务器和最大64MB的块上

1459
01:07:08,490 --> 01:07:12,320
如果你写

1460
01:07:12,320 --> 01:07:14,360
如果你查看了10 TB的已爬

1461
01:07:14,360 --> 01:07:17,750
网页内容，你只需把他们写到

1462
01:07:17,750 --> 01:07:20,120
GFS，甚至作为一个大文件

1463
01:07:20,120 --> 01:07:23,030
GFS将自动把大数据拆分成64 KB的块

1464
01:07:23,030 --> 01:07:25,010
GFS将自动把大数据拆分成64 KB的块

1465
01:07:25,010 --> 01:07:28,010
使其均匀地分布在所有

1466
01:07:28,010 --> 01:07:30,950
GFS服务器上，也就是说

1467
01:07:30,950 --> 01:07:32,510
Google提供的所有服务器都可以用

1468
01:07:32,510 --> 01:07:34,580
这非常美妙，这正是我们需要的

1469
01:07:34,580 --> 01:07:36,860
如果我们接下来要运行MapReduce任务

1470
01:07:36,860 --> 01:07:39,650
抓取的整个网站作为输入

1471
01:07:39,650 --> 01:07:42,650
数据均匀分割后

1472
01:07:42,650 --> 01:07:44,540
存储在所有的跨服务器上了

1473
01:07:44,540 --> 01:07:47,780
这意味着

1474
01:07:47,780 --> 01:07:49,940
Map worker，我们要启动

1475
01:07:49,940 --> 01:07:51,440
我们有一千台服务器

1476
01:07:51,440 --> 01:07:53,000
我们要启动一千个Map  worker

1477
01:07:53,000 --> 01:07:55,850
每个输入数据读取，1000秒

1478
01:07:55,850 --> 01:07:57,080
他们可以并行地读取

1479
01:07:57,080 --> 01:08:01,460
一千个GFS文件服务器里的数据

1480
01:08:01,460 --> 01:08:04,490
总的庞大的

1481
01:08:04,490 --> 01:08:07,730
读取吞吐量

1482
01:08:07,730 --> 01:08:10,960
一千台服务器上的

1483
01:08:20,990 --> 01:08:23,490
你可能在想也许Google

1484
01:08:23,490 --> 01:08:25,470
有一组物理机器

1485
01:08:25,470 --> 01:08:27,779
介于GFS和一组单独运行MapReduce任务的物理机器之间

1486
01:08:27,779 --> 01:08:40,489
介于GFS和一组单独运行MapReduce作业的物理机器之间

1487
01:08:40,580 --> 01:08:44,790
对，所以问题是

1488
01:08:44,790 --> 01:08:48,630
这里的箭头实际上涉及了什么内容

1489
01:08:48,630 --> 01:08:50,220
答案是实际上那是随着时间改变的

1490
01:08:50,220 --> 01:08:51,630
自Google

1491
01:08:51,630 --> 01:08:55,800
涉足这个系统后

1492
01:08:55,800 --> 01:08:58,200
在一般情况下，如果我们有

1493
01:08:58,200 --> 01:09:01,080
大文件存储在某个大网络文件系统中

1494
01:09:01,080 --> 01:09:02,880
像GFS

1495
01:09:02,880 --> 01:09:05,130
可能有点像你在Athena上使用过的AFS

1496
01:09:05,130 --> 01:09:07,229
你去跟某些数据集通信

1497
01:09:07,229 --> 01:09:09,810
你的数据在集群服务器里被拆分

1498
01:09:09,810 --> 01:09:11,040
你必须在网络上和那些服务器通信

1499
01:09:11,040 --> 01:09:12,149
你必须在网络上和那些服务器通信

1500
01:09:12,149 --> 01:09:14,580
去检索你的数据，在那种情况下

1501
01:09:14,580 --> 01:09:17,840
该箭头可能代表的是Map

1502
01:09:17,840 --> 01:09:20,520
MapReduce任务进程必须关闭

1503
01:09:20,520 --> 01:09:22,649
跨网通信到

1504
01:09:22,649 --> 01:09:25,800
正确的GFS服务器上，或者

1505
01:09:25,800 --> 01:09:28,350
存储部分输入的服务器

1506
01:09:28,350 --> 01:09:30,950
通过网络获取，连接到MapReduce

1507
01:09:30,950 --> 01:09:33,450
worker机器，传递Map

1508
01:09:33,450 --> 01:09:35,310
那当然是最一般的情况

1509
01:09:35,310 --> 01:09:37,920
以上就是MapReduce最终是

1510
01:09:37,920 --> 01:09:40,800
如何工作的

1511
01:09:40,800 --> 01:09:44,819
在这篇论文里面，如果你做了

1512
01:09:44,819 --> 01:09:45,930
那里有很多网络通信

1513
01:09:45,930 --> 01:09:47,910
你通信10TB的数据

1514
01:09:47,910 --> 01:09:49,350
我们就从他们的数据中心网络移动了10TB

1515
01:09:49,350 --> 01:09:51,600
我们就从他们的数据中心网络移动了10TB

1516
01:09:51,600 --> 01:09:54,270
数据中心

1517
01:09:54,270 --> 01:09:55,740
网络是每秒GB级的

1518
01:09:55,740 --> 01:09:57,780
但仍然需要很多时间

1519
01:09:57,780 --> 01:10:02,460
去移动数十TB的数据，为了尝试...

1520
01:10:02,460 --> 01:10:04,170
实际上在这篇2004年的论文中

1521
01:10:04,170 --> 01:10:07,350
他们最具约束力的瓶颈

1522
01:10:07,350 --> 01:10:08,850
是MapReduce系统中的网络吞吐量

1523
01:10:08,850 --> 01:10:11,610
因为它们要在网络上运行

1524
01:10:11,610 --> 01:10:13,590
如果你深读了

1525
01:10:13,590 --> 01:10:18,770
评估部分

1526
01:10:18,770 --> 01:10:24,750
他们的网络，有成千上万的

1527
01:10:24,750 --> 01:10:27,230
机器

1528
01:10:27,479 --> 01:10:30,909
他们会集成机器

1529
01:10:30,909 --> 01:10:32,920
他们会插入机器

1530
01:10:32,920 --> 01:10:35,110
机器的每个机架

1531
01:10:35,110 --> 01:10:36,519
机架的以太网交换机或者其他

1532
01:10:36,519 --> 01:10:38,110
他们全部

1533
01:10:38,110 --> 01:10:40,449
需要互相通信

1534
01:10:40,449 --> 01:10:43,989
还有路由以太网交换机

1535
01:10:43,989 --> 01:10:45,519
所有的网络交换机要与之通信

1536
01:10:45,519 --> 01:10:47,889
如果你只是

1537
01:10:47,889 --> 01:10:51,039
选择一些MapReduce worker和一些GFS服务器

1538
01:10:51,039 --> 01:10:52,960
可能最少是

1539
01:10:52,960 --> 01:10:54,880
他们之间必须跨通信的时间的一半

1540
01:10:54,880 --> 01:10:56,199
他们之间必须跨通信的时间的一半

1541
01:10:56,199 --> 01:10:58,409
这一个不会改变他们的路线

1542
01:10:58,409 --> 01:11:01,479
仅占总吞吐量的一部分

1543
01:11:01,479 --> 01:11:05,650
我忘了

1544
01:11:05,650 --> 01:11:09,909
每秒几GB，我忘记具体的数据了

1545
01:11:09,909 --> 01:11:13,590
但是当我做除法时

1546
01:11:13,590 --> 01:11:17,889
被除数是

1547
01:11:17,889 --> 01:11:19,119
路线中可用的总吞吐量

1548
01:11:19,119 --> 01:11:21,639
他们在这篇论文实验中使用的大约是2000台服务器

1549
01:11:21,639 --> 01:11:23,769
他们在这篇论文实验中使用的大约是2000台服务器

1550
01:11:23,769 --> 01:11:26,170
我得到的结论是

1551
01:11:26,170 --> 01:11:27,999
路由交换机或整个网络

1552
01:11:27,999 --> 01:11:30,610
容量的每台机器分量仅为每秒50Mb

1553
01:11:30,610 --> 01:11:36,309
在他们的设置中

1554
01:11:36,309 --> 01:11:41,530
每台机器每秒50Mb

1555
01:11:41,530 --> 01:11:43,090
看起来好像是很多50Mb

1556
01:11:43,090 --> 01:11:45,429
但实际上

1557
01:11:45,429 --> 01:11:47,440
只有非常小的一部分能比肩磁盘运行的速度

1558
01:11:47,440 --> 01:11:51,999
或者CPU运行的速度

1559
01:11:51,999 --> 01:11:53,769
他们的网络，每秒50Mb

1560
01:11:53,769 --> 01:11:56,440
有一个巨大的限制，所以他们

1561
01:11:56,440 --> 01:11:57,760
脑中坚定要

1562
01:11:57,760 --> 01:12:00,010
在论文中提到的设计中

1563
01:12:00,010 --> 01:12:02,979
避免使用网络

1564
01:12:02,979 --> 01:12:05,860
他们使用了一堆技巧

1565
01:12:05,860 --> 01:12:07,059
尽一切可能避免在网络上发送东西

1566
01:12:07,059 --> 01:12:10,570
其中之一是他们...

1567
01:12:10,570 --> 01:12:14,380
他们在同一组机器中使用gfs服务器和

1568
01:12:14,380 --> 01:12:16,809
MapReduce workers

1569
01:12:16,809 --> 01:12:19,059
他们有一千台机器

1570
01:12:19,059 --> 01:12:23,079
运行GFS

1571
01:12:23,079 --> 01:12:25,090
他们在一千台机器实现GFS服务

1572
01:12:25,090 --> 01:12:27,099
并在同一千台机器上运行MapReduce

1573
01:12:27,099 --> 01:12:29,530
并在同一千台机器上运行MapReduce

1574
01:12:29,530 --> 01:12:33,429
master分拆Map任务

1575
01:12:33,429 --> 01:12:34,630
分包到不同的worker服务器

1576
01:12:34,630 --> 01:12:39,390
那很智能

1577
01:12:39,390 --> 01:12:41,550
当它即将运行Map时

1578
01:12:41,550 --> 01:12:44,640
map读取输入文件1

1579
01:12:44,640 --> 01:12:47,790
它会从GFS中找出来哪个服务器

1580
01:12:47,790 --> 01:12:50,340
的本地磁盘中有输入文件1

1581
01:12:50,340 --> 01:12:53,070
它将把输入文件发送给Map

1582
01:12:53,070 --> 01:12:55,710
到同一机器上的MapReduce软件

1583
01:12:55,710 --> 01:12:59,190
因此默认情况下此箭头

1584
01:12:59,190 --> 01:13:01,980
实际上是读取

1585
01:13:01,980 --> 01:13:03,450
本地磁盘，并且不涉及

1586
01:13:03,450 --> 01:13:05,160
网络，这取决于

1587
01:13:05,160 --> 01:13:07,290
故障或负载或其他

1588
01:13:07,290 --> 01:13:10,020
也不可能总是那样做，但几乎所有

1589
01:13:10,020 --> 01:13:11,970
Map都会在相同的机器上运行

1590
01:13:11,970 --> 01:13:13,620
和存储数据，从而节省

1591
01:13:13,620 --> 01:13:17,400
大量时间

1592
01:13:17,400 --> 01:13:19,020
而如果在网络中移动输入，这些时间则是必须要等待的

1593
01:13:19,020 --> 01:13:22,770
他们玩的下一个窍门是

1594
01:13:22,770 --> 01:13:26,250
我提过的，Map

1595
01:13:26,250 --> 01:13:28,470
在输出存储到机器的本地磁盘之前

1596
01:13:28,470 --> 01:13:29,940
你就运行Map

1597
01:13:29,940 --> 01:13:31,860
又一次，存储Map的输出

1598
01:13:31,860 --> 01:13:33,270
不需要网络通信

1599
01:13:33,270 --> 01:13:35,480
他不是实时

1600
01:13:35,480 --> 01:13:38,000
因为输出存储在了磁盘中

1601
01:13:38,000 --> 01:13:42,360
但是我们肯定知道，不管怎样，

1602
01:13:42,360 --> 01:13:45,060
为了全部分组

1603
01:13:45,060 --> 01:13:46,980
按照MapReduce定义的方式

1604
01:13:46,980 --> 01:13:49,650
为了把与给定key关联的所有的value全部分组

1605
01:13:49,650 --> 01:13:51,510
为了把与给定key关联的所有的value全部分组

1606
01:13:51,510 --> 01:13:55,260
并将其传递给单个调用

1607
01:13:55,260 --> 01:13:57,750
在某些机器上生成（数据），这将

1608
01:13:57,750 --> 01:13:59,940
需要网络通讯

1609
01:13:59,940 --> 01:14:02,190
我们想要获取

1610
01:14:02,190 --> 01:14:03,840
所有这些，把他们给到单台

1611
01:14:03,840 --> 01:14:05,970
必须在网络上移动的机器

1612
01:14:05,970 --> 01:14:08,670
所以这个洗牌

1613
01:14:08,670 --> 01:14:11,690
keys的这种移动方式

1614
01:14:11,690 --> 01:14:14,850
最初按行存储在同一台运行Map的机器上的

1615
01:14:14,850 --> 01:14:16,740
我们实际上需要它们

1616
01:14:16,740 --> 01:14:18,780
按列存储在

1617
01:14:18,780 --> 01:14:19,800
机器上

1618
01:14:19,800 --> 01:14:22,020
负责Reduce

1619
01:14:22,020 --> 01:14:23,610
这种将行存储的变为

1620
01:14:23,610 --> 01:14:25,440
列存储的转换本质上称为

1621
01:14:25,440 --> 01:14:28,530
这篇论文称为，洗牌。它确实很需要

1622
01:14:28,530 --> 01:14:30,480
在网络上移动的每条数据

1623
01:14:30,480 --> 01:14:33,000
通过Map生成传到

1624
01:14:33,000 --> 01:14:34,470
Reduce

1625
01:14:34,470 --> 01:14:36,300
还需要它（洗牌），现在它像

1626
01:14:36,300 --> 01:14:41,870
是MapReduce代价最大的一部分

1627
01:14:51,840 --> 01:14:53,860
你是对的，你可以想象一个不同的

1628
01:14:53,860 --> 01:14:55,239
定义，在里面你有更多的

1629
01:14:55,239 --> 01:14:57,989
Reduce流。我不知道

1630
01:14:57,989 --> 01:15:00,070
我还没仔细想过这个

1631
01:15:00,070 --> 01:15:02,050
我不知道为什么...那是否可行

1632
01:15:02,050 --> 01:15:04,239
当然，至于程序员界面而言

1633
01:15:04,239 --> 01:15:06,070
目标

1634
01:15:06,070 --> 01:15:09,940
他们的第一目标是否确实是能够

1635
01:15:09,940 --> 01:15:11,980
易于编程的

1636
01:15:11,980 --> 01:15:13,989
对于只是不知道系统发生了什么的人来说

1637
01:15:13,989 --> 01:15:16,660
可能是，你知道的

1638
01:15:16,660 --> 01:15:18,460
小缺陷

1639
01:15:18,460 --> 01:15:22,660
这正是Reduce函数的样子

1640
01:15:22,660 --> 01:15:24,850
在C ++或像这样的流版

1641
01:15:24,850 --> 01:15:28,090
现在看起来的样子

1642
01:15:28,090 --> 01:15:30,190
我不知道它究竟是啥样

1643
01:15:30,190 --> 01:15:33,250
或许没这么简单

1644
01:15:33,250 --> 01:15:35,320
也许可以用那种方式做

1645
01:15:35,320 --> 01:15:37,960
实际上很多现代系统...

1646
01:15:37,960 --> 01:15:41,530
人们对现代事物了解更多

1647
01:15:41,530 --> 01:15:43,420
如MapReduce的后继者们

1648
01:15:43,420 --> 01:15:45,430
他们确实经常涉及处理

1649
01:15:45,430 --> 01:15:48,640
数据流，而不是这些

1650
01:15:48,640 --> 01:15:50,739
批处理的方法

1651
01:15:50,739 --> 01:15:52,780
从某种意义上说，有一种批处理方法

1652
01:15:52,780 --> 01:15:54,970
我们要一直等待所有数据获取完时才能处理

1653
01:15:54,970 --> 01:15:57,250
因此，首先，你必须

1654
01:15:57,250 --> 01:15:59,670
有一个有限输入的概念

1655
01:15:59,670 --> 01:16:02,170
现代系统通常确实可以处理流

1656
01:16:02,170 --> 01:16:05,980
也能够

1657
01:16:05,980 --> 01:16:08,910
充分利用MapReduce的效率

1658
01:16:08,910 --> 01:16:15,460
好吧，这就是洗牌的重点

1659
01:16:15,460 --> 01:16:17,380
好吧，这就是洗牌的重点

1660
01:16:17,380 --> 01:16:19,450
所有的网络路线是哪里发生的

1661
01:16:19,450 --> 01:16:21,040
这实际上可能有海量数据

1662
01:16:21,040 --> 01:16:23,920
如果你想要排序，如果你在

1663
01:16:23,920 --> 01:16:26,710
排序的输出和输入有相同的大小

1664
01:16:26,710 --> 01:16:29,440
排序的输出和输入有相同的大小

1665
01:16:29,440 --> 01:16:30,850
也就是

1666
01:16:30,850 --> 01:16:32,890
如果你的输入是10 TB的数据

1667
01:16:32,890 --> 01:16:34,750
你在做排序，你在这里要

1668
01:16:34,750 --> 01:16:36,220
跨网络移动10TB的数据

1669
01:16:36,220 --> 01:16:38,410
你的输出也将是10TB

1670
01:16:38,410 --> 01:16:40,780
这是量非常大的数据

1671
01:16:40,780 --> 01:16:42,430
他们确实来自任意的

1672
01:16:42,430 --> 01:16:44,140
MapReduce作业，尽管不是全部的

1673
01:16:44,140 --> 01:16:46,450
确实有些，在这些阶段，很大程度上减少数据量

1674
01:16:46,450 --> 01:16:49,690
确实有些，在这些阶段，很大程度上减少数据量

1675
01:16:49,690 --> 01:16:51,070
有人提到，哦，如果你想把

1676
01:16:51,070 --> 01:16:52,900
Reduce 的输出传给另一个

1677
01:16:52,900 --> 01:16:55,150
MapReduce作业，的确如此，那是

1678
01:16:55,150 --> 01:16:56,979
人们想做的事

1679
01:16:56,979 --> 01:16:58,389
如果Reduce的输出可能

1680
01:16:58,389 --> 01:17:00,400
像排序或网站一样巨大

1681
01:17:00,400 --> 01:17:03,400
10TB输入生成的输出

1682
01:17:03,400 --> 01:17:05,260
Reduces的输出

1683
01:17:05,260 --> 01:17:07,719
也会是10TB

1684
01:17:07,719 --> 01:17:09,249
Reduce的输出也会保存

1685
01:17:09,249 --> 01:17:12,639
在GFS里，系统将...

1686
01:17:12,639 --> 01:17:13,869
Reduce只会生成这些key

1687
01:17:13,869 --> 01:17:18,369
value对，但MapReduce框架

1688
01:17:18,369 --> 01:17:20,320
会把它们收集起来并写入

1689
01:17:20,320 --> 01:17:23,679
GFS上的巨型文件里

1690
01:17:23,679 --> 01:17:27,489
另一轮网络通讯

1691
01:17:27,489 --> 01:17:30,219
需要把每个Reduce的输出

1692
01:17:30,219 --> 01:17:33,039
弄到需要存储Reduce的GFS服务器上

1693
01:17:33,039 --> 01:17:35,229
因为你可能

1694
01:17:35,229 --> 01:17:37,959
认为他们也许用了相同的技巧

1695
01:17:37,959 --> 01:17:39,639
（就是）把输出

1696
01:17:39,639 --> 01:17:42,489
存在GFS服务器上

1697
01:17:42,489 --> 01:17:46,449
同时运行了 MapReduce worker

1698
01:17:46,449 --> 01:17:48,969
运行了 Reduce，也许他们确实那样做了

1699
01:17:48,969 --> 01:17:51,760
但是由于GFS以及

1700
01:17:51,760 --> 01:17:53,979
拆分数据以提高性能

1701
01:17:53,979 --> 01:17:55,929
也为容错保留两三份副本

1702
01:17:55,929 --> 01:17:58,030
这意味着无论你

1703
01:17:58,030 --> 01:17:59,079
需要什么去写一份数据备份

1704
01:17:59,079 --> 01:18:01,349
跨网络连接到其他服务器

1705
01:18:01,349 --> 01:18:03,070
有很多网络通信

1706
01:18:03,070 --> 01:18:05,699
这儿就有一大堆

1707
01:18:05,699 --> 01:18:08,199
而我是这个网络通信

1708
01:18:08,199 --> 01:18:09,999
在2004年，那确实限制了MapReduce的吞吐量

1709
01:18:09,999 --> 01:18:10,659
在2004年，那确实限制了MapReduce的吞吐量

1710
01:18:10,659 --> 01:18:17,679
2020年，因为网络

1711
01:18:17,679 --> 01:18:19,869
布局是一个很大的限制性因素

1712
01:18:19,869 --> 01:18:21,789
很多人们想做的事情

1713
01:18:21,789 --> 01:18:23,920
在数据中心，现代数据中心

17142
01:18:23,920 --> 01:18:26,079
网络从根本上讲要比过去快很多

1715
01:18:26,079 --> 01:18:28,959
所以大家知道

1716
01:18:28,959 --> 01:18:30,639
你现在可能会看到的典型的数据中心网络

1717
01:18:30,639 --> 01:18:32,889
实际上有很多根

1718
01:18:32,889 --> 01:18:34,329
而不是，所有数据要经过的单个根交换机

1719
01:18:34,329 --> 01:18:37,630
你可能有..

1720
01:18:37,630 --> 01:18:40,269
许多根交换机,每个机架

1721
01:18:40,269 --> 01:18:42,459
交换机与每个这种备份根交换机相连

1722
01:18:42,459 --> 01:18:44,530
交换机与每个这种备份根交换机相连

1723
01:18:44,530 --> 01:18:46,479
流量在根交换机之间分配

1724
01:18:46,479 --> 01:18:48,599
现代数据中心网络

1725
01:18:48,599 --> 01:18:52,269
具有更大的网络吞吐量

1726
01:18:52,269 --> 01:18:54,880
因为，我认为，实际上，现代

1727
01:18:54,880 --> 01:18:57,099
Google在几年前就开始停止使用MapReduce

1728
01:18:57,099 --> 01:19:00,309
但在他们停止使用之前

1729
01:19:00,309 --> 01:19:02,590
现代MapReduce

1730
01:19:02,590 --> 01:19:04,959
已不再试图在同一机器上运行Map

1731
01:19:04,959 --> 01:19:06,939
当数据在存储时

1732
01:19:06,939 --> 01:19:08,139
很高兴能从任何地方对数据进行读取

1733
01:19:08,139 --> 01:19:11,369
因为他们认为

1734
01:19:11,369 --> 01:19:16,439
那样速度非常快，好了，我们

1735
01:19:16,439 --> 01:19:18,439
没有更多的时间说MapReduce了

1736
01:19:18,439 --> 01:19:21,689
我们下周有一个lab

1737
01:19:21,689 --> 01:19:22,349
我们下周有一个lab

1738
01:19:22,349 --> 01:19:24,840
你可以自己在里面编写一些

1739
01:19:24,840 --> 01:19:27,899
简化的MapReduce，请尽情耍

1740
01:19:27,899 --> 01:19:28,349
简化的MapReduce，请尽情耍

1741
01:19:28,349 --> 01:19:32,000
周四见

