1
00:00:02,500 --> 00:00:07,370
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
今天我想谈谈 Go 语言

2
00:00:07,370 --> 00:00:08,990
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
它真的相当有趣

3
00:00:08,990 --> 00:00:10,849
在这门课中

4
00:00:10,849 --> 00:00:12,709
未来的 labs

5
00:00:12,709 --> 00:00:14,450
将使用 Go 语言来完成，所以今天我想

6
00:00:14,450 --> 00:00:17,090
花些精力关注

7
00:00:17,090 --> 00:00:19,280
在 labs 会用到的部分

8
00:00:19,280 --> 00:00:22,940
特别是在

9
00:00:22,940 --> 00:00:26,170
分布式程序中，嗯，首先

10
00:00:26,170 --> 00:00:29,600
为什么在这门课里我们要使用 Go 语言？

11
00:00:29,600 --> 00:00:32,180
事实上，我们已经使用过

12
00:00:32,180 --> 00:00:33,890
其它风格的编程语言

13
00:00:33,890 --> 00:00:35,899
非常多，比如

14
00:00:35,899 --> 00:00:38,210
Java, C#, 甚至是 Python

15
00:00:38,210 --> 00:00:40,730
这些语言提供了我们需要的工具

16
00:00:40,730 --> 00:00:42,859
我们也在这门课用使用过 C++

17
00:00:42,859 --> 00:00:47,079
并且它也能得出满意的结果

18
00:00:47,079 --> 00:00:49,010
Go 也像其它编程语言一样

19
00:00:49,010 --> 00:00:50,719
给你打包了一些非常便利的功能（特性）

20
00:00:50,719 --> 00:00:51,649
供你使用

21
00:00:51,649 --> 00:00:53,409
尤其是在多线程

22
00:00:53,409 --> 00:00:56,659
锁，以及线程间同步上，Go 都做的相当的棒！

23
00:00:56,659 --> 00:00:59,239
未来我们会大量使用这些特性

24
00:00:59,239 --> 00:01:01,789
另外 RPC package(RPC 包)也相当的方便

25
00:01:01,789 --> 00:01:04,879
它听起来好像没什么大不了的

26
00:01:04,879 --> 00:01:06,380
但是这在其它诸如 C++ 这样的语言中

27
00:01:06,380 --> 00:01:09,950
真的是个很大的包袱，用起来不尽人意

28
00:01:09,950 --> 00:01:11,210
比如说，你很难找到一个

29
00:01:11,210 --> 00:01:13,579
方便好用的 RPC 包

30
00:01:13,579 --> 00:01:14,930
当然了

31
00:01:14,930 --> 00:01:16,570
在这门课里或是

32
00:01:16,570 --> 00:01:18,409
程序中，并且在不同的机器上，我们会用它做比较

33
00:01:18,409 --> 00:01:22,610
不像 C++, Go 是类型安全

34
00:01:22,610 --> 00:01:25,100
且内存安全的语言

35
00:01:25,100 --> 00:01:27,619
想要编写一个完美的程序真的太难了

36
00:01:27,619 --> 00:01:29,180
它总是或多或少存在和内存相关的 bug

37
00:01:29,180 --> 00:01:31,340
然后导致程序产生一些奇奇怪怪的事情

38
00:01:31,340 --> 00:01:34,789
然而，Go 的垃圾回收机制

39
00:01:34,789 --> 00:01:36,320
能尽可能的帮我们消灭大量类似的 bug

40
00:01:36,320 --> 00:01:39,680
这意味着

41
00:01:39,680 --> 00:01:41,869
你再也不用身处 double free 的危险之中

42
00:01:41,869 --> 00:01:44,509
也不用再为释放正在被使用的内存而担忧

43
00:01:44,509 --> 00:01:46,340
还有一些不用的 vector

44
00:01:46,340 --> 00:01:48,859
当它不被使用时，也应该要被释放掉

45
00:01:48,859 --> 00:01:51,920
还有一些看起来不太明显的问题

46
00:01:51,920 --> 00:01:54,829
直到你接触

47
00:01:54,829 --> 00:01:56,719
这样的程序之前

48
00:01:56,719 --> 00:01:58,640
多线程协同，垃圾回收

49
00:01:58,640 --> 00:02:01,880
也是相当重要的事情之一

50
00:02:01,880 --> 00:02:03,200
在非垃圾回收型语言中

51
00:02:03,200 --> 00:02:06,109
这些都很容易出错，比如 C++

52
00:02:06,109 --> 00:02:08,899
如果你使用它(C++)编写多线程程序

53
00:02:08,899 --> 00:02:10,690
它总会出现一些让人迷惑的的问题

54
00:02:10,690 --> 00:02:13,430
这要求你需要一大本草稿本帮助你去理解

55
00:02:13,430 --> 00:02:14,190
什么时候最后一个线程

56
00:02:14,190 --> 00:02:15,660
不在使用共享对象

57
00:02:15,660 --> 00:02:17,340
因为只有

58
00:02:17,340 --> 00:02:19,530
在这个时候，你才能释放对象

59
00:02:19,530 --> 00:02:20,910
所以最终你会写很多代码

60
00:02:20,910 --> 00:02:22,620
就像许多程序员会

61
00:02:22,620 --> 00:02:24,480
自己动手写一堆代码那样

62
00:02:24,480 --> 00:02:26,580
你知道可以实现类似引用计数这样的功能

63
00:02:26,580 --> 00:02:28,470
来解决它，你也知道

64
00:02:28,470 --> 00:02:30,030
当最后一个使用对象的线程结束时（需要释放它）

65
00:02:30,030 --> 00:02:32,460
那真是相当的痛苦

66
00:02:32,460 --> 00:02:34,710
如果有垃圾回收，这些问题都将不复存在

67
00:02:34,710 --> 00:02:36,560
比如在 Go 语言中

68
00:02:36,560 --> 00:02:39,390
最后一点，这门语言比 C++ 要简单的多。

69
00:02:39,390 --> 00:02:41,460
使用 C++ 的麻烦的问题之一，比如

70
00:02:41,460 --> 00:02:44,640
你可能只是一个拼写错误

71
00:02:44,640 --> 00:02:47,250
它就可能导致编译器

72
00:02:47,250 --> 00:02:51,420
报出非常复杂的错误信息

73
00:02:51,420 --> 00:02:53,730
在 C++ 里

74
00:02:53,730 --> 00:02:56,160
尝试去理解这些

75
00:02:56,160 --> 00:02:57,510
错误信息不太值得了

76
00:02:57,510 --> 00:02:59,520
我觉得更好、更快的方法

77
00:02:59,520 --> 00:03:01,470
就是去看看出错的那一行代码

78
00:03:01,470 --> 00:03:02,670
尝试去猜测它到底是什么错误

79
00:03:02,670 --> 00:03:04,800
因为这门语言真是太复杂了

81
00:03:04,800 --> 00:03:07,140
然而 Go，你懂的

82
00:03:07,140 --> 00:03:09,710
它没有许多让人热衷的特性

83
00:03:09,710 --> 00:03:11,580
相对而言它是一门“直接了当”的语言

84
00:03:11,580 --> 00:03:14,940
Okay, 所以现在你们

85
00:03:14,940 --> 00:03:17,250
都应该看看 Go 语言教程

86
00:03:17,250 --> 00:03:19,290
如果你正在纠结关于这门语言

87
00:03:19,290 --> 00:03:21,630
你下一步应该学习什么的时候

88
00:03:21,630 --> 00:03:23,190
有一个好东西你可以看看

89
00:03:23,190 --> 00:03:25,590
名为《Effective Go》

90
00:03:25,590 --> 00:03:30,390
你可以通过互联网搜索到这本书

91
00:03:30,390 --> 00:03:33,110
好吧，现在我们谈谈多线程

92
00:03:33,110 --> 00:03:35,940
在这门课里

93
00:03:35,940 --> 00:03:39,000
为什么要关注多线程？

94
00:03:39,000 --> 00:03:41,459
线程将是在这门课中

95
00:03:41,459 --> 00:03:44,370
实现并发的重要工具

96
00:03:44,370 --> 00:03:47,340
在分布式程序中

97
00:03:47,340 --> 00:03:49,920
并发相当有意思

98
00:03:49,920 --> 00:03:52,440
比较常见的情况是

99
00:03:52,440 --> 00:03:53,820
一个程序需要同时

100
00:03:53,820 --> 00:03:55,890
和多台计算机通信

101
00:03:55,890 --> 00:03:58,230
客户端可能会同时和多台服务器通信

102
00:03:58,230 --> 00:04:00,300
一台服务器可能会同时响应

103
00:04:00,300 --> 00:04:02,430
来自不同客户端的多条请求

104
00:04:02,430 --> 00:04:04,830
我们需要一种方式来解释

105
00:04:04,830 --> 00:04:06,030
我的程序同时有 7 件不同的事情在进行

106
00:04:06,030 --> 00:04:07,410
因为它正和 7 个不同

107
00:04:07,410 --> 00:04:10,110
客户端在通信

108
00:04:10,110 --> 00:04:12,450
我想要一种简单的方式

109
00:04:12,450 --> 00:04:14,459
实现它能同时做 7 件不同的事情

110
00:04:14,459 --> 00:04:16,858
我不需要做太复杂的编程

111
00:04:16,858 --> 00:04:19,589
线程就能很好的解决它

112
00:04:19,589 --> 00:04:21,630
在 Go 的文档中

113
00:04:21,630 --> 00:04:24,419
它把线程称为 goroutine

114
00:04:24,419 --> 00:04:26,789
goroutine 真的很像

115
00:04:26,789 --> 00:04:27,880
大家所说的线程

116
00:04:27,880 --> 00:04:32,560
你可以这样来思考线程

117
00:04:32,560 --> 00:04:36,600
你有一个程序

118
00:04:36,600 --> 00:04:43,120
有一个地址空间，让我来画个小盒子

119
00:04:43,120 --> 00:04:46,060
来表示地址空间

120
00:04:46,060 --> 00:04:48,250
在这个地址空间里

121
00:04:48,250 --> 00:04:51,520
串行执行的程序是没有多个线程的

122
00:04:51,520 --> 00:04:54,550
你只有一个线程

123
00:04:54,550 --> 00:04:57,040
它在这个地址空间中执行代码

124
00:04:57,040 --> 00:05:00,100
它只有一个程序计数器，只有一套寄存器，一个栈

125
00:05:00,100 --> 00:05:02,080
这些东西就能描述

126
00:05:02,080 --> 00:05:04,180
当前的执行状态

127
00:05:04,180 --> 00:05:06,160
在一个多线程程序中，比方说 Go 程序

128
00:05:06,160 --> 00:05:09,190
你可以拥有多个线程，

129
00:05:09,190 --> 00:05:10,870
我来画些弯弯的线条来表示它

130
00:05:10,870 --> 00:05:13,480
每条线之间都是分开的

131
00:05:13,480 --> 00:05:16,120
尤其是

132
00:05:16,120 --> 00:05:17,440
如果这些线程同时执行

133
00:05:17,440 --> 00:05:19,630
那它们就分别有一个属于自己的程序计数器

134
00:05:19,630 --> 00:05:21,550
一套寄存器和一个栈

135
00:05:21,550 --> 00:05:24,220
是的，每个线程都有自己的一套东西

136
00:05:24,220 --> 00:05:26,230
自己的一套线程控制

137
00:05:26,230 --> 00:05:28,330
他们可以在程序中不同的部分

138
00:05:28,330 --> 00:05:31,810
执行每个线程

139
00:05:31,810 --> 00:05:33,310
有一个不太让人注意的细节

140
00:05:33,310 --> 00:05:35,530
每一个独立的线程都有一个栈

141
00:05:35,530 --> 00:05:41,170
线程会在这些栈上执行

142
00:05:41,170 --> 00:05:44,530
这些栈都在程序中的同一个地址空间里

143
00:05:44,530 --> 00:05:46,720
所以，即使

144
00:05:46,720 --> 00:05:47,860
每个线程都有它自己的栈

145
00:05:47,860 --> 00:05:51,220
严格来讲他们都在同一地址空间中

146
00:05:51,220 --> 00:05:52,240
如果知道正确的地址的话

147
00:05:52,240 --> 00:05:53,800
不同的线程之间

148
00:05:53,800 --> 00:05:55,960
是可以互相访问的他们的栈的

149
00:05:55,960 --> 00:05:59,050
尽管你通常不会这么干

150
00:05:59,050 --> 00:06:01,510
在 Go 中，即便在只有 main 函数的程序中

151
00:06:01,510 --> 00:06:02,890
当你首次启动程序时

152
00:06:02,890 --> 00:06:05,110
它会在 main 函数中运行

153
00:06:05,110 --> 00:06:06,490
它就是一个 goroutine，然后做完所有的事情

154
00:06:06,490 --> 00:06:14,440
好啦

155
00:06:14,440 --> 00:06:17,850
我想说的最重要的原因

156
00:06:17,850 --> 00:06:21,730
就是允许程序中不同的部分

157
00:06:21,730 --> 00:06:25,030
都能独立的

158
00:06:25,030 --> 00:06:27,550
执行不同的动作

159
00:06:27,550 --> 00:06:31,510
我常常说 IO 并发是出于历史原因

160
00:06:31,510 --> 00:06:36,580
称之为 IO 并发

161
00:06:36,580 --> 00:06:38,050
是因为在过去这个概念

162
00:06:38,050 --> 00:06:39,580
第一次被提出的时候是这样的

163
00:06:39,580 --> 00:06:41,260
你可能有一个线程

164
00:06:41,260 --> 00:06:43,240
正在等待从磁盘上读数据

166
00:06:43,240 --> 00:06:44,410
当它在等待的时候，你又想要

167
00:06:44,410 --> 00:06:46,330
另一个线程，可能用来做计算或是

168
00:06:46,330 --> 00:06:49,000
从某个磁盘的地方读取数据

169
00:06:49,000 --> 00:06:50,560
或是向网络发送一条消息并等待回复

170
00:06:50,560 --> 00:06:54,490
所以 IO 并发

171
00:06:54,490 --> 00:06:57,250
也是你使用多线程的地方之一

172
00:06:57,250 --> 00:07:00,190
比如说

173
00:07:00,190 --> 00:07:01,690
我们有一个程序

174
00:07:01,690 --> 00:07:04,090
已经启动并且通过 RPC

175
00:07:04,090 --> 00:07:06,010
请求网络上不同的服务器

176
00:07:06,010 --> 00:07:08,140
然后同时在等待多个回复

177
00:07:08,140 --> 00:07:10,570
这就是我们要解决的问题

178
00:07:10,570 --> 00:07:15,040
具体做法是

180
00:07:15,040 --> 00:07:18,790
你需要为每个 RPC 调用创建一个线程

182
00:07:18,790 --> 00:07:21,190
每个线程

183
00:07:21,190 --> 00:07:26,380
都会通过 RPC 发送 request 消息

185
00:07:26,380 --> 00:07:27,820
然后在这个位置等待

186
00:07:27,820 --> 00:07:29,320
当响应回复时

187
00:07:29,320 --> 00:07:31,330
这个线程将会继续执行

188
00:07:31,330 --> 00:07:33,220
使用多线程

189
00:07:33,220 --> 00:07:36,250
可以让我们同时发起多个网络请求

191
00:07:36,250 --> 00:07:38,440
所有线程都会等待回复

192
00:07:38,440 --> 00:07:40,690
也不是非得在同一时间去发请求

193
00:07:40,690 --> 00:07:43,090
只要它愿意，这些线程总可以做不同的事情

195
00:07:43,090 --> 00:07:49,720
不同 IO 并发活动可能会有互相重叠的部分

197
00:07:49,720 --> 00:07:55,060
也允许一个活动正在等待

198
00:07:55,060 --> 00:07:57,060
另一个活动可以继续执行

199
00:07:57,060 --> 00:08:00,330
使用多线程的另一个重要原因是多核并行

200
00:08:00,330 --> 00:08:08,680
我就写并行化吧

202
00:08:08,680 --> 00:08:10,270
我们想通过线程来达到并行化的目的

203
00:08:10,270 --> 00:08:11,890
并行化就是如果你有个多核机器

204
00:08:11,890 --> 00:08:13,540
我确定你们每个人都能用你自己的电脑做到

205
00:08:13,540 --> 00:08:15,760
如果你有一个计算繁重的工作

206
00:08:15,760 --> 00:08:17,470
它需要消耗许多 CPU 时钟

207
00:08:17,470 --> 00:08:19,150
这不是太好

208
00:08:19,150 --> 00:08:21,060
假设你的程序

209
00:08:21,060 --> 00:08:23,860
能使用机器上所有的 CPU 核

210
00:08:23,860 --> 00:08:27,580
比方说它是用 Go 写的多线程程序

212
00:08:27,580 --> 00:08:30,040
你启动了多个 goroutine

213
00:08:30,040 --> 00:08:31,570
这些 goroutine 执行一些计算密集型的任务

214
00:08:31,570 --> 00:08:33,940
比如一直在那执行一个循环，计算 pi（圆周率)的值

215
00:08:33,940 --> 00:08:38,520
直到达到机器上 cpu 核的极限

217
00:08:38,520 --> 00:08:41,260
你的线程将会真正的以并行的方式运行

218
00:08:41,260 --> 00:08:43,690
如果你启动 2 个线程代替 1 个线程

219
00:08:43,690 --> 00:08:45,750
你就能获得 2 倍的性能

220
00:08:45,750 --> 00:08:48,370
就能使用 2 倍数量的 CPU 核时钟

221
00:08:48,370 --> 00:08:51,070
对部分人来说这真的太重要了

222
00:08:51,070 --> 00:08:53,170
但是在这门课里

223
00:08:53,170 --> 00:08:54,740
这其实没什么大不了的

224
00:08:54,740 --> 00:08:57,440
我们并不会把多过精力

225
00:08:57,440 --> 00:08:59,480
放在这一类并行化上

226
00:08:59,480 --> 00:09:01,640
在现实世界中

227
00:09:01,640 --> 00:09:05,390
我们开发像服务器这样的程序

228
00:09:05,390 --> 00:09:06,890
来组成分布式系统的一部分

229
00:09:06,890 --> 00:09:09,770
有时让服务器

230
00:09:09,770 --> 00:09:11,780
能使用多线程

231
00:09:11,780 --> 00:09:13,550
能使用多核还是非常重要的

232
00:09:13,550 --> 00:09:15,140
因为往往客户端

233
00:09:15,140 --> 00:09:18,740
带给服务器的负载非常高

234
00:09:18,740 --> 00:09:22,850
okay, 所以并行化是第二个原因

235
00:09:22,850 --> 00:09:25,310
那么为什么咱们会在分布式系统中

236
00:09:25,310 --> 00:09:27,170
如此关注多线程呢

237
00:09:27,170 --> 00:09:29,540
第三个原因，但也可能不那么重要

238
00:09:29,540 --> 00:09:32,780
就是有时候

239
00:09:32,780 --> 00:09:38,630
你只是想在后台做一些事情

241
00:09:38,630 --> 00:09:42,770
比如你就想周期性的去执行它

243
00:09:42,770 --> 00:09:45,260
但你又不愿意在主线程

244
00:09:45,260 --> 00:09:47,420
插入一些检查

245
00:09:47,420 --> 00:09:49,190
比如我要做的那个动作

246
00:09:49,190 --> 00:09:51,080
它应该每秒发生一次

247
00:09:51,080 --> 00:09:52,370
就像你生火一样

248
00:09:52,370 --> 00:09:54,380
每秒都能做

249
00:09:54,380 --> 00:09:56,060
不管周期性执行做什么事情

250
00:09:56,060 --> 00:10:00,500
所以，易用性也是原因

251
00:10:00,500 --> 00:10:03,380
这里有个例子

252
00:10:03,380 --> 00:10:05,210
也是经常会遇到的情况

253
00:10:05,210 --> 00:10:07,250
比如有一个 master 服务需要

254
00:10:07,250 --> 00:10:09,350
周期性的检查它的 worker 服务是否一直存活

255
00:10:09,350 --> 00:10:10,580
因为这些 worker 之一宕机的话

256
00:10:10,580 --> 00:10:12,170
就需要把工作扔到另一台机器上去执行

257
00:10:12,170 --> 00:10:14,540
就像 MapReduce 那样

258
00:10:14,540 --> 00:10:17,420
你可以每秒、每分钟

259
00:10:17,420 --> 00:10:21,680
通过发送一条“你还活着吗？”这样的消息到 worker 服务上

261
00:10:21,680 --> 00:10:24,170
你能启动一个 goroutine

262
00:10:24,170 --> 00:10:25,700
然后执行一个死循环，sleep 1 秒后

263
00:10:25,700 --> 00:10:26,990
然后做需要周期执行的动作

264
00:10:26,990 --> 00:10:28,700
然后又 sleep 1 秒

265
00:10:28,700 --> 00:10:31,400
在后面的 lab 里，你最后将会创建这样的线程

266
00:10:31,400 --> 00:10:36,560
（提问...猜测是开启 goroutine 开销的问题）

267
00:10:36,560 --> 00:10:42,470
这个开销是值得的，是的，这个开销

268
00:10:42,470 --> 00:10:44,840
真的非常少

269
00:10:44,840 --> 00:10:46,700
这依赖于你创建多少线程

270
00:10:46,700 --> 00:10:50,150
但是如果你创建了 100 万个线程

271
00:10:50,150 --> 00:10:52,040
每个线程中执行循环，循环只 sleep 1 毫秒

272
00:10:52,040 --> 00:10:53,960
然后发送网络消息

273
00:10:53,960 --> 00:10:56,330
这可能会给你的机器带来巨大的负载

274
00:10:56,330 --> 00:10:59,200
如果你就创建了 10 个线程的话

275
00:10:59,200 --> 00:11:01,400
sleep 1 秒，然后做一点点工作

276
00:11:01,400 --> 00:11:04,850
这真的没什么大不了的

277
00:11:04,850 --> 00:11:10,019
我保证这会节约你很多时间

279
00:11:10,019 --> 00:11:13,980
你不用把各种不同的

280
00:11:13,980 --> 00:11:16,199
功能搞到一起

281
00:11:16,199 --> 00:11:19,319
放在一行代码里

282
00:11:19,319 --> 00:11:21,449
它只会消耗一点点 CPU

283
00:11:21,449 --> 00:11:26,160
如果很不幸

284
00:11:26,160 --> 00:11:27,600
你在 Labs 发现

285
00:11:27,600 --> 00:11:30,449
有些循环 sleep 的时间不够长

286
00:11:30,449 --> 00:11:32,519
或者是创建了大量的 goroutine

287
00:11:32,519 --> 00:11:35,730
也从未让他们退出

288
00:11:35,730 --> 00:11:37,589
这样 goroutine 就会越来越多

289
00:11:37,589 --> 00:11:41,329
甚至是你做的更过火

290
00:11:41,329 --> 00:11:43,680
okay，所以这些原因

291
00:11:43,680 --> 00:11:46,410
是人们喜欢线程的主要原因

292
00:11:46,410 --> 00:11:47,730
也是我们在这门课里使用多线程的原因

293
00:11:47,730 --> 00:11:50,370
关于线程大家还有什么问题吗？

294
00:11:50,370 --> 00:12:01,860
（提问：...）通过异步编程

295
00:12:01,860 --> 00:12:03,569
你的意思是通过单线程

296
00:12:03,569 --> 00:12:06,779
来追踪不同活动的状态是吗？

297
00:12:06,779 --> 00:12:09,509
yeah，这真的是个好问题

298
00:12:09,509 --> 00:12:13,439
如果不使用多线程会怎样？

300
00:12:13,439 --> 00:12:15,089
可能因为某些原因我们不想使用线程

301
00:12:15,089 --> 00:12:16,800
那么我们如何写程序？

302
00:12:16,800 --> 00:12:21,209
你知道服务器

304
00:12:21,209 --> 00:12:23,339
能够同时与不同客户端通信

305
00:12:23,339 --> 00:12:24,509
或是客户端能同时与多个服务器通信

306
00:12:24,509 --> 00:12:26,100
这时候应该使用什么样的工具？

307
00:12:26,100 --> 00:12:29,069
事实上还有另一种方式

308
00:12:29,069 --> 00:12:36,420
另一种主要风格

309
00:12:36,420 --> 00:12:40,019
这种组织程序的方式称为异步编程

312
00:12:40,019 --> 00:12:42,529
也称为事件驱动编程

313
00:12:42,529 --> 00:12:45,899
你可以使用事件驱动编程

314
00:12:45,899 --> 00:12:52,709
事件驱动编程的一般结构

316
00:12:52,709 --> 00:12:54,420
通常它有一个线程

317
00:12:54,420 --> 00:12:57,380
同时有一个循环

318
00:12:57,380 --> 00:13:01,380
这个循环等待输入

319
00:13:01,380 --> 00:13:03,779
或者是其它任何事件

320
00:13:03,779 --> 00:13:05,699
这些事件能触发程序继续进行

321
00:13:05,699 --> 00:13:07,800
事件可能是一个来自客户端的请求

322
00:13:07,800 --> 00:13:10,889
可能是定时器到期，如果你在编写

323
00:13:10,889 --> 00:13:12,629
windows 系统程序

324
00:13:12,629 --> 00:13:14,189
你电脑上的许多 windows 系统程序

325
00:13:14,189 --> 00:13:16,019
都是通过事件驱动的风格来编写的

326
00:13:16,019 --> 00:13:17,639
它们等待的东西是像键盘击键

327
00:13:17,639 --> 00:13:18,339
或者是鼠标移动这样的事件

328
00:13:18,339 --> 00:13:20,259
因此你可能会有一个单一的

329
00:13:20,259 --> 00:13:21,550
只有一个控制线程的程序

330
00:13:21,550 --> 00:13:23,350
这个线程有一个循环一直等待输入

331
00:13:23,350 --> 00:13:25,269
无论何时有输入进来

332
00:13:25,269 --> 00:13:27,160
比如收到报文，它能够找出来

333
00:13:27,160 --> 00:13:28,749
是哪个客户端发送的这个报文

334
00:13:28,749 --> 00:13:31,540
它有一张表格

335
00:13:31,540 --> 00:13:38,199
记录这个客户端到底处于什么样的活动状态

337
00:13:38,199 --> 00:13:40,509
比如说，oh 上帝，

338
00:13:40,509 --> 00:13:42,220
我现在处于“读”某个文件的状态

339
00:13:42,220 --> 00:13:44,110
那么它就会要求我去读下一个数据块

340
00:13:44,110 --> 00:13:45,850
然后我就会去读取下一个数据块然后返回

341
00:13:45,850 --> 00:13:55,480
使用线程的话

342
00:13:55,480 --> 00:13:57,249
通常会变的更加方便

343
00:13:57,249 --> 00:14:00,069
因为线程能让你更容易把把程序写的连贯有序

344
00:14:00,069 --> 00:14:03,610
你就一溜写下来几行代码

346
00:14:03,610 --> 00:14:05,649
计算，然后发送消息，然后等待响应

347
00:14:05,649 --> 00:14:09,009
这比在只有一个线程里

349
00:14:09,009 --> 00:14:16,269
把一个活动给分割成一块一块的办法要容易多了

351
00:14:16,269 --> 00:14:19,089
在事件驱动循环里

352
00:14:19,089 --> 00:14:23,379
你一次只能执行一个活动

353
00:14:23,379 --> 00:14:29,110
这种编程模式的问题在于

354
00:14:29,110 --> 00:14:32,889
它实现起来有点痛苦

356
00:14:32,889 --> 00:14:34,660
另一个潜在的缺陷

357
00:14:34,660 --> 00:14:36,639
当你用这种方法获取了 IO 并发后

358
00:14:36,639 --> 00:14:38,769
你就没法利用 CPU 的并行化机制

359
00:14:38,769 --> 00:14:39,910
所以当你写一个负载很高的服务

360
00:14:39,910 --> 00:14:42,730
你得想方设法把一台大型机器的 32 核都用上

361
00:14:42,730 --> 00:14:49,149
使用一个单一循环的话，你知道，它相当的不自然

363
00:14:49,149 --> 00:14:50,620
也很难获得多核的性能

364
00:14:50,620 --> 00:14:55,029
另一方面

365
00:14:55,029 --> 00:14:56,620
冒这样的风险编程

366
00:14:56,620 --> 00:14:59,259
通常换来的性能提升相比多线程来说并不会太多

367
00:14:59,259 --> 00:15:01,660
而且线程相对来说也很廉价

368
00:15:01,660 --> 00:15:05,379
但是每个线程都有一个栈

369
00:15:05,379 --> 00:15:07,329
栈通常是 1kb 或数千字节

370
00:15:07,329 --> 00:15:09,459
如果你有 20 个线程

371
00:15:09,459 --> 00:15:10,959
这些消耗根本不用在意

372
00:15:10,959 --> 00:15:12,970
但是你若有 100 万个线程

373
00:15:12,970 --> 00:15:14,009
那它就会消耗大量的内存

374
00:15:14,009 --> 00:15:17,769
另外，线程调度

375
00:15:17,769 --> 00:15:20,980
它是指下一步应该选择哪个线程运行

377
00:15:20,980 --> 00:15:25,899
通常有一个调度列表，上面记录了 1000 个线程

379
00:15:25,899 --> 00:15:28,420
这时候切换线程执行将付出相当昂贵的代价

380
00:15:28,420 --> 00:15:30,519
所以，当你只有一个服务器的时候

381
00:15:30,519 --> 00:15:33,520
你的服务器需要为 100 万个客户端提供服务

383
00:15:33,520 --> 00:15:37,920
你需要为这 100 万个客户端记录一些状态

385
00:15:37,920 --> 00:15:39,370
这个代价还是挺高的

386
00:15:39,370 --> 00:15:46,060
如果使用事件驱动编程，花点时间的话

388
00:15:46,060 --> 00:15:47,440
应该容易写一个

389
00:15:47,440 --> 00:15:50,560
一个简单的而又五脏俱全高性能的服务

390
00:15:50,560 --> 00:15:51,940
就是你需要多做点工作

391
00:15:51,940 --> 00:16:15,390
你是问我 JavaScript 吗？

392
00:16:15,390 --> 00:16:18,040
你这个问题我也不会

393
00:16:18,040 --> 00:16:20,950
JavaScript 有没有利用多核这个……

394
00:16:20,950 --> 00:16:25,870
有人知道吗? 这得取决于具体实现

395
00:16:25,870 --> 00:16:27,250
yeah，不过我确实不太清楚这个

396
00:16:27,250 --> 00:16:29,230
有个很自然的想法

397
00:16:29,230 --> 00:16:31,570
即使是在 Go 中

398
00:16:31,570 --> 00:16:33,400
假设你知道你的机器有 8 个核

399
00:16:33,400 --> 00:16:35,170
你想写一个世界上最高效的 server

400
00:16:35,170 --> 00:16:39,490
你可能就会启动 8 个线程

402
00:16:39,490 --> 00:16:47,350
每个线程上运行一个精简的事件驱动循环

404
00:16:47,350 --> 00:16:49,660
一个循环一个核

405
00:16:49,660 --> 00:16:54,700
对于 IO 并发来说，这是一种获得并行化的方式

407
00:16:54,700 --> 00:16:59,160
(提问)

408
00:17:05,060 --> 00:17:07,950
okay，所以你想问多线程与多进程的区别是什么对吧

410
00:17:07,950 --> 00:17:11,190
通常，对于类 UNIX 系统的机器来说

411
00:17:11,190 --> 00:17:14,880
一个进程就是一个单独运行的程序

412
00:17:14,880 --> 00:17:16,650
只有一个地址空间

413
00:17:16,650 --> 00:17:18,690
一大片可供进程使用的内存

414
00:17:18,690 --> 00:17:22,109
在这个进程里你可能同时会有好多个线程

415
00:17:22,109 --> 00:17:25,290
当你准备好一个 go 程序并运行

417
00:17:25,290 --> 00:17:31,890
将会创建一个 unix 进程和一块内存区

419
00:17:31,890 --> 00:17:35,880
当你的 Go 进程创建 goroutine 时

420
00:17:35,880 --> 00:17:37,380
它们实际上都是在同一个进程里的

421
00:17:37,380 --> 00:17:42,990
我不太确定真实的答案是不是这样

423
00:17:42,990 --> 00:17:45,360
但历史上，操作系统都提供了像这样的大盒子

424
00:17:45,360 --> 00:17:47,490
它就是个进程

425
00:17:47,490 --> 00:17:49,580
实际上这也取决于操作系统的实现

426
00:17:49,580 --> 00:17:52,050
确实有个别人或一些操作系统

427
00:17:52,050 --> 00:17:53,940
并不关心你的进程内部到底发生了什么事情

428
00:17:53,940 --> 00:17:56,550
也不关心你使用什么语言

429
00:17:56,550 --> 00:17:59,130
不关心操作系统内部的业务逻辑

430
00:17:59,130 --> 00:18:00,810
在进程内部能运行多个线程就行了

431
00:18:00,810 --> 00:18:06,630
好，如果在你的机器上运行了不止一个进程

434
00:18:06,630 --> 00:18:09,570
比如一个编辑器或是编译器

435
00:18:09,570 --> 00:18:12,360
操作系统需要让它们彼此分开

436
00:18:12,360 --> 00:18:13,620
你的编辑器和你的编译器

437
00:18:13,620 --> 00:18:15,690
都有自己的内存空间

438
00:18:15,690 --> 00:18:16,830
他们之间无法看到彼此的内存

439
00:18:16,830 --> 00:18:20,000
不同的进程之间不会有交集

441
00:18:20,000 --> 00:18:22,470
你的编辑器可能有多个线程

442
00:18:22,470 --> 00:18:24,030
你的编译器也可能有多个线程

443
00:18:24,030 --> 00:18:27,480
但是他们都处于各自的世界

444
00:18:27,480 --> 00:18:29,190
但是在同一个进程中，线程与线程之间可以共享内存

445
00:18:29,190 --> 00:18:31,890
可以使用 channel(Go语言中的概念) 进行同步

446
00:18:31,890 --> 00:18:33,720
也可以使用 mutex 等

447
00:18:33,720 --> 00:18:38,240
但进程之间是没有交集的

448
00:18:38,240 --> 00:18:45,509
这类软件的传统结构就是这样

450
00:18:45,509 --> 00:18:48,509
(提问)

451
00:18:53,370 --> 00:19:08,010
问题：当上下文切换时，是所有线程都在切换吗？（内心：这届同学有点难搞）

453
00:19:08,010 --> 00:19:10,420
okay，我们想象一下

454
00:19:10,420 --> 00:19:12,580
你只有一个单核机器

455
00:19:12,580 --> 00:19:14,530
这意味着在同一个时刻你只能做一件事情

456
00:19:14,530 --> 00:19:19,900
你这样想

457
00:19:19,900 --> 00:19:22,960
你打算在你的机器上运行多进程

459
00:19:22,960 --> 00:19:27,520
操作系统把 CPU 时间片

460
00:19:27,520 --> 00:19:33,430
反复的分配给这两个程序

462
00:19:33,430 --> 00:19:35,950
当硬件时钟到期时

463
00:19:35,950 --> 00:19:38,950
操作系统就判断是时候把 CPU 从当前正在运行的进程剥夺

465
00:19:38,950 --> 00:19:40,480
然后把 CPU 分配给另一个进程

466
00:19:40,480 --> 00:19:44,700
这件事件是在进程级别上做的

467
00:19:48,600 --> 00:19:52,330
这有点复杂，好

468
00:19:52,330 --> 00:19:55,240
让我们重新再思考这个问题

469
00:19:55,240 --> 00:20:00,070
我们使用的线程最终是由是操作系统线程所提供的

471
00:20:00,070 --> 00:20:02,080
当操作系统上下文切换时

472
00:20:02,080 --> 00:20:03,910
就是不同的线程之间产生切换时

473
00:20:03,910 --> 00:20:06,520
操作系统是知道这一切的

474
00:20:06,520 --> 00:20:08,620
所以操作系统可能会清楚

475
00:20:08,620 --> 00:20:11,560
这儿有两个线程在这个进程中，有三个线程在那个进程

477
00:20:11,560 --> 00:20:13,600
当时钟到期时

478
00:20:13,600 --> 00:20:16,870
操作系统会基于一些调度算法选择一个不同的线程来运行

480
00:20:16,870 --> 00:20:18,730
在这个进程中的线程和另一进程中的线程可能是不同的

483
00:20:22,270 --> 00:20:25,690
另外，Go 会聪明复用一个操作系统线程

484
00:20:25,690 --> 00:20:29,860
在上面运行尽可能多的 goroutine 以节省开支

486
00:20:29,860 --> 00:20:32,590
所以这可能需要两个阶段去调度

487
00:20:32,590 --> 00:20:34,480
首先操作系统选择一个线程去运行

488
00:20:34,480 --> 00:20:45,820
然后在这个进程中，Go 会再去选择哪个 goroutine 去运行

491
00:20:45,820 --> 00:20:53,409
好啦，线程真的很方便

492
00:20:53,409 --> 00:20:55,919
大多数时候，使用它

493
00:20:55,409 --> 00:20:59,919
就能让你在每个线程中写出非常普通、连贯的代码

495
00:20:59,919 --> 00:21:15,149
然而，事实上写多线程程序是有些挑战的

497
00:21:15,149 --> 00:21:17,679
其中一个是共享数据

498
00:21:17,679 --> 00:21:18,999
关于线程模型，牛逼的地方在于

499
00:21:18,999 --> 00:21:22,359
这些线程共享地址空间，共享内存

501
00:21:22,359 --> 00:21:24,309
如果某个线程在内存中创建了一个对象

502
00:21:24,309 --> 00:21:26,919
在其它线程中你也能使用它

503
00:21:26,919 --> 00:21:29,139
你可以创建个数组或是别的什么东西

504
00:21:29,139 --> 00:21:31,419
所有不同的线程都能读写

506
00:21:31,419 --> 00:21:33,879
这就存在一些临界情况

507
00:21:33,879 --> 00:21:35,080
如果你你持有一些你关注的状态

508
00:21:35,080 --> 00:21:36,309
可能你会缓存一些数据

509
00:21:36,309 --> 00:21:39,099
你的 server，你的缓存，你的内存

510
00:21:39,099 --> 00:21:40,840
当其中一个线程正处理一个客户端的请求的时候

511
00:21:40,840 --> 00:21:42,309
首先它会先查一下缓存中的数据

512
00:21:42,309 --> 00:21:43,809
但是这个共享缓存，每个线程都能读

513
00:21:43,809 --> 00:21:45,809
当线程里有新的信息时

514
00:21:45,809 --> 00:21:49,179
线程可能会向缓存里写入数据进行更新

516
00:21:49,179 --> 00:21:51,220
所以这真的很厉害

517
00:21:51,220 --> 00:21:55,210
你可以共享内存

518
00:21:55,210 --> 00:21:57,970
但是事实也表明这也非常容易出现 bug

519
00:21:57,970 --> 00:21:59,739
如果你不关心多线程之间共享内存的话

520
00:21:59,739 --> 00:22:05,529
有个经典的例子

522
00:22:05,529 --> 00:22:07,629
假设你有一个全局变量 N

523
00:22:07,629 --> 00:22:09,669
在不同的线程之间共享

524
00:22:09,669 --> 00:22:11,440
其中一个线程只是对 N 做自增

525
00:22:11,440 --> 00:22:20,710
这可能就是造成 bug 的原因

527
00:22:20,710 --> 00:22:22,239
如果你不做一些特殊处理的话

528
00:22:22,239 --> 00:22:25,119
为什么？

529
00:22:25,119 --> 00:22:31,899
无论何时你在多线程中读写共享数据

532
00:22:31,899 --> 00:22:33,669
总是存在一种可能性

533
00:22:33,669 --> 00:22:35,259
你得牢记

534
00:22:35,259 --> 00:22:37,549
在同一时刻，总有其它的线程可能也正在查看

535
00:22:37,259 --> 00:22:39,549
或是修改这个共享数据

536
00:22:39,549 --> 00:22:41,739
所以这里有个很明显的问题

537
00:22:41,739 --> 00:22:43,899
看这里，线程 1 正在执行

538
00:22:43,899 --> 00:22:50,799
但是另一个不同的线程 2 也在执行相同的代码

541
00:22:50,799 --> 00:22:53,049
记得刚我说 N 它是一个全局变量

542
00:22:53,049 --> 00:22:54,369
所以这里我们说的这个 N 都是同一个 N

543
00:22:54,369 --> 00:22:57,039
这里再总结一下

544
00:22:57,039 --> 00:22:58,269
实际上机器运行的并不是这样的代码

545
00:22:58,269 --> 00:23:01,749
而是由编译器吐出来的机器码

547
00:23:01,749 --> 00:23:03,879
机器码长啥样呢

548
00:23:03,879 --> 00:23:06,720
首先把 X 载入到一个寄存器里

549
00:23:06,720 --> 00:23:13,210
然后给寄存器的加 1

550
00:23:13,210 --> 00:23:18,129
接着再把寄存器的值保存到 X

551
00:23:18,129 --> 00:23:21,009
这里 X 是某个位置的内存地址

552
00:23:21,009 --> 00:23:24,340
所以你可以假设所有的线程

554
00:23:24,340 --> 00:23:25,929
都在执行这行代码

555
00:23:25,929 --> 00:23:28,720
他们都会执行 load x 到寄存器

556
00:23:28,720 --> 00:23:31,090
x 从 0 开始有效

557
00:23:31,090 --> 00:23:32,470
这意味着，所有线程都把 0 读入寄存器

558
00:23:32,470 --> 00:23:33,970
然后他们都给寄存器加 1

559
00:23:33,970 --> 00:23:35,619
这样所有线程各有自的寄存器的值是 1

560
00:23:35,619 --> 00:23:37,809
最后再把寄存器的值 1 重新保存到内存里

561
00:23:37,809 --> 00:23:39,999
现在，这两个线程对 N 做自增后，结果都是 1

562
00:23:39,999 --> 00:23:44,019
谁知道程序员心里想的啥呢

563
00:23:44,019 --> 00:23:45,489
可能他就是这么想

564
00:23:45,489 --> 00:23:47,289
但是碰巧这样写并不正确

565
00:23:47,289 --> 00:23:49,149
碰巧程序想要的结果不是 1

566
00:23:49,149 --> 00:24:02,710
(提问...) 有一些指令是原子的

567
00:24:02,710 --> 00:24:04,239
这个问题不错

568
00:24:04,239 --> 00:24:11,259
这些独立的指令是不是原子的

570
00:24:11,259 --> 00:24:13,269
答案是有些是，有些不是

571
00:24:13,269 --> 00:24:23,440
对于 32 位的 store 指令它极有可能是原子的

573
00:24:23,440 --> 00:24:25,960
从某种意义上来说，如果有两个处理器

574
00:24:25,440 --> 00:24:27,960
同时在相同的内存地址上执行 store 一个 32 位值

575
00:24:27,960 --> 00:24:30,169
最终要么是其中一个处理器上的 32 位值

576
00:24:30,169 --> 00:24:35,169
要么是另一个处理器上的 32 位值

578
00:24:35,169 --> 00:24:38,200
而不是一个混合的值

579
00:24:38,200 --> 00:24:40,450
其它尺寸大小的未必就这么简单

580
00:24:40,450 --> 00:24:41,980
比如一个字节的存储这依赖于你所使用的 CPU

581
00:24:41,980 --> 00:24:44,440
因为 1 字节的存储几乎和 32 字节的 load 差不多

582
00:24:44,440 --> 00:24:47,919
就是 8 bit 的修改，和一个 32 字节的存储

583
00:24:47,919 --> 00:24:51,820
这依赖于处理器和更复杂的指令

585
00:24:51,820 --> 00:24:55,899
比如微处理器上的自增指令

587
00:24:55,899 --> 00:25:00,220
它能直接给内存上某个地址的值加 1

589
00:25:00,220 --> 00:25:04,239
未必就是原子的

590
00:25:04,239 --> 00:25:07,890
尽管这些指令存在原子版本的

592
00:25:07,890 --> 00:25:16,679
好，咱们继续。所以这是一个非常经典的错误

594
00:25:16,679 --> 00:25:20,490
通常我们叫他“竞争”(注：后面不译，直接使用 race)，后面我打算会多次提起它

595
00:25:20,490 --> 00:25:22,679
因为你将会做大量的多线程编程

596
00:25:22,679 --> 00:25:25,280
且存在共享状态

597
00:25:25,280 --> 00:25:27,570
这里 race 这个词

598
00:25:27,570 --> 00:25:30,570
我认为来源于电子电路中的一类古老的 bug

599
00:25:30,570 --> 00:25:33,770
但是对我们来说

600
00:25:33,770 --> 00:25:37,770
称为 race 是因为如果一个 CPU 已经开始执行这段代码

602
00:25:37,770 --> 00:25:44,790
另一些线程正在结束这段代码

604
00:25:44,790 --> 00:25:46,320
这就是 race

605
00:25:46,320 --> 00:25:48,090
第一个处理器能够

606
00:25:48,090 --> 00:25:53,370
在第二个处理器开始执行 load 前执行 store

608
00:25:53,370 --> 00:25:54,809
如果第一个处理器的 store

609
00:25:54,809 --> 00:25:59,070
确实是在第二个处理器 load 之前

611
00:25:59,070 --> 00:26:00,750
那么第二个处理器就能看到第一个处理器存储的值

612
00:26:00,750 --> 00:26:07,370
第二个处理器将 load 值 1，然后再加 1，再把 2 存入

614
00:26:07,370 --> 00:26:10,200
好了，你可以通过上面这种方式理解这个术语

615
00:26:10,200 --> 00:26:15,270
okay, 解决这个问题的方式很简单

617
00:26:15,270 --> 00:26:16,890
加个锁就行了

618
00:26:16,890 --> 00:26:19,470
你知道，作为一个程序员

619
00:26:19,470 --> 00:26:23,910
你心中应该有一些办法如何给数据加锁

620
00:26:23,910 --> 00:26:31,500
只有在持有锁的时候，这个共享数据才能被使用

623
00:26:31,500 --> 00:26:33,090
到后面你就会明白

624
00:26:33,090 --> 00:26:36,660
在后面的教程里你可能就会用到

625
00:26:36,660 --> 00:26:39,799
Go 调用 lock 来锁住 mutex，你能看到 mu.Lock()

626
00:26:39,799 --> 00:26:44,130
加在这一段使用共享数据的代码前面

627
00:26:44,130 --> 00:26:48,320
然后在结束的地方调用  mu.Unlock()

628
00:26:48,320 --> 00:26:52,020
无论哪个线程执行到这里

629
00:26:52,020 --> 00:26:53,340
只有足够幸运的那个线程才能第一个抢到锁

630
00:26:53,340 --> 00:26:56,220
然后执行所有这些代码

631
00:26:56,220 --> 00:26:57,600
在结束之前，另一个线程都不能继续

633
00:26:57,600 --> 00:27:02,340
你可以考虑把这些在锁中间的代码封装起来

634
00:27:02,340 --> 00:27:05,460
就像这一堆东西

635
00:27:05,460 --> 00:27:07,020
记住，尽管这里只有一行代码

636
00:27:07,020 --> 00:27:10,380
实际上这里也有 3 条不同的指令

637
00:27:10,380 --> 00:27:16,040
对于必须加锁的人来说

639
00:27:16,040 --> 00:27:18,240
你可以认为锁能把这一连串的代码变成一个原子操作

640
00:27:18,240 --> 00:27:21,320
(提问)

641
00:27:26,370 --> 00:27:30,970
你是……胆子小吗，能不能再说一遍？

643
00:27:30,970 --> 00:27:37,090
oh，这个问题很棒

644
00:27:37,090 --> 00:27:39,040
Go 怎么知道我们正锁住哪些变量？

645
00:27:39,040 --> 00:27:41,350
在这里

646
00:27:41,350 --> 00:27:43,090
就只有一个变量

647
00:27:43,090 --> 00:27:45,910
但是也可能我们会锁住等于 x + y 的值

648
00:27:45,910 --> 00:27:47,440
实际上三个不同变量

649
00:27:47,440 --> 00:27:52,890
所以答案是 go 并不知道

650
00:27:52,890 --> 00:27:55,030
他们一点关联都没有

651
00:27:55,030 --> 00:27:58,030
在这个锁里的任何位置

652
00:27:58,030 --> 00:28:00,640
所以，这里新的东西是这个变量(mu)

653
00:28:00,640 --> 00:28:04,600
它是个 mutex

654
00:28:04,600 --> 00:28:07,630
在 lock 和任何变量之间

655
00:28:07,630 --> 00:28:10,720
他们并没有什么关联

656
00:28:10,720 --> 00:28:12,340
在程序员脑袋中

657
00:28:12,340 --> 00:28:14,470
你只需要说

658
00:28:14,470 --> 00:28:18,670
oh, 这里有一堆共享数据

659
00:28:18,670 --> 00:28:20,770
在任意时刻，你修改其中任意一个

660
00:28:20,770 --> 00:28:22,810
有些复杂的数据结构

661
00:28:22,810 --> 00:28:24,280
比如是树或是可扩展的 hash 表或是别的什么

662
00:28:24,280 --> 00:28:26,560
任何时候你若打算修改它

663
00:28:26,560 --> 00:28:27,820
当然，树是有许多对象组合而成的

664
00:28:27,820 --> 00:28:29,710
任何时候，你打算修改任何

665
00:28:29,710 --> 00:28:30,880
和这个数据结构关联的东西

666
00:28:30,880 --> 00:28:32,290
你都得先拿到这样的锁

667
00:28:32,290 --> 00:28:34,540
当然，包含许多对象

668
00:28:34,540 --> 00:28:36,580
以及对象的集合的修改

669
00:28:36,580 --> 00:28:37,630
因为你可能会分配一个新的树节点

670
00:28:37,630 --> 00:28:40,120
但是程序员必须想出一个策略

671
00:28:40,120 --> 00:28:41,980
保证在同一时刻

672
00:28:41,980 --> 00:28:44,710
数据结构只在一个核上被使用

673
00:28:44,710 --> 00:28:47,470
所以

674
00:28:47,470 --> 00:28:50,260
需要创建一个甚至是多个锁

675
00:28:50,260 --> 00:28:51,670
有许多许多加锁的方案

676
00:28:51,670 --> 00:28:53,020
应用到树上

677
00:28:53,020 --> 00:28:57,580
你可以想象一棵树上所有的树节点只有一个锁

678
00:28:57,580 --> 00:28:58,780
程序员可以制定一些策略来分配锁

679
00:28:58,780 --> 00:29:02,230
在脑子里记住数据之间关系

681
00:29:02,230 --> 00:29:04,960
但是对 Go 来说

682
00:29:04,960 --> 00:29:07,690
这里的这个锁其实非常简单

683
00:29:07,690 --> 00:29:10,930
它是一个锁对象

684
00:29:10,930 --> 00:29:12,970
第一个线程调用 lock 方法拿到锁

685
00:29:12,970 --> 00:29:14,770
其它所有线程等待直接 unlock 被执行

686
00:29:14,770 --> 00:29:18,540
所有这些事情 Go 都清楚

687
00:29:18,800 --> 00:29:21,160
(提问)

688
00:29:23,990 --> 00:29:26,730
不用给一个对象中

689
00:29:26,730 --> 00:29:29,040
所有变量都加上锁吗？

690
00:29:29,040 --> 00:29:30,690
Go 不知道变量和锁之间是什么关系

691
00:29:30,690 --> 00:29:33,720
当你请求锁的时候

692
00:29:33,720 --> 00:29:37,710
当你的代码调用 lock 方法时

693
00:29:37,710 --> 00:29:41,280
它在做什么

694
00:29:41,280 --> 00:29:44,220
它就是想拿到这个锁，这就是它的作用

695
00:29:44,220 --> 00:29:47,280
其它任何人想尝试获得锁对象

696
00:29:47,280 --> 00:29:49,260
所以在某个地方

697
00:29:49,260 --> 00:29:55,170
需要声明一个 mutex mu;

698
00:29:55,170 --> 00:29:56,580
这个 mu 指向了某些特别的 lock 对象

699
00:29:56,580 --> 00:29:58,410
有许多（听不懂。。。）

700
00:29:58,410 --> 00:30:01,350
所有这些动作都是获取这把锁

701
00:30:01,350 --> 00:30:04,620
其它任何人想获得它

702
00:30:04,620 --> 00:30:06,000
都需要等待，直到 unlock 这把锁

703
00:30:06,000 --> 00:30:09,120
作为程序员，我们使用锁保护什么

704
00:30:09,120 --> 00:30:11,970
完全由我们自己决定

705
00:30:11,970 --> 00:30:33,570
(提问) 所以问题是

706
00:30:33,570 --> 00:30:38,100
让锁私有会不会好些

707
00:30:38,100 --> 00:30:39,660
数据结构的私有数据

708
00:30:39,660 --> 00:30:42,890
我们假设有个城市的分区图

709
00:30:42,890 --> 00:30:44,820
你可能希望，尽管这不是真的

710
00:30:44,820 --> 00:30:46,860
地图内部需要有一把锁来保护它

711
00:30:46,860 --> 00:30:52,860
这是个合理的策略

712
00:30:52,860 --> 00:30:56,340
有了这些会怎样？

714
00:30:56,340 --> 00:30:58,350
如果你定义了一个

715
00:30:58,350 --> 00:30:59,820
需要加锁使用的数据结构

716
00:30:59,820 --> 00:31:01,650
这个锁是内部私有的

717
00:31:01,650 --> 00:31:03,210
数据结构的每个方法都有责任

718
00:31:03,210 --> 00:31:04,860
请求这把锁

719
00:31:04,860 --> 00:31:06,840
用户，数据结构可能永远都不知道有这把锁的存在

720
00:31:06,840 --> 00:31:09,210
这个相当合理

721
00:31:09,210 --> 00:31:10,830
但是唯一点需要打破

722
00:31:10,830 --> 00:31:15,930
好吧，有几件事，其中之一是

723
00:31:15,930 --> 00:31:18,090
如果程序员知道这个数据从未被共享

724
00:31:18,090 --> 00:31:20,910
他们可能会感觉烦恼

725
00:31:20,910 --> 00:31:22,200
因为他们得多付出锁的开销

726
00:31:22,200 --> 00:31:23,400
他们清楚这没必要加锁

727
00:31:23,400 --> 00:31:25,820
所以这是个潜在的问题

728
00:31:25,820 --> 00:31:31,140
另一件事

729
00:31:31,140 --> 00:31:33,060
如果有任何内部数据结构依赖

730
00:31:33,060 --> 00:31:36,020
比如我们有两个带有锁的数据结构

732
00:31:36,020 --> 00:31:38,710
他们可能会互相使用

733
00:31:38,710 --> 00:31:41,080
这可能会导致产生环和死锁

734
00:31:41,080 --> 00:31:45,160
死锁可以被解决

735
00:31:45,160 --> 00:31:47,600
但常规解决死锁的方法

736
00:31:47,600 --> 00:31:52,370
需要把锁拿到实现的外面来

737
00:31:52,370 --> 00:31:54,290
放到调用代码的地方（注：把函数里面的锁，移到外面）

738
00:31:54,290 --> 00:31:56,000
后面有机会我们会讲到它的

739
00:31:56,000 --> 00:31:59,180
不过对于隐藏锁细节的代码来说

740
00:31:59,180 --> 00:32:00,710
这是个不太好的方法

741
00:32:00,710 --> 00:32:11,600
okay, 所以你使用多线程的问题之一

742
00:32:11,600 --> 00:32:14,060
就是这些 race

743
00:32:14,060 --> 00:32:16,370
通常你都使用锁来解决 race 问题

744
00:32:16,370 --> 00:32:18,020
okay，事实上，还有 2 个大的策略

745
00:32:18,020 --> 00:32:19,430
其中之一是你需要解决

746
00:32:19,430 --> 00:32:25,180
同时访问数据的加锁策略

748
00:32:25,180 --> 00:32:29,170
另一个方案是你可以让你的代码不要共享数据

749
00:32:29,170 --> 00:32:32,420
如果可以的话，这种方法会更好

750
00:32:32,420 --> 00:32:35,540
因为这会降低复杂性

751
00:32:35,540 --> 00:32:38,330
好，现在来看另一个话题 coordination(协作)

752
00:32:38,330 --> 00:32:40,100
它和指导线程运作有关

753
00:32:40,100 --> 00:32:46,670
当我们正在执行涉及到多线程情况下的加锁时

755
00:32:46,670 --> 00:32:48,530
可能并不知道其它线程也在加锁

756
00:32:48,530 --> 00:32:51,650
他们只是想在没有人干涉的情况下拿到数据

758
00:32:51,650 --> 00:32:53,960
但也有一些情况

759
00:32:53,960 --> 00:32:55,220
你确实就是故意的想让不同的线程之间

760
00:32:55,220 --> 00:32:56,870
互相受到制约

761
00:32:56,870 --> 00:32:58,370
我就是想等着你

762
00:32:58,370 --> 00:32:59,930
比如你生产某些数据

763
00:32:59,930 --> 00:33:01,550
但是你又和我不是同一个线程

764
00:33:01,550 --> 00:33:03,140
你生产数据

765
00:33:03,140 --> 00:33:05,900
我想在你生产完数据前一直等待

766
00:33:05,900 --> 00:33:09,980
直到你完成后，我再去读取

767
00:33:09,980 --> 00:33:11,180
或者是你启动了一堆线程去抓取 web 页面

768
00:33:11,180 --> 00:33:12,440
然后需要等待所有线程都执行结束

769
00:33:12,440 --> 00:33:14,180
所以当我们想

770
00:33:14,180 --> 00:33:18,770
特意的互相等待的时候

773
00:33:18,770 --> 00:33:23,320
这种情况通常就称为 coordination (协作)

774
00:33:23,440 --> 00:33:26,630
你要是做完了咱们的教程的话

775
00:33:26,630 --> 00:33:28,250
就能知道很多了

776
00:33:28,250 --> 00:33:31,220
Go 中有很多技术可以做到

777
00:33:31,220 --> 00:33:34,299
比如 channel (通道)

778
00:33:34,299 --> 00:33:37,029
channel 是一种用于发数据从这个线程

779
00:33:37,029 --> 00:33:38,950
发送到另一个线程的工具

780
00:33:38,950 --> 00:33:42,039
也有一些其它工具

781
00:33:42,039 --> 00:33:45,239
它更多的用于特殊的目的

782
00:33:45,239 --> 00:33:48,940
比如有个东西叫 condition variables (条件变量)

783
00:33:48,940 --> 00:33:51,549
这东西很牛逼

784
00:33:51,549 --> 00:33:53,229
如果有些线程在那里等着（马儿不走了）

785
00:33:53,229 --> 00:33:54,489
你想周期性的“踢”它一下（类似马儿，抽它一下）

786
00:33:54,489 --> 00:33:55,839
但你不确定哪些线程是否正在等待你

787
00:33:55,839 --> 00:33:57,459
如果它在等你，你就踢它一下

788
00:33:57,459 --> 00:33:59,499
这样它就知道它需要

789
00:33:59,499 --> 00:34:01,509
继续做它应该要做的事情

790
00:34:01,509 --> 00:34:06,279
还有一个工具 WaitGroup

791
00:34:06,279 --> 00:34:08,260
相当牛逼

792
00:34:08,260 --> 00:34:10,449
常用于启动已知数据的 goroutine

793
00:34:10,449 --> 00:34:14,469
然后等待它们结束

794
00:34:14,469 --> 00:34:16,059
线程最终的致命错误是死锁

795
00:34:16,059 --> 00:34:23,619
死锁是一个一般性问题

796
00:34:23,619 --> 00:34:29,219
有时你运行到线程中的某个位置

798
00:34:29,219 --> 00:34:35,859
这个线程（T1)正在等待另外一个线程(T2)生产的数据

800
00:34:35,859 --> 00:34:37,750
我来画个箭头

801
00:34:37,750 --> 00:34:41,168
表示 T1 正在等待 T2

802
00:34:41,168 --> 00:34:43,989
线程 T1 可能正在等待 T2 释放锁

804
00:34:43,989 --> 00:34:46,690
或是向 channel 上发数据

805
00:34:46,690 --> 00:34:48,279
又或是等着 T2 给 WaitGroup 计数减 1

806
00:34:48,279 --> 00:34:51,579
然而不幸的是

807
00:34:51,579 --> 00:34:55,210
T2 也可能正在等着 T1 做一些事情

808
00:34:55,210 --> 00:35:00,069
在锁中这种情况特别常见

810
00:35:00,069 --> 00:35:01,839
T1 在请求锁 A

811
00:35:01,839 --> 00:35:05,740
T2 在请求锁 B

812
00:35:05,740 --> 00:35:07,690
应该这样，T1 持有锁 A, T2 持有锁 B

813
00:35:07,690 --> 00:35:11,230
然后下一步，T1 也需要请求锁 B

814
00:35:11,230 --> 00:35:15,910
它需要同时持有 2 把锁

816
00:35:15,910 --> 00:35:17,289
刚好 T2 也需要请求锁 A

817
00:35:17,289 --> 00:35:19,990
这就死锁了

818
00:35:19,990 --> 00:35:21,490
这至少需要他们都能抢到第一把锁

819
00:35:21,490 --> 00:35:23,410
然后继续执行到他们需要第二把锁的位置

820
00:35:23,410 --> 00:35:24,520
现在它们都在永远互相等待着对方

821
00:35:24,520 --> 00:35:26,740
它们都无法继续进行下去

822
00:35:26,740 --> 00:35:28,779
也没有人能释放掉刚拿到的锁

823
00:35:28,779 --> 00:35:33,569
通常什么都不会发生

824
00:35:33,569 --> 00:35:36,190
所以如果你的程序像机器一样停下来

825
00:35:36,190 --> 00:35:37,420
什么也不干的时候

826
00:35:37,420 --> 00:35:40,000
但是又没有 crash 掉，那就是死锁了

827
00:35:40,000 --> 00:35:42,960
你应该要好好查查

828
00:35:43,799 --> 00:35:53,859
okay，让我们看看教程里的 web 爬虫

830
00:35:53,859 --> 00:36:00,430
这是一个使用多线程的例子

831
00:36:00,430 --> 00:36:03,730
我这里有 2 种不同风格的方案

832
00:36:03,730 --> 00:36:07,630
呃，实际上应该是有 3 种

833
00:36:07,630 --> 00:36:09,430
不同风格的方案里

834
00:36:09,430 --> 00:36:10,779
咱们可以谈谈多线程编程里的一些细节

835
00:36:10,779 --> 00:36:13,539
首先

836
00:36:13,539 --> 00:36:16,119
你们可能知道

837
00:36:16,119 --> 00:36:18,490
爬虫就是你给它一个 URL 让它开始运行

838
00:36:18,490 --> 00:36:20,470
在 web 页面里

839
00:36:20,470 --> 00:36:23,109
包含有许多链接指向了其它的页面

840
00:36:23,109 --> 00:36:24,849
所以 web 爬虫要做的就是

841
00:36:24,849 --> 00:36:29,529
把这些链接指向的页面提取出来

843
00:36:29,529 --> 00:36:32,049
抓取这些页面后

844
00:36:32,049 --> 00:36:33,730
再检查所有这些页面里的 url

845
00:36:33,730 --> 00:36:35,740
然后继续抓取这些 url 指向的页面

846
00:36:35,740 --> 00:36:38,380
它应该要能够停止

847
00:36:38,380 --> 00:36:41,230
比如直到 web 中所有的页面被抓取完

848
00:36:41,230 --> 00:36:45,490
另外

849
00:36:45,490 --> 00:36:52,150
网页构成的 graph 和 URL 存在环

850
00:36:52,150 --> 00:36:53,380
如果你不关心的话

851
00:36:53,380 --> 00:36:55,420
um 你的爬虫可能会结束

852
00:36:55,420 --> 00:36:57,099
但是如果你忘记了已经抓取了这个 web 页面

853
00:36:57,099 --> 00:36:59,019
你可能会永远无休止的

854
00:36:59,019 --> 00:37:01,450
在循环中进行下去

855
00:37:01,450 --> 00:37:03,579
你的爬虫永远无法结束

856
00:37:03,579 --> 00:37:05,559
所以爬虫的工作之一就是需要记住

857
00:37:05,559 --> 00:37:08,140
它抓取过的页面

858
00:37:08,140 --> 00:37:10,779
或是已经开始抓取的页面

859
00:37:10,779 --> 00:37:15,819
对于任何正在抓取中的页面

860
00:37:15,819 --> 00:37:17,200
都不应该有第二次抓取

861
00:37:17,200 --> 00:37:18,849
你可以想象

862
00:37:18,849 --> 00:37:21,759
它是一个树结构

863
00:37:21,759 --> 00:37:25,269
这个树结构是一个

864
00:37:25,269 --> 00:37:31,809
包含了环的实际网页 graph 的子集

865
00:37:31,809 --> 00:37:33,430
我们想避开环

866
00:37:33,430 --> 00:37:37,059
不想抓取同一个页面 2 次

867
00:37:37,059 --> 00:37:38,289
另外，实践证明抓取一个 web 页面

868
00:37:38,289 --> 00:37:40,089
需要花点时间

869
00:37:40,089 --> 00:37:42,160
但是服务器又很慢

870
00:37:42,160 --> 00:37:46,960
因为网络有较长的延迟

871
00:37:46,960 --> 00:37:48,670
所以你完全不会想一次只抓取一个页面

872
00:37:48,670 --> 00:37:50,289
除非你想让你的爬虫运行个数年

873
00:37:50,289 --> 00:37:54,190
如果你同时抓取许多页面的话

874
00:37:54,190 --> 00:37:56,030
这个成本太高了

875
00:37:56,030 --> 00:37:57,980
我会达到某些限制

876
00:37:57,980 --> 00:37:59,480
你需要使用并行化的方式

877
00:37:59,480 --> 00:38:01,490
持续的增加抓取页面的数量

878
00:38:01,490 --> 00:38:03,140
直到达到呑吐极限

879
00:38:03,140 --> 00:38:05,690
也就是每秒你抓取的页面数量

880
00:38:05,690 --> 00:38:07,910
不在增加为止，也就是并发数的增加

881
00:38:07,910 --> 00:38:11,300
这时候也耗尽了网络带宽

882
00:38:11,300 --> 00:38:12,500
所以，我们希望利用并行化的方式抓取

883
00:38:12,500 --> 00:38:15,980
最后一个挑战

884
00:38:15,980 --> 00:38:17,900
有时候也是最难解决的问题

885
00:38:17,900 --> 00:38:19,400
当爬虫运行结束

886
00:38:19,400 --> 00:38:21,620
一旦我们已经抓取了所有的页面

887
00:38:21,620 --> 00:38:24,110
就需要停止爬虫

888
00:38:24,110 --> 00:38:25,370
但是我确实需要写一些代码

889
00:38:25,370 --> 00:38:27,110
来表明：啊哈

890
00:38:27,110 --> 00:38:29,840
所有的页面都已经抓取了

891
00:38:29,840 --> 00:38:32,480
我已经想出了一些方案

892
00:38:32,480 --> 00:38:33,890
什么时候结束被证明是

893
00:38:33,890 --> 00:38:38,420
最难的一部分

894
00:38:38,420 --> 00:38:40,730
所以我的第一个爬虫是一个串行化的爬虫

895
00:38:40,730 --> 00:38:43,400
顺便说一下，课程表里的 crawler.go 文件中的

896
00:38:43,400 --> 00:38:45,980
这段代码是可以用的

897
00:38:45,980 --> 00:38:48,500
后面你会看到它的

898
00:38:48,500 --> 00:38:53,240
这个串行爬虫在网页 graph 中

899
00:38:53,240 --> 00:38:58,120
进行深度优先搜索

900
00:38:58,120 --> 00:39:02,870
有件比较有意思的事情

901
00:39:02,870 --> 00:39:04,490
它会使用一个 map 类型的变量 fetched

902
00:39:04,490 --> 00:39:06,650
它只是被当作一个 set 使用

903
00:39:06,650 --> 00:39:08,630
目的就是为了记住

904
00:39:08,630 --> 00:39:11,210
它所抓取过的页面

905
00:39:11,210 --> 00:39:12,830
这是最有意思的部分

906
00:39:12,830 --> 00:39:16,250
在 18 行你给它一个 URL

907
00:39:16,250 --> 00:39:17,920
如果这个 URL 已经被抓取过它就直接 return

908
00:39:17,920 --> 00:39:20,210
如果没有被抓取过

909
00:39:20,210 --> 00:39:22,420
首先它要把这个 URL 记下

910
00:39:22,420 --> 00:39:26,060
然后开始抓取，fetcher 会真正开始抓取页面

911
00:39:26,060 --> 00:39:27,650
然后提取页面中的 URL

912
00:39:27,650 --> 00:39:29,540
接下来迭代所有的 URL

913
00:39:29,540 --> 00:39:33,430
然后递归的调用它自己

914
00:39:33,430 --> 00:39:35,660
对于所有的页面

915
00:39:35,660 --> 00:39:38,060
它会把这些页面传递给自己

916
00:39:38,060 --> 00:39:40,010
它只有一个表格

917
00:39:40,010 --> 00:39:43,070
一个 fetched map

918
00:39:43,070 --> 00:39:45,770
当我调用递归的抓取的时候

919
00:39:45,770 --> 00:39:47,330
它又抓取了很多页面

920
00:39:47,330 --> 00:39:49,970
在它返回后，我需要意识到

921
00:39:49,970 --> 00:39:52,340
你知道，在抓取实例的外面，需要意识到

922
00:39:52,340 --> 00:39:53,960
某些页面是已经抓取过的

923
00:39:53,960 --> 00:39:56,330
所以我们十分依赖于

924
00:39:56,330 --> 00:39:58,250
在函数里传递的 fetched 对象

925
00:39:58,250 --> 00:40:01,970
map 使用引用而不是拷贝

926
00:40:01,970 --> 00:40:03,770
所以在底层

927
00:40:03,770 --> 00:40:05,330
go 把指向map对象的指针

928
00:40:05,330 --> 00:40:08,480
传递给

929
00:40:08,480 --> 00:40:10,070
每个crawl函数调用

930
00:40:10,070 --> 00:40:12,830
因此这些调用共享同一个对象和内存的指针

931
00:40:12,830 --> 00:40:15,740
而不是（对象）的拷贝

932
00:40:15,740 --> 00:40:22,760
有什么问题吗

933
00:40:22,760 --> 00:40:24,140
这段代码显然没有解决

934
00:40:24,140 --> 00:40:25,760
之前提到的问题

935
00:40:25,760 --> 00:40:30,650
因为它没有并行化的执行 fetch（函数）

936
00:40:30,650 --> 00:40:33,200
我们需要把 goroutine

937
00:40:33,200 --> 00:40:35,150
放在这段代码的某个位置

938
00:40:35,150 --> 00:40:37,880
来实现并行的 fetch 让我们假设

939
00:40:37,880 --> 00:40:41,480
为了让大家开心一下……

940
00:40:41,480 --> 00:40:51,440
老爹，让我偷个懒

941
00:40:51,440 --> 00:40:54,950
为啥我非得这么改代码……

942
00:40:54,950 --> 00:40:57,470
其实就是想把每个 crawl 子调用

943
00:40:57,470 --> 00:41:00,470
放到各自的 goroutine 里执行

944
00:41:00,470 --> 00:41:01,580
我执行这段代码 给你们看看

945
00:41:01,580 --> 00:41:04,070
正确的 output 是什么样

946
00:41:04,070 --> 00:41:07,670
这个窗口运行crawler

947
00:41:07,670 --> 00:41:09,380
实际上执行了全部3个crawler

948
00:41:09,380 --> 00:41:10,970
它们都找到了

949
00:41:10,970 --> 00:41:14,330
完全相同的一组网页

950
00:41:14,330 --> 00:41:16,100
这正是我们期望看到的输出

951
00:41:16,100 --> 00:41:19,220
5行，5个不同的网页被爬取到

952
00:41:19,220 --> 00:41:20,750
每个打印出一行

953
00:41:20,750 --> 00:41:26,120
现在我们把crawler

954
00:41:26,120 --> 00:41:28,130
放在各自的goroutine里执行

955
00:41:28,130 --> 00:41:35,540
我将看到什么结果

956
00:41:35,540 --> 00:41:37,880
我们的期望是并行爬取网页

957
00:41:37,880 --> 00:41:42,800
达到更高的性能 好的

958
00:41:42,800 --> 00:41:45,110
你的观点是只会看到一个URL

959
00:41:45,110 --> 00:41:47,680
为什么

960
00:41:50,980 --> 00:41:55,220
对 完全正确

961
00:41:55,220 --> 00:41:59,000
它不会等待在

962
00:41:59,000 --> 00:42:00,559
for循环，第26行

963
00:42:00,559 --> 00:42:02,450
它将迅速执行完循环

964
00:42:02,450 --> 00:42:04,849
当最开始的那个网页被抓取（第22行）

965
00:42:04,849 --> 00:42:07,039
然后一个循环 它将会启动

966
00:42:07,039 --> 00:42:08,390
这些goroutine

967
00:42:08,390 --> 00:42:10,220
紧接着crawl函数就将返回

968
00:42:10,220 --> 00:42:11,990
而且crawl是在main函数里调用的

969
00:42:11,990 --> 00:42:13,789
几乎可以确定main

970
00:42:13,789 --> 00:42:15,200
会在这些goroutine能做任何事之前退出

971
00:42:15,200 --> 00:42:16,880
所以我们很可能只会看到第一个网页

972
00:42:16,880 --> 00:42:19,690
我运行它

973
00:42:19,690 --> 00:42:23,920
你会看到，这里，在Serial下面

974
00:42:23,920 --> 00:42:26,660
唯一被找到的网页

975
00:42:26,660 --> 00:42:28,730
由于程序并没有在Serial Crawler结束后退出

976
00:42:28,730 --> 00:42:30,799
这些goroutine

977
00:42:30,799 --> 00:42:32,269
仍然在运行 实际上 他们打印的输出

978
00:42:32,269 --> 00:42:35,390
和后面的crawler例子（的输出）

979
00:42:35,390 --> 00:42:37,819
混在了一起

980
00:42:37,819 --> 00:42:42,829
然而 这段代码 只是在这里加了一个go关键词

981
00:42:42,829 --> 00:42:45,829
完全不起作用

982
00:42:45,829 --> 00:42:49,579
我们忘掉这段代码 现在我

983
00:42:49,579 --> 00:42:52,190
想给你们看一种并发风格的crawler

984
00:42:52,190 --> 00:42:55,789
我马上会展示其中一个

985
00:42:55,789 --> 00:42:59,750
（它）使用了共享数据

986
00:42:59,750 --> 00:43:02,809
共享对象和锁 这是第一个（crawler）

987
00:43:02,809 --> 00:43:05,059
还有一个（crawler）没有用共享数据

988
00:43:05,059 --> 00:43:08,990
但使用channel传递消息

989
00:43:08,990 --> 00:43:11,359
channel 可以让不同的线程之间进行协作

990
00:43:11,359 --> 00:43:12,920
现在（要讲的）是共享数据的

991
00:43:12,920 --> 00:43:17,000
这只是众多使用共享数据

992
00:43:17,000 --> 00:43:18,980
来构建crawler的方式之一

993
00:43:18,980 --> 00:43:22,460
这段代码明显

994
00:43:22,460 --> 00:43:26,079
比Serial crawler要复杂的多

995
00:43:26,079 --> 00:43:31,130
它为每个fetch创建一个thread

996
00:43:31,130 --> 00:43:33,740
最大的不同之处在于

997
00:43:33,740 --> 00:43:38,390
它做了两件事

998
00:43:38,390 --> 00:43:40,700
一是必要的统计 以注意到

999
00:43:40,700 --> 00:43:44,690
所有爬取完成的时刻

1000
00:43:44,690 --> 00:43:47,900
它也会处理共享表格

1001
00:43:47,900 --> 00:43:49,849
这个表格记录了已爬取的URL

1002
00:43:49,849 --> 00:43:53,809
所以这段代码仍然有URL表格

1003
00:43:53,809 --> 00:43:59,349
即 f.fetched

1004
00:43:59,349 --> 00:44:06,130
在第43行 这个表格

1005
00:44:06,130 --> 00:44:10,660
被所有的crawler线程共享

1006
00:44:10,660 --> 00:44:12,190
所有的crawler线程

1007
00:44:12,190 --> 00:44:14,890
执行在

1008
00:44:14,890 --> 00:44:16,900
函数 ConcurrentMutex 内 所以我们仍然

1009
00:44:16,900 --> 00:44:18,609
有 ConcurrentMutex 的树结构

1010
00:44:18,609 --> 00:44:20,619
来探索 web graph 的不同部分

1011
00:44:20,619 --> 00:44:22,599
但它们中的每一个是被

1012
00:44:22,599 --> 00:44:25,660
被放在各自的goroutine中启动

1013
00:44:25,660 --> 00:44:28,720
而不是作为函数调用

1014
00:44:28,720 --> 00:44:30,400
但是它们都共享一个状态表

1015
00:44:30,400 --> 00:44:32,859
记录已爬取URL的表格

1016
00:44:32,859 --> 00:44:34,990
因为如果有个goroutine爬取了一个URL

1017
00:44:34,990 --> 00:44:36,970
我们不希望另一个goroutine

1018
00:44:36,970 --> 00:44:40,420
意外地爬取同一个URL

1019
00:44:40,420 --> 00:44:43,150
你在这里看到 在第42行和第45行

1020
00:44:43,150 --> 00:44:48,250
我在这段代码前后加上互斥锁

1021
00:44:48,250 --> 00:44:51,099
用于防止race

1022
00:44:51,099 --> 00:44:52,900
如果不加 race就可能发生

1023
00:44:52,900 --> 00:44:57,730
所以这里的危险是

1024
00:44:57,730 --> 00:44:59,980
在第43行 一个线程正在检查URL是否已经被爬取

1025
00:44:59,980 --> 00:45:02,680
两个线程恰好在处理

1026
00:45:02,680 --> 00:45:06,819
同一个URL  两个ConcurrentMutex函数的调用

1027
00:45:06,819 --> 00:45:09,490
结果却会看到同一个URL

1028
00:45:09,490 --> 00:45:11,140
原因可能是同一个URL

1029
00:45:11,140 --> 00:45:13,930
在两个不同的网页都出现过

1030
00:45:13,930 --> 00:45:17,559
如果我们没有锁

1031
00:45:17,559 --> 00:45:18,819
它们都将访问表格

1032
00:45:18,819 --> 00:45:20,829
查看URL是否已经爬取

1033
00:45:20,829 --> 00:45:23,650
在第43行它们都拿到False

1034
00:45:23,650 --> 00:45:27,069
在第44行 它们都把表格中的

1035
00:45:27,069 --> 00:45:30,880
URL项设置为True

1036
00:45:30,880 --> 00:45:32,380
在第47行 它们都看到already值为False

1037
00:45:32,380 --> 00:45:33,880
之后它们都会去爬取这个网页

1038
00:45:33,880 --> 00:45:37,030
所以我们需要在那里加锁

1039
00:45:37,030 --> 00:45:38,740
对于（在那里加锁）的一个理解方式 我觉得是

1040
00:45:38,740 --> 00:45:41,410
我们希望第43行和44行（一起）

1041
00:45:41,410 --> 00:45:44,020
是原子性的 也即是说我们不希望

1042
00:45:44,020 --> 00:45:45,910
其他线程进入第43行和44行

1043
00:45:45,910 --> 00:45:48,460
使用表 我们想要

1044
00:45:48,460 --> 00:45:50,349
读取当前的内容 每个线程

1045
00:45:50,349 --> 00:45:52,690
希望能读取当前的表格内容

1046
00:45:52,690 --> 00:45:55,780
并更新 且没有其他线程干扰

1047
00:45:55,780 --> 00:45:57,309
这正是锁

1048
00:45:57,309 --> 00:46:01,150
为我们做到的事情 对于这里使用锁的策略

1049
00:46:01,150 --> 00:46:03,280
有任何问题吗

1050
00:46:03,280 --> 00:46:05,940

1051
00:46:07,750 --> 00:46:10,760
好 当我们检查表中的URL条目之后

1052
00:46:10,760 --> 00:46:13,670
在51行

1053
00:46:13,670 --> 00:46:15,320
URL被以常见的方式爬取

1054
00:46:15,320 --> 00:46:18,950
之后另一个有趣的事情

1055
00:46:18,950 --> 00:46:20,600
是线程的启动

1056
00:46:20,600 --> 00:46:35,450
（这个同学的）问题是

1057
00:46:35,450 --> 00:46:43,970
关于F. 不

1058
00:46:43,970 --> 00:46:47,120
在第36行有一个结构体

1059
00:46:47,120 --> 00:46:50,330
某种意义上聚集了

1060
00:46:50,330 --> 00:46:53,930
所有的不同的东西

1061
00:46:53,930 --> 00:46:55,280
所有我们需要的不同状态 用以运行crawl

1062
00:46:55,280 --> 00:46:57,380
这里只有两个对象

1063
00:46:57,380 --> 00:46:58,820
但是可以是更多

1064
00:46:58,820 --> 00:47:00,620
只是为了方便

1065
00:47:00,620 --> 00:47:02,030
才它们放在一起

1066
00:47:02,030 --> 00:47:05,390
把mu和fetched放在一个结构中

1067
00:47:05,390 --> 00:47:07,490
并没有什么深层意义

1068
00:47:07,490 --> 00:47:11,750
在同一个结构体里

1069
00:47:11,750 --> 00:47:14,690
F. 只是一种语法

1070
00:47:14,690 --> 00:47:15,890
用于取出结构体里的元素

1071
00:47:15,890 --> 00:47:17,180
我只是刚巧把它们

1072
00:47:17,180 --> 00:47:19,070
放在结构体里 因为

1073
00:47:19,070 --> 00:47:21,080
它让我把与crawl相关的东西

1074
00:47:21,080 --> 00:47:22,790
组织在一起 但是

1075
00:47:22,790 --> 00:47:25,600
这绝对不是说

1076
00:47:25,600 --> 00:47:28,880
go把mu和那个结构体联系在一起

1077
00:47:28,880 --> 00:47:30,950
或是和fetch表联系在一起

1078
00:47:30,950 --> 00:47:33,710
它只是个锁的对象

1079
00:47:33,710 --> 00:47:35,090
只是有一个Lock函数你可以调用

1080
00:47:35,090 --> 00:47:37,930
仅此而已

1081
00:47:53,790 --> 00:47:58,750
（学生的）问题是

1082
00:47:58,750 --> 00:48:00,520
为了传引用，我必须在这里使用*操作符

1083
00:48:00,520 --> 00:48:02,440
但在前一个例子里

1084
00:48:02,440 --> 00:48:03,940
我们传递了一个map

1085
00:48:03,940 --> 00:48:06,040
没有使用*操作符

1086
00:48:06,040 --> 00:48:07,569
不是一定要传递pointer 我的意思是

1087
00:48:07,569 --> 00:48:09,069
第41行的*记号

1088
00:48:09,069 --> 00:48:15,339
如他所说

1089
00:48:15,339 --> 00:48:16,809
我们传递指针

1090
00:48:16,809 --> 00:48:19,210
给这个fetchState对象 我们这里要用指针

1091
00:48:19,210 --> 00:48:20,559
是因为我们希望

1092
00:48:20,559 --> 00:48:22,000
内存里有一个对象

1093
00:48:22,000 --> 00:48:23,710
并且所有不同的goroutine都使用那个对象

1094
00:48:23,710 --> 00:48:25,240
所以它们需要一个

1095
00:48:25,240 --> 00:48:28,000
指向同一个对象的指针

1096
00:48:28,000 --> 00:48:29,410
所以我们需要找到你们自己的结构体

1097
00:48:29,410 --> 00:48:30,940
某种你用来传递指针的语法

1098
00:48:30,940 --> 00:48:32,530
我们不需要对map这么做

1099
00:48:32,530 --> 00:48:35,920
是因为 虽然

1100
00:48:35,920 --> 00:48:39,000
从语法上没那么清晰 （但）map是个指针

1101
00:48:39,000 --> 00:48:42,579
因为map是语言内置的

1102
00:48:42,579 --> 00:48:45,069
它们让你无需使用*操作符

1103
00:48:45,069 --> 00:48:50,530
但map是什么

1104
00:48:50,530 --> 00:48:52,420
如果你声明一个map类型的变量

1105
00:48:52,420 --> 00:48:55,319
这个变量是指向堆上数据的指针

1106
00:48:55,319 --> 00:48:57,579
所以不管怎样，它是个指针

1107
00:48:57,579 --> 00:48:59,260
它总是以引用形式传递

1108
00:48:59,260 --> 00:49:00,609
你就无需使用*运算符 它（语言）替你做了

1109
00:49:00,609 --> 00:49:01,210

1110
00:49:01,210 --> 00:49:03,609
所以map是特殊的

1111
00:49:03,609 --> 00:49:06,130
你不能在语言中定义map

1112
00:49:06,130 --> 00:49:07,900
它必须是语言内置的

1113
00:49:07,900 --> 00:49:09,430
因为有些古怪的事情

1114
00:49:09,430 --> 00:49:15,819
好的 好的 我们爬取网页

1115
00:49:15,819 --> 00:49:18,849
现在我们想要

1116
00:49:18,849 --> 00:49:20,799
为每一个刚爬取页面中的URL

1117
00:49:20,799 --> 00:49:23,170
启动一个crawler goroutine

1118
00:49:23,170 --> 00:49:26,440
在第56行

1119
00:49:26,440 --> 00:49:29,890
遍历fetch函数返回的URLs

1120
00:49:29,890 --> 00:49:32,950
第58行 对每个URL

1121
00:49:32,950 --> 00:49:35,740
启动一个goroutine

1122
00:49:35,740 --> 00:49:41,530
58行的func语法是一个闭包

1123
00:49:41,530 --> 00:49:43,990
或一个匿名函数

1124
00:49:43,990 --> 00:49:46,599
func关键字声明了一个函数

1125
00:49:46,599 --> 00:49:49,140
然后我们调用了这个函数

1126
00:49:49,140 --> 00:49:53,280
所以 可能 理解（这段代码）的方式是

1127
00:49:53,740 --> 00:49:56,780
你把一个函数声明成

1128
00:49:56,780 --> 00:50:00,230
一段数据 先写下func关键字

1129
00:50:00,230 --> 00:50:03,349
然后给出函数参数

1130
00:50:03,349 --> 00:50:08,930
之后写出函数体 结束

1131
00:50:08,930 --> 00:50:12,500
现在这是一个对象

1132
00:50:12,500 --> 00:50:14,000
就好比你敲下1，你有了1

1133
00:50:14,000 --> 00:50:18,349
或23 或什么别的你在声明的东西

1134
00:50:18,349 --> 00:50:19,819
你在声明某种常量对象

1135
00:50:19,819 --> 00:50:21,079
这是声明常量函数的方式

1136
00:50:21,079 --> 00:50:24,079
我们这么做是因为我们想要

1137
00:50:24,079 --> 00:50:25,730
启动一个goroutine

1138
00:50:25,730 --> 00:50:27,290
来运行我们刚声明的这个函数

1139
00:50:27,290 --> 00:50:29,119
为了让它成为一个goroutine

1140
00:50:29,119 --> 00:50:31,069
我们要在func前

1141
00:50:31,069 --> 00:50:33,140
加上go关键字

1142
00:50:33,140 --> 00:50:35,059
然后我们必须要调用这个函数

1143
00:50:35,059 --> 00:50:37,520
因为在go语法中

1144
00:50:37,520 --> 00:50:39,140
go关键字后面

1145
00:50:39,140 --> 00:50:40,910
接函数名 以及要传递的参数

1146
00:50:40,910 --> 00:50:43,460
所以我们在这里

1147
00:50:43,460 --> 00:50:50,900
传递一些参数 这么做有两个原因

1148
00:50:50,900 --> 00:50:52,670
我们这么做

1149
00:50:52,670 --> 00:50:55,069
原因是

1150
00:50:55,069 --> 00:50:57,790
在其他某些情况下 我们写go ConcurrentMutex

1151
00:50:57,790 --> 00:51:00,230
ConcurrentMutex是

1152
00:51:00,230 --> 00:51:01,400
我们要调用的函数的名字

1153
00:51:01,400 --> 00:51:06,619
实际上我们把URL作为参数调用这个函数

1154
00:51:06,619 --> 00:51:08,119
但我们也想要做一点别的事情

1155
00:51:08,119 --> 00:51:10,160
所以我们定义这个小辅助函数

1156
00:51:10,160 --> 00:51:12,170
先调用函数ConcurrentMutex url作为参数

1157
00:51:12,170 --> 00:51:15,740
在ConcurrentMutex

1158
00:51:15,740 --> 00:51:17,119
结束之后 我们做一些

1159
00:51:17,119 --> 00:51:19,520
特殊操作 来帮助我们

1160
00:51:19,520 --> 00:51:22,069
在外层函数退出之前

1161
00:51:22,069 --> 00:51:24,920
等待所有crawl结束 这为我们

1162
00:51:24,920 --> 00:51:27,380
引入了WaitGroup 第55行的WaitGroup

1163
00:51:27,380 --> 00:51:29,569
是go语言定义的一个数据结构

1164
00:51:29,569 --> 00:51:33,619
用于帮助协作

1165
00:51:33,619 --> 00:51:35,030
WaitGroup内部

1166
00:51:35,030 --> 00:51:39,290
有一个计数器

1167
00:51:39,290 --> 00:51:43,640
就像第57行 你调用WaitGroup.Add()来增加计数器

1168
00:51:43,640 --> 00:51:46,549
调用WaitGroup.Done()

1169
00:51:46,549 --> 00:51:48,619
来减小计数器

1170
00:51:48,619 --> 00:51:50,900
第63行 这个Wait方法被调用

1171
00:51:50,900 --> 00:51:53,119
等待计数器归零

1172
00:51:53,119 --> 00:51:56,510
因此WaitGroup是一种

1173
00:51:56,510 --> 00:51:59,329
用于等待若干事件结束的方式

1174
00:51:59,329 --> 00:52:02,540
它在很多不同场景中

1175
00:52:02,540 --> 00:52:04,010
都有应用 这里我们应用它

1176
00:52:04,010 --> 00:52:05,359
来等待最后一个goroutine

1177
00:52:05,359 --> 00:52:05,920
结束

1178
00:52:05,920 --> 00:52:07,839
因为我们对于每个goroutine

1179
00:52:07,839 --> 00:52:11,200
都对WaitGroup加一

1180
00:52:11,200 --> 00:52:13,119
第60行 在这个函数的末尾

1181
00:52:13,119 --> 00:52:15,310
我们把WaitGroup里的counter减一

1182
00:52:15,310 --> 00:52:18,130
然后第63行等待

1183
00:52:18,130 --> 00:52:20,250
直到所有的减一操作完成

1184
00:52:20,250 --> 00:52:22,300
我们声明这种函数的原因

1185
00:52:22,300 --> 00:52:23,920
基本上是为了能够

1186
00:52:23,920 --> 00:52:26,530
即调用函数ConcurrentMutex 又调用Done

1187
00:52:26,530 --> 00:52:28,630
这就是为什么

1188
00:52:28,630 --> 00:52:39,760
我们需要这个函数 （学生的）问题是

1189
00:52:39,760 --> 00:52:43,240
如果某个子程序失败 导致done没被调用

1190
00:52:43,240 --> 00:52:45,820
该怎么办  这是个很好的问题

1191
00:52:45,820 --> 00:52:49,210
我不记得

1192
00:52:49,210 --> 00:52:51,070
能够导致goroutine失败

1193
00:52:51,070 --> 00:52:53,440
但整个程序没有失败

1194
00:52:53,440 --> 00:52:55,150
的错误有哪些

1195
00:52:55,150 --> 00:52:56,589
可能是除零错误 我不确定

1196
00:52:56,589 --> 00:52:57,790
或者对null指针解引用

1197
00:52:57,790 --> 00:52:59,140
不太确定 但是有些方式

1198
00:52:59,140 --> 00:53:04,570
可以使function失败

1199
00:53:04,570 --> 00:53:06,910
goroutine死掉而整个程序不死

1200
00:53:06,910 --> 00:53:08,890
这对我们是个麻烦

1201
00:53:08,890 --> 00:53:12,130
所以实际上 正确的方式是

1202
00:53:12,130 --> 00:53:13,660
我确定你其实知道这个

1203
00:53:13,660 --> 00:53:15,849
才问这个问题的 正确的写法是

1204
00:53:15,849 --> 00:53:18,520
这样写（defer） 以确保 不论goroutine是怎么结束的

1205
00:53:18,520 --> 00:53:20,740
done都会被调用

1206
00:53:20,740 --> 00:53:27,180
把defer放在这里

1207
00:53:27,180 --> 00:53:31,540
意味着在包含它的函数结束前调用done.Done()

1208
00:53:31,540 --> 00:53:34,330
而且总是会被调用

1209
00:53:34,330 --> 00:53:36,130
不管包含它的函数

1210
00:53:36,130 --> 00:53:42,119
是以何种原因结束的

1211
00:53:53,559 --> 00:53:58,789
是的 提问说的是

1212
00:53:58,789 --> 00:54:00,650
为什么两个不同threads对done的调用

1213
00:54:00,650 --> 00:54:08,210
不构成race 答案是

1214
00:54:08,210 --> 00:54:10,640
（WaitGroup）内部有互斥锁

1215
00:54:10,640 --> 00:54:14,170
或类似的机制

1216
00:54:14,170 --> 00:54:18,200
每个done的方法会在执行任何指令前先取得锁

1217
00:54:18,200 --> 00:54:19,970
于是同时

1218
00:54:19,970 --> 00:54:22,789
调用WaitGroup的方法

1219
00:54:22,789 --> 00:54:32,170
并不构成race

1220
00:54:39,519 --> 00:54:43,880
是的 当然 C++ 在C语言中

1221
00:54:43,880 --> 00:54:45,440
你可能需要看 pthreads

1222
00:54:45,440 --> 00:54:47,390
对于C语言，线程由库提供

1223
00:54:47,390 --> 00:54:48,650
它们不是语言的一部分

1224
00:54:48,650 --> 00:54:51,710
叫做 pthreads 它有

1225
00:54:51,710 --> 00:54:55,420
非常传统且古老的原语

1226
00:54:55,420 --> 00:55:04,450
所有的语言都有

1227
00:55:06,630 --> 00:55:12,220
请重复一遍 不在这段代码里

1228
00:55:12,220 --> 00:55:14,140
你可以想象一下WaitGroup如何使用

1229
00:55:14,140 --> 00:55:15,250
我的意思是 WaitGroup只是

1230
00:55:15,250 --> 00:55:21,250
一个计数的东西 是的

1231
00:55:21,250 --> 00:55:22,990
WaitGroup并不关心

1232
00:55:22,990 --> 00:55:27,370
你在数什么或者为什么计数 我的意思是

1233
00:55:27,370 --> 00:55:45,850
这是最常见的用法

1234
00:55:45,850 --> 00:55:48,550
你在困惑 为什么u被作为参数

1235
00:55:48,550 --> 00:55:54,780
传递给58行这个函数

1236
00:55:54,780 --> 00:55:59,070
是的 好吧 提问是

1237
00:55:59,070 --> 00:56:01,450
好的 实际上

1238
00:56:01,450 --> 00:56:05,890
这里function的规则是

1239
00:56:05,890 --> 00:56:09,010
正如我在58行定义的

1240
00:56:09,010 --> 00:56:10,960
如果函数体里访问了一个变量

1241
00:56:10,960 --> 00:56:14,050
这个变量的定义在外围的函数里

1242
00:56:14,050 --> 00:56:17,470
但没有被遮蔽 然后

1243
00:56:17,470 --> 00:56:19,000
内部函数使用的变量

1244
00:56:19,000 --> 00:56:20,650
和外部函数中的

1245
00:56:20,650 --> 00:56:23,080
是同一个变量

1246
00:56:23,080 --> 00:56:26,380
例如fetcher就是这样

1247
00:56:26,380 --> 00:56:28,780
这里内部函数里的fetcher变量

1248
00:56:28,780 --> 00:56:30,250
指代的

1249
00:56:30,250 --> 00:56:32,980
内部函数 好吧 它指代

1250
00:56:32,980 --> 00:56:35,290
和外部函数中fetcher指代的

1251
00:56:35,290 --> 00:56:37,480
是同一个变量

1252
00:56:37,480 --> 00:56:38,920
所以当内部函数

1253
00:56:38,920 --> 00:56:40,510
涉及fetcher的地方意味着

1254
00:56:40,510 --> 00:56:42,310
表示它指代的是和这里相同的变量

1255
00:56:42,310 --> 00:56:45,670
同理f也是一样

1256
00:56:45,670 --> 00:56:48,160
这里用了它 它就是这个变量

1257
00:56:48,160 --> 00:56:50,320
所以你可能觉得我们可以摆脱

1258
00:56:50,320 --> 00:56:55,990
这个u参数

1259
00:56:55,990 --> 00:56:57,880
就让内部函数完全不含参数

1260
00:56:57,880 --> 00:56:59,860
直接使用

1261
00:56:59,860 --> 00:57:04,530
定义在第56行循环里的u

1262
00:57:05,070 --> 00:57:07,390
假如我们可以这么做 当然很棒

1263
00:57:07,390 --> 00:57:09,910
因为能让我们少打些字

1264
00:57:09,910 --> 00:57:12,550
但这样行不通 理由是

1265
00:57:12,550 --> 00:57:16,060
go的for循环语义

1266
00:57:16,060 --> 00:57:17,410
第56行

1267
00:57:17,410 --> 00:57:21,850
for循环更新了变量u

1268
00:57:21,850 --> 00:57:23,620
所以在for循环的第一次迭代中

1269
00:57:23,620 --> 00:57:29,380
变量u包含了某个URL

1270
00:57:29,380 --> 00:57:31,510
当进入for循环的第二次迭代

1271
00:57:31,510 --> 00:57:34,150
变量的内容

1272
00:57:34,150 --> 00:57:37,750
变成了第二个URL

1273
00:57:37,750 --> 00:57:39,370
这意味着 我们第一个启动的goroutine

1274
00:57:39,370 --> 00:57:41,530
看外部

1275
00:57:41,530 --> 00:57:43,000
如果我们看外部函数的

1276
00:57:43,000 --> 00:57:46,930
变量u 我们启动的第一个goroutine

1277
00:57:46,930 --> 00:57:48,910
将看到u中是

1278
00:57:48,910 --> 00:57:51,400
不同的值

1279
00:57:51,400 --> 00:57:53,800
（因为）外部函数 已经更新了u

1280
00:57:53,800 --> 00:57:55,150
有时这正是你们想要的

1281
00:57:55,150 --> 00:57:58,000
例如 f.fetched

1282
00:57:58,000 --> 00:58:01,600
内部函数当然

1283
00:58:01,600 --> 00:58:04,960
希望看到map的变化 但是

1284
00:58:04,960 --> 00:58:06,490
对于u 我们不希望看到改变

1285
00:58:06,490 --> 00:58:09,070
我们启动的第一个goroutine应该

1286
00:58:09,070 --> 00:58:12,130
读取第一个URL 而不是第二个URL

1287
00:58:12,130 --> 00:58:13,810
所以我们希望goroutine能够有一份拷贝

1288
00:58:13,810 --> 00:58:16,080
你有它自己的URL拷贝

1289
00:58:16,080 --> 00:58:18,370
你懂的 如果我们有别的办法做到这件事

1290
00:58:18,370 --> 00:58:20,560
我们也可以那么做

1291
00:58:20,560 --> 00:58:22,150
但是这段代码的

1292
00:58:22,150 --> 00:58:25,630
给内部函数一个私有拷贝的方式

1293
00:58:25,630 --> 00:58:31,860
是传递URL参数给内部函数 是的

1294
00:58:34,450 --> 00:58:36,890
是的 如果我们把u的地址传递

1295
00:58:36,890 --> 00:58:51,200
是的 事实上

1296
00:58:51,200 --> 00:58:52,190
我不知道string怎么行得通的

1297
00:58:52,190 --> 00:58:54,049
但是肯定是给你 你自己的私有的

1298
00:58:54,049 --> 00:59:00,140
变量的拷贝 你拿到自己的

1299
00:59:00,140 --> 00:59:08,950
变量拷贝 它 是的

1300
00:59:26,500 --> 00:59:28,850
你说我们不需要

1301
00:59:28,850 --> 00:59:33,860
在这段代码中 用这个技巧？

1302
00:59:33,860 --> 00:59:35,270
我们当然需要这个技巧

1303
00:59:35,270 --> 00:59:37,700
实际上发生的是 它是

1304
00:59:37,700 --> 00:59:39,170
（学生的）问题是 既然strings是不可变的

1305
00:59:39,170 --> 00:59:41,960
strings是不可变的 是的 那么

1306
00:59:41,960 --> 00:59:43,850
strings是不可变的 那么

1307
00:59:43,850 --> 00:59:45,110
外部函数又是怎么改变这个string的呢

1308
00:59:45,110 --> 00:59:47,720
不该有这个问题 问题并不是

1309
00:59:47,720 --> 00:59:49,700
string被改变了

1310
00:59:49,700 --> 00:59:51,500
问题是变量u

1311
00:59:51,500 --> 00:59:56,150
被改变了 所以当内部函数

1312
00:59:56,150 --> 00:59:57,860
访问一个定义在

1313
00:59:57,860 --> 00:59:59,000
外部函数的变量时 他访问的是

1314
00:59:59,000 --> 01:00:01,070
这个变量 这个变量当前的值

1315
01:00:01,070 --> 01:00:03,320
所以当你 假如你有一个string变量

1316
01:00:03,320 --> 01:00:06,590
里面含有一个字母‘a’

1317
01:00:06,590 --> 01:00:09,110
然后你把‘B’赋值给那个string变量

1318
01:00:09,110 --> 01:00:10,520
你并不是在重写这个string

1319
01:00:10,520 --> 01:00:12,530
（而是）你改变了这个变量

1320
01:00:12,530 --> 01:00:15,950
让它指向了一个不同的string

1321
01:00:15,950 --> 01:00:18,680
由于for循环改变了变量u

1322
01:00:18,680 --> 01:00:21,290
它指向了一个不同的string 你懂的

1323
01:00:21,290 --> 01:00:22,970
这种改变对于内部函数

1324
01:00:22,970 --> 01:00:24,680
是可见的 因此

1325
01:00:24,680 --> 01:00:26,390
内部函数自己需要一个变量的拷贝

1326
01:00:26,390 --> 01:00:29,260

1327
01:00:36,150 --> 01:00:42,000
本质上是复制一份

1328
01:00:50,250 --> 01:00:53,110
好的 但是这正是我们在这段代码里做的

1329
01:00:53,110 --> 01:00:54,670
这就是为什么是这段code

1330
01:00:54,670 --> 01:00:56,440
能跑通的原因

1331
01:00:56,440 --> 01:00:59,080
你的提议 或者说我们没有采用的错误的代码

1332
01:00:59,080 --> 01:01:00,400
我会给你展示一下

1333
01:01:00,400 --> 01:01:02,850
错误的代码

1334
01:01:44,060 --> 01:01:46,440
这只是些可怕的细节

1335
01:01:46,440 --> 01:01:47,700
但是不幸的

1336
01:01:47,700 --> 01:01:50,850
你们在lab中会遇到它们

1337
01:01:50,850 --> 01:01:52,200
所以你们至少应该有意识 这里有个麻烦

1338
01:01:52,200 --> 01:01:54,690
当你遇到这个问题时

1339
01:01:54,690 --> 01:02:12,170
你可以尝试想弄清楚细节

1340
01:02:12,170 --> 01:02:15,870
这是个很好的问题

1341
01:02:15,870 --> 01:02:18,090
提问说的是 如果你有一个内部函数

1342
01:02:18,090 --> 01:02:19,770
我重复一遍

1343
01:02:19,770 --> 01:02:21,180
如果你有一个内部函数

1344
01:02:21,180 --> 01:02:23,430
访问定义在外部的变量

1345
01:02:23,430 --> 01:02:25,980
但是外部函数返回之后

1346
01:02:25,980 --> 01:02:28,590
内部函数的变量将指向哪里

1347
01:02:28,590 --> 01:02:30,030
由于外部函数已经返回

1348
01:02:30,030 --> 01:02:32,460
答案是

1349
01:02:32,460 --> 01:02:35,190
go会注意到 go会分析你的内部函数

1350
01:02:35,190 --> 01:02:38,160
或者说闭包

1351
01:02:38,160 --> 01:02:39,870
go分析它们 编译器分析它们 aha

1352
01:02:39,870 --> 01:02:41,580
oh 这个闭包 这个函数

1353
01:02:41,580 --> 01:02:42,570
使用了外部函数里的变量

1354
01:02:42,570 --> 01:02:44,310
我们实际上会

1355
01:02:44,310 --> 01:02:47,580
编译器会分配堆内存

1356
01:02:47,580 --> 01:02:50,670
来放这些变量 你懂的

1357
01:02:50,670 --> 01:02:52,590
这些变量的当前的值

1358
01:02:52,590 --> 01:02:55,230
两个函数将找到

1359
01:02:55,230 --> 01:02:58,350
堆上的那小片区域 所以

1360
01:02:58,350 --> 01:02:59,760
变量不会被分配在栈上

1361
01:02:59,760 --> 01:03:01,590
如你可能预期的

1362
01:03:01,590 --> 01:03:03,180
如果编译器看到闭包

1363
01:03:03,180 --> 01:03:04,980
变量会被放到堆上

1364
01:03:04,980 --> 01:03:06,060
当外部函数返回时

1365
01:03:06,060 --> 01:03:07,950
对象仍然在堆上

1366
01:03:07,950 --> 01:03:09,840
内部函数还是能够访问到它

1367
01:03:09,840 --> 01:03:11,820
之后垃圾回收器负责

1368
01:03:11,820 --> 01:03:13,440
监测最后一个

1369
01:03:13,440 --> 01:03:15,540
涉及那段堆的函数退出

1370
01:03:15,540 --> 01:03:18,540
返回

1371
01:03:18,540 --> 01:03:24,769
并且将它释放 好的

1372
01:03:24,769 --> 01:03:29,309
所以WaitGroup WaitGroup可能是

1373
01:03:29,309 --> 01:03:30,629
（这节课） 更重要的话题

1374
01:03:30,629 --> 01:03:32,549
这段代码使用这个技术

1375
01:03:32,549 --> 01:03:35,719
来等待当前层所有的crawl结束

1376
01:03:35,719 --> 01:03:37,739
等待它的直系孩子结束

1377
01:03:37,739 --> 01:03:39,599
当然

1378
01:03:39,599 --> 01:03:41,279
这里有很多这样的WaitGroup

1379
01:03:41,279 --> 01:03:44,909
每次调用ConcurrentMutex函数就有一个（WaitGroup）

1380
01:03:44,909 --> 01:03:46,289
ConcurrentMutex等待孩子结束

1381
01:03:46,289 --> 01:03:49,519
然后返回

1382
01:03:49,519 --> 01:03:53,609
好的 回到锁 实际上

1383
01:03:53,609 --> 01:03:54,479
关于锁还有一个事情 我想要谈

1384
01:03:54,479 --> 01:03:56,279
那就是探究 如果我们不加锁

1385
01:03:56,279 --> 01:03:57,949
会发生什么

1386
01:03:57,949 --> 01:04:00,689
好的 我认为 你懂的

1387
01:04:00,689 --> 01:04:02,369
你不加锁的话，你会遇到race

1388
01:04:02,369 --> 01:04:05,209
你会得到不正确的运行结果

1389
01:04:05,209 --> 01:04:11,039
让我们试试 我将会

1390
01:04:11,039 --> 01:04:14,519
把锁注释掉

1391
01:04:14,519 --> 01:04:17,159
问题是：如果我运行这段不加锁的代码

1392
01:04:17,159 --> 01:04:24,179
我将会看到什么

1393
01:04:24,179 --> 01:04:26,459
我们可能会看到一个URL打印两次，或者说被爬取两遍

1394
01:04:26,459 --> 01:04:28,589
是的 你会想

1395
01:04:28,589 --> 01:04:31,649
那将是个错误

1396
01:04:31,649 --> 01:04:34,799
我运行无锁的代码

1397
01:04:34,799 --> 01:04:36,269
我们看ConcurrentMutex

1398
01:04:36,269 --> 01:04:38,459
中间的这段  这次似乎没有

1399
01:04:38,459 --> 01:04:40,369
爬取任何URL两遍 只有五行

1400
01:04:40,369 --> 01:04:49,139
再运行一次 天哪

1401
01:04:49,139 --> 01:04:50,719
我们可能在浪费时间

1402
01:04:50,719 --> 01:04:52,499
是的 似乎永远不有出错

1403
01:04:52,499 --> 01:04:57,419
实际上我从来没有看到它出错

1404
01:04:57,419 --> 01:05:00,269
虽然如此 代码是错的

1405
01:05:00,269 --> 01:05:03,329
总有一天程序会失败 好的 问题在于

1406
01:05:03,329 --> 01:05:04,559
你懂的

1407
01:05:04,559 --> 01:05:06,179
这里只是几个指令

1408
01:05:06,179 --> 01:05:07,979
而线程有几百个指令

1409
01:05:07,979 --> 01:05:09,539
两个线程同时执行到这几个指令

1410
01:05:09,539 --> 01:05:12,269
且犯错的几率非常低

1411
01:05:12,269 --> 01:05:14,489

1412
01:05:14,489 --> 01:05:17,729
确实 这是

1413
01:05:17,729 --> 01:05:20,459
一个有race bug的代码令人失望的地方

1414
01:05:20,459 --> 01:05:23,519
它通常运行良好

1415
01:05:23,519 --> 01:05:25,289
但当客户在他们的电脑上运行时

1416
01:05:25,289 --> 01:05:28,020
总是可能会出问题

1417
01:05:28,020 --> 01:05:30,510
所以 这对我们是个坏消息

1418
01:05:30,510 --> 01:05:32,940
你懂的 这可能出现在

1419
01:05:32,940 --> 01:05:34,920
复杂的程序里

1420
01:05:34,920 --> 01:05:37,170
非常难搞清楚你是不有一个race

1421
01:05:37,170 --> 01:05:39,390
你可能会 你可能会有一段代码

1422
01:05:39,390 --> 01:05:41,910
看起来非常合理

1423
01:05:41,910 --> 01:05:44,610
但实际上有某些你未知的race

1424
01:05:44,610 --> 01:05:47,970
是使用共享变量导致的

1425
01:05:47,970 --> 01:05:50,040
在实践中唯一能发现race的方法是

1426
01:05:50,040 --> 01:05:53,580
使用自动化的工具 幸运的是

1427
01:05:53,580 --> 01:05:55,890
go给我们提供了一个很不错的race探测器

1428
01:05:55,890 --> 01:06:00,119
内置于go

1429
01:06:00,119 --> 01:06:04,619
你应该使用它 如果你把 -race 作为命令行参数

1430
01:06:04,619 --> 01:06:06,540
当你必须让你的go程序

1431
01:06:06,540 --> 01:06:09,710
运行这个race探测器

1432
01:06:09,710 --> 01:06:11,760
好的 我将会运行race检测器

1433
01:06:11,760 --> 01:06:16,650
我们将会看到 它发出了一个错误信息

1434
01:06:16,650 --> 01:06:19,680
它已经找到一个race

1435
01:06:19,680 --> 01:06:21,420
实际它上告诉我们

1436
01:06:21,420 --> 01:06:23,550
race发生的准确位置 输出里有很多废物

1437
01:06:23,550 --> 01:06:25,260
但是真正关键的是

1438
01:06:25,260 --> 01:06:28,320
race检测器意识到

1439
01:06:28,320 --> 01:06:30,180
我们读了一个变量

1440
01:06:30,180 --> 01:06:32,790
读取的内容是之前写入的

1441
01:06:32,790 --> 01:06:35,670
并且（这两个操作）中间

1442
01:06:35,670 --> 01:06:37,770
没有锁的释放和申请

1443
01:06:37,770 --> 01:06:40,200
此外 它告诉我们

1444
01:06:40,200 --> 01:06:43,710
行号 所以它告诉我们

1445
01:06:43,710 --> 01:06:49,290
读取在第43行 写入

1446
01:06:49,290 --> 01:06:51,660
之前的写入在第44行 确实

1447
01:06:51,660 --> 01:06:53,190
我们看代码 读操作在第43行

1448
01:06:53,190 --> 01:06:56,220
写操作在第44行

1449
01:06:56,220 --> 01:06:58,170
这意味着一个线程在第44行

1450
01:06:58,170 --> 01:07:00,869
执行了写入

1451
01:07:00,869 --> 01:07:02,520
之后没有任何锁介入

1452
01:07:02,520 --> 01:07:05,340
并且之后另一个线程在第43行读取了这个写入的数据

1453
01:07:05,340 --> 01:07:07,560
这些就是race探测器寻找的

1454
01:07:07,560 --> 01:07:10,020
它工作的原理

1455
01:07:10,020 --> 01:07:11,820
内部地 探测器分配了

1456
01:07:11,820 --> 01:07:15,000
某种隐蔽内存 分配了某种 你懂的

1457
01:07:15,000 --> 01:07:16,260
它使用了大量的内存

1458
01:07:16,260 --> 01:07:17,460
基本上对于每一个内存位置

1459
01:07:17,460 --> 01:07:19,710
race探测器

1460
01:07:19,710 --> 01:07:21,600
都被分配了少量内存

1461
01:07:21,600 --> 01:07:24,330
用于跟踪哪些线程

1462
01:07:24,330 --> 01:07:26,400
最近读取或者写入了任何内存位置

1463
01:07:26,400 --> 01:07:28,590
然后

1464
01:07:28,590 --> 01:07:30,810
它也跟踪

1465
01:07:30,810 --> 01:07:32,609
线程申请锁和释放锁

1466
01:07:32,609 --> 01:07:35,430
以及别的强制线程

1467
01:07:35,430 --> 01:07:37,980
以非并发形式运行的

1468
01:07:37,980 --> 01:07:39,180
同步活动

1469
01:07:39,180 --> 01:07:40,980
如果race探测器看到

1470
01:07:40,980 --> 01:07:42,450
有内存位置被写入

1471
01:07:42,450 --> 01:07:45,210
然后被读取

1472
01:07:45,210 --> 01:07:49,160
而且中间没有锁 它就会报错

1473
01:07:49,160 --> 01:08:06,600
是的 我相信这并不完美

1474
01:08:06,600 --> 01:08:12,170
我必须要思考一下

1475
01:08:12,170 --> 01:08:15,180
当然一个不完美的情况是

1476
01:08:15,180 --> 01:08:18,899
如果你不执行任何代码

1477
01:08:18,899 --> 01:08:21,270
那么race探测器不会知道任何事

1478
01:08:21,270 --> 01:08:25,109
它将不会分析

1479
01:08:25,109 --> 01:08:27,990
它并不是做静态分析

1480
01:08:27,990 --> 01:08:29,220
race探测器不会看你的源代码

1481
01:08:29,220 --> 01:08:31,770
不会基于源代码作出判断

1482
01:08:31,770 --> 01:08:33,390
某种程度上 它观察

1483
01:08:33,390 --> 01:08:35,700
一次具体的程序运行

1484
01:08:35,700 --> 01:08:37,649
所以如果这次

1485
01:08:37,649 --> 01:08:39,330
具体的程序运行 没有执行

1486
01:08:39,330 --> 01:08:42,450
某些恰好读写共享数据的代码

1487
01:08:42,450 --> 01:08:44,370
那么race探测器不可能知道（有race）

1488
01:08:44,370 --> 01:08:46,500
但这里可能确实有race

1489
01:08:46,500 --> 01:08:48,270
这是需要小心的地方

1490
01:08:48,270 --> 01:08:49,319
你懂的 如果你想

1491
01:08:49,319 --> 01:08:50,580
认真对待race探测器

1492
01:08:50,580 --> 01:08:53,100
你需要设置某种测试装置

1493
01:08:53,100 --> 01:08:55,620
以确保所有的代码

1494
01:08:55,620 --> 01:08:59,340
都被执行 但是这是 非常好

1495
01:08:59,340 --> 01:09:01,620
你需要把它用在你的6.824lab中

1496
01:09:01,620 --> 01:09:07,830
这是这里的race

1497
01:09:07,830 --> 01:09:09,300
当然这个race没有真的发生

1498
01:09:09,300 --> 01:09:12,330
race探测器没有看到

1499
01:09:12,330 --> 01:09:14,370
这些敏感代码真的同时执行交织在一起

1500
01:09:14,370 --> 01:09:17,370

1501
01:09:17,370 --> 01:09:18,899
它没有看到两个线程

1502
01:09:18,899 --> 01:09:21,859
同时执行第43行和第44行

1503
01:09:21,859 --> 01:09:23,970
我们知道

1504
01:09:23,970 --> 01:09:25,140
我们已经手动运行了过几次

1505
01:09:25,140 --> 01:09:28,319
显而易见race并没有发生 或者概率很小

1506
01:09:28,319 --> 01:09:29,880
探测器看到的只是 某时刻有一个写操作

1507
01:09:29,880 --> 01:09:31,529
很久之后有一个读操作

1508
01:09:31,529 --> 01:09:37,620
没有锁隔开

1509
01:09:37,620 --> 01:09:39,180
从那种意义上 它能探测到

1510
01:09:39,180 --> 01:09:41,540
不一定真的会发生的race

1511
01:09:41,540 --> 01:09:47,630
或者不会真的导致bug

1512
01:09:49,540 --> 01:09:52,550
好的 最后一个关于这个crawler的问题

1513
01:09:52,550 --> 01:09:57,550
它创建了多少个线程

1514
01:10:03,639 --> 01:10:10,119
最多有多少个并发的线程

1515
01:10:10,119 --> 01:10:24,969
是的 这个crawler的缺陷是

1516
01:10:24,969 --> 01:10:27,159
没有一个明显的

1517
01:10:27,159 --> 01:10:28,719
同时存在线程的

1518
01:10:28,719 --> 01:10:30,580
数量界限 你懂的

1519
01:10:30,580 --> 01:10:32,800
在这个测试数据下，只有5个URL

1520
01:10:32,800 --> 01:10:34,659
如果你爬取真实的网络

1521
01:10:34,659 --> 01:10:36,610
真实的网络 我不确定

1522
01:10:36,610 --> 01:10:38,380
有数十亿的URL在那儿

1523
01:10:38,380 --> 01:10:40,389
我们当然不希望

1524
01:10:40,389 --> 01:10:41,380
遇到这种情况 crawler可能

1525
01:10:41,380 --> 01:10:43,380
意外地创建了数十亿计的线程

1526
01:10:43,380 --> 01:10:46,119
因为 你懂的 几千个线程

1527
01:10:46,119 --> 01:10:47,889
没问题 数十亿计个线程是不行

1528
01:10:47,889 --> 01:10:51,070
因为每个（线程）

1529
01:10:51,070 --> 01:10:54,280
占据一定量的内存

1530
01:10:54,280 --> 01:10:56,080
在现实中这个crawler

1531
01:10:56,080 --> 01:10:58,270
可能有很多缺陷 在我们讨论的这一层

1532
01:10:58,270 --> 01:11:00,219
它确实创建太多线程

1533
01:11:00,219 --> 01:11:01,600
最好有一种方式

1534
01:11:01,600 --> 01:11:03,280
可以创建 好比20,000个

1535
01:11:03,280 --> 01:11:04,630
或100个 或1000个线程

1536
01:11:04,630 --> 01:11:06,520
但是不会更多

1537
01:11:06,520 --> 01:11:08,199
一个方式是预先创建

1538
01:11:08,199 --> 01:11:11,050
一个固定大小的线程池

1539
01:11:11,050 --> 01:11:13,179
池中的worker迭代地

1540
01:11:13,179 --> 01:11:14,830
寻找下一个要爬取的URL

1541
01:11:14,830 --> 01:11:18,159
而不是为每个URL创建新的线程

1542
01:11:18,159 --> 01:11:21,070
所以 接下来我想要

1543
01:11:21,070 --> 01:11:23,230
讨论另一种crawler

1544
01:11:23,230 --> 01:11:25,600
它的实现方式显著不同

1545
01:11:25,600 --> 01:11:28,780
使用了channel

1546
01:11:28,780 --> 01:11:31,869
而不是共享内存

1547
01:11:31,869 --> 01:11:33,489
回忆之前的版本

1548
01:11:33,489 --> 01:11:34,840
记录URL的表格被所有线程共享

1549
01:11:34,840 --> 01:11:36,550
必须加锁

1550
01:11:36,550 --> 01:11:40,330
这个版本没有这样一个（共享）的表格

1551
01:11:40,330 --> 01:11:44,440
没有共享内存

1552
01:11:44,440 --> 01:11:52,510
不需要使用锁 好的

1553
01:11:52,510 --> 01:11:55,060
相反地 有一个master线程

1554
01:11:55,060 --> 01:11:57,790
第86行的master函数

1555
01:11:57,790 --> 01:12:00,699
它有一个表格

1556
01:12:00,699 --> 01:12:02,800
但是这个表格是master函数私有的

1557
01:12:02,800 --> 01:12:06,690
master函数并不像前一个版本那样

1558
01:12:06,690 --> 01:12:09,219
创建

1559
01:12:09,219 --> 01:12:11,409
一棵函数调用树

1560
01:12:11,409 --> 01:12:13,330
以对应图结构的搜索

1561
01:12:13,330 --> 01:12:17,940
这个版本

1562
01:12:17,940 --> 01:12:21,880
为每个URL创建一个goroutine

1563
01:12:21,880 --> 01:12:23,770
但是只由master来创建

1564
01:12:23,770 --> 01:12:26,560
只有唯一一个master

1565
01:12:26,560 --> 01:12:28,300
创建这些线程 所以我们没有

1566
01:12:28,300 --> 01:12:30,130
一个函数的树形结构

1567
01:12:30,130 --> 01:12:35,199
我们只有一个master 好的

1568
01:12:35,199 --> 01:12:37,540
它在第88行创建了自己的私有的map

1569
01:12:37,540 --> 01:12:41,550
记录哪些URL已经爬取

1570
01:12:41,550 --> 01:12:44,650
然后创建一个channel

1571
01:12:44,650 --> 01:12:46,900
只有一个channel 所有的worker线程

1572
01:12:46,900 --> 01:12:49,120
都将通过这个channel沟通

1573
01:12:49,120 --> 01:12:50,699
这个思路是 启动一个worker线程

1574
01:12:50,699 --> 01:12:53,040
每个worker线程

1575
01:12:53,040 --> 01:12:55,630
在结束时

1576
01:12:55,630 --> 01:12:58,150
只会通过channel发送恰好一份数据

1577
01:12:58,150 --> 01:13:00,250
给master

1578
01:13:00,250 --> 01:13:03,219
这份数据包含了这个worker

1579
01:13:03,219 --> 01:13:07,960
从网页上爬取的网页中的URL的列表

1580
01:13:07,960 --> 01:13:10,420
master在第89行循环中 从channel中

1581
01:13:10,420 --> 01:13:13,989
读取数据

1582
01:13:13,989 --> 01:13:16,780
我们想象

1583
01:13:16,780 --> 01:13:20,469
它已经预先启动一些worker

1584
01:13:20,469 --> 01:13:22,840
现在读取

1585
01:13:22,840 --> 01:13:24,489
这些worker发回的URL列表

1586
01:13:24,489 --> 01:13:26,830
每当89行拿到一个URL

1587
01:13:26,830 --> 01:13:28,810
它遍历

1588
01:13:28,810 --> 01:13:32,620
这些从爬取的网页中获得的

1589
01:13:32,620 --> 01:13:36,100
URL列表里的URL

1590
01:13:36,100 --> 01:13:39,969
如果URL还未被爬取，它将在第94行

1591
01:13:39,969 --> 01:13:42,190
启动一个新的worker去爬取那个URL

1592
01:13:42,190 --> 01:13:44,800
我们看worker代码

1593
01:13:44,800 --> 01:13:47,320
第77行 从第77行开始 大概是说

1594
01:13:47,320 --> 01:13:51,130
调用fetcher 然后第80行，82行

1595
01:13:51,130 --> 01:13:53,710
发送信息给channel

1596
01:13:53,710 --> 01:13:57,929
这是爬取的网页中的URLs

1597
01:13:57,929 --> 01:14:01,170
注意到

1598
01:14:01,170 --> 01:14:03,639
可能有趣的事情是

1599
01:14:03,639 --> 01:14:07,989
worker线程不共享任何对象

1600
01:14:07,989 --> 01:14:10,210
worker和master之间

1601
01:14:10,210 --> 01:14:11,530
也不共享任何对象

1602
01:14:11,530 --> 01:14:12,850
所以我们不必担心锁

1603
01:14:12,850 --> 01:14:16,360
我们不必担心race

1604
01:14:16,360 --> 01:14:18,940
这是通信的例子

1605
01:14:18,940 --> 01:14:21,100
而不是通过

1606
01:14:21,100 --> 01:14:25,620
共享内存 是的

1607
01:14:33,930 --> 01:14:38,140
是的 可以观察到

1608
01:14:38,140 --> 01:14:40,810
代码看上去好像 但是worker是

1609
01:14:40,810 --> 01:14:42,250
可以观察到 worker在改变channel

1610
01:14:42,250 --> 01:14:47,130
同时master在读channel

1611
01:14:49,170 --> 01:14:51,520
go的作者不会希望

1612
01:14:51,520 --> 01:14:54,160
你们这样理解

1613
01:14:54,160 --> 01:14:55,360
他们希望你这么思考

1614
01:14:55,360 --> 01:14:58,030
ch是channel，channel有

1615
01:14:58,030 --> 01:15:00,880
发送和接收操作

1616
01:15:00,880 --> 01:15:03,070
worker发送到channel上

1617
01:15:03,070 --> 01:15:05,260
同时master读channel

1618
01:15:05,260 --> 01:15:09,250
这完全合法 channel毫无压力

1619
01:15:09,250 --> 01:15:11,050
我的意思是 那意味着

1620
01:15:11,050 --> 01:15:12,790
channel内部实现中

1621
01:15:12,790 --> 01:15:15,610
有一个互斥锁

1622
01:15:15,610 --> 01:15:19,000
当它们把channel内部数据混在一起时

1623
01:15:19,000 --> 01:15:20,860
channel的操作小心的

1624
01:15:20,860 --> 01:15:22,449
使用了互斥锁

1625
01:15:22,449 --> 01:15:24,190
来保证

1626
01:15:24,190 --> 01:15:27,580
实际上没有任何race 是的

1627
01:15:27,580 --> 01:15:29,290
channel被保护了起来 免受并发风险

1628
01:15:29,290 --> 01:15:30,400
你可以在不同的线程中

1629
01:15:30,400 --> 01:15:34,680
并发地使用它 是的

1630
01:15:36,389 --> 01:15:43,190
通过channel接收 是的

1631
01:15:53,810 --> 01:15:56,260
我们不需要关闭channel

1632
01:15:56,260 --> 01:15:58,850
我的意思是 好吧 这个break语句

1633
01:15:58,850 --> 01:16:00,590
当crawl完全结束

1634
01:16:00,590 --> 01:16:03,160
我们爬取了每个URL

1635
01:16:03,160 --> 01:16:06,410
发生的事情是

1636
01:16:06,410 --> 01:16:09,230
master持续  我的意思是 这个n

1637
01:16:09,230 --> 01:16:13,190
是私有的 每当master

1638
01:16:13,190 --> 01:16:14,860
启动一个worker 会增加n

1639
01:16:14,860 --> 01:16:17,360
每个启动的worker

1640
01:16:17,360 --> 01:16:20,480
发送恰好一个东西到channel上

1641
01:16:20,480 --> 01:16:21,920
所以每次master从channel读取一个

1642
01:16:21,920 --> 01:16:23,120
就能知道 一个worker

1643
01:16:23,120 --> 01:16:24,920
已经结束 当worker数目

1644
01:16:24,920 --> 01:16:29,060
降为0

1645
01:16:29,060 --> 01:16:32,870
我们就完成了 我们不 一旦

1646
01:16:32,870 --> 01:16:34,520
当所有worker的数目降为0

1647
01:16:34,520 --> 01:16:36,500
之后唯一引用channel的

1648
01:16:36,500 --> 01:16:40,370
是master函数 或者

1649
01:16:40,370 --> 01:16:41,780
是调用master的代码

1650
01:16:41,780 --> 01:16:43,460
垃圾回收器很快看到

1651
01:16:43,460 --> 01:16:45,260
这个channel没有被引用

1652
01:16:45,260 --> 01:16:48,680
将会释放这个channel

1653
01:16:48,680 --> 01:16:50,060
在这种情况下 有时你需要关闭channel

1654
01:16:50,060 --> 01:16:53,630
实际上 我很少必须要

1655
01:16:53,630 --> 01:16:56,170
关闭channel

1656
01:17:03,150 --> 01:17:06,050
你能重复一遍吗

1657
01:17:09,749 --> 01:17:12,219
问题说的是

1658
01:17:12,219 --> 01:17:16,389
看第106行 在调用master之前

1659
01:17:16,389 --> 01:17:19,949
并发channel某种程度启动了一个

1660
01:17:19,949 --> 01:17:25,659
把一个URL塞进了channel

1661
01:17:25,659 --> 01:17:26,710
这样开始整个流程

1662
01:17:26,710 --> 01:17:28,059
因为master代码这样写的

1663
01:17:28,059 --> 01:17:29,469
你懂的 在第89行master直接

1664
01:17:29,469 --> 01:17:31,749
从channel读取数据

1665
01:17:31,749 --> 01:17:33,489
所以最开始channel中要有数据

1666
01:17:33,489 --> 01:17:36,550
否则89行将永远阻塞

1667
01:17:36,550 --> 01:17:38,260
如果没有107行的代码

1668
01:17:38,260 --> 01:17:42,550
89行将block在读channel上

1669
01:17:42,550 --> 01:17:44,050
一直在channel上读取

1670
01:17:44,050 --> 01:17:54,460
这段代码不能工作 是的

1671
01:17:54,460 --> 01:17:56,289
一个观察是 天哪 如果

1672
01:17:56,289 --> 01:17:57,510
写出的代码

1673
01:17:57,510 --> 01:17:59,530
能够注意到

1674
01:17:59,530 --> 01:18:01,570
是否有东西在等待channel 就好了

1675
01:18:01,570 --> 01:18:03,219
如果你去看select语句 你可以做到

1676
01:18:03,219 --> 01:18:05,019
它更复杂

1677
01:18:05,019 --> 01:18:06,579
但是select语句

1678
01:18:06,579 --> 01:18:09,460
让你免于block 继续执行

1679
01:18:09,460 --> 01:18:11,139
如果没有等待在channel

1680
01:18:11,139 --> 01:18:13,590
如果没有等待在channel

1681
01:18:44,590 --> 01:18:59,600
因为worker没有结束 好的 抱歉

1682
01:18:59,600 --> 01:19:02,600
对于第一个问题 我觉得

1683
01:19:02,600 --> 01:19:03,830
你真正担心的是

1684
01:19:03,830 --> 01:19:05,630
我们是否真的能够并行启动

1685
01:19:05,630 --> 01:19:09,110
最开始的第一个fetch不会并行

1686
01:19:09,110 --> 01:19:37,220
因为

1687
01:19:37,220 --> 01:19:40,270
不 不 不 for循环在第89行等待

1688
01:19:40,270 --> 01:19:44,450
89行的for loop

1689
01:19:44,450 --> 01:19:47,660
并不是 遍历当前channel的内容

1690
01:19:47,660 --> 01:19:49,190
然后退出

1691
01:19:49,190 --> 01:19:54,230
89行的for循环将会读

1692
01:19:54,230 --> 01:19:58,100
它可以永不退出

1693
01:19:58,100 --> 01:19:59,780
它将一直等待

1694
01:19:59,780 --> 01:20:01,130
直到有东西出现在channel中

1695
01:20:01,130 --> 01:20:04,280
所以 如果没有第99行的break

1696
01:20:04,280 --> 01:20:10,250
for循环不会被结束 是的 好

1697
01:20:10,250 --> 01:20:12,440
恐怕我们时间到了 我们会继续

1698
01:20:12,440 --> 01:20:15,800
事实上我们的助教安排了一场展示

1699
01:20:15,800 --> 01:20:16,260
在那儿会聊更多关于go的话题

1700
01:20:16,260 --> 01:20:18,260
在那儿会聊更多关于go的话题

