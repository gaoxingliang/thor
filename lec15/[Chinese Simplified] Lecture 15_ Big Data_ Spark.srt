1
00:00:06,899 --> 00:00:13,209
好的，今天我们将

2
00:00:13,209 --> 00:00:17,770
讨论 spark 本质上说是

3
00:00:17,770 --> 00:00:21,370
MapReduce 的继任者，您可以将

4
00:00:21,370 --> 00:00:24,400
其视为 MapReduce 的一种进化步骤，

5
00:00:24,400 --> 00:00:28,600
我们正在研究它的一个原因

6
00:00:28,600 --> 00:00:31,210
是它今天广泛用于

7
00:00:31,210 --> 00:00:34,149
数据中心 事实

8
00:00:34,149 --> 00:00:37,260
证明非常流行和非常有用

9
00:00:37,260 --> 00:00:40,359
的计算它所做的一件有趣的事情会

10
00:00:40,359 --> 00:00:41,589
引起注意的是，它

11
00:00:41,589 --> 00:00:43,780
概括了 MapReduce 的两个阶段，

12
00:00:43,780 --> 00:00:47,550
将地图引入到

13
00:00:47,550 --> 00:00:51,339
多步数据流

14
00:00:51,339 --> 00:00:57,579
图的完整概念中 它既

15
00:00:57,579 --> 00:00:59,679
有助于程序员的灵活性，它更具

16
00:00:59,679 --> 00:01:02,139
表现力，也为系统提供

17
00:01:02,139 --> 00:01:04,229
了更多的 SPARC 系统，

18
00:01:04,229 --> 00:01:07,530
当涉及到优化和

19
00:01:07,530 --> 00:01:09,490
处理

20
00:01:09,490 --> 00:01:12,759
故障时，它还支持从

21
00:01:12,759 --> 00:01:14,110
程序员的角度来看它支持

22
00:01:14,110 --> 00:01:16,539
迭代应用程序应用程序说

23
00:01:16,539 --> 00:01:19,140
你知道循环数据比生成我们的数据有效

24
00:01:19,140 --> 00:01:21,909
得多，你

25
00:01:21,909 --> 00:01:24,180
可以用多个 MapReduc 拼凑很多东西

26
00:01:24,180 --> 00:01:27,579
e 应用程序

27
00:01:27,579 --> 00:01:30,100
一个接一个地运行，但

28
00:01:30,100 --> 00:01:36,149
在 SPARC 中使用起来更方便，所以我

29
00:01:36,149 --> 00:01:38,350
想我会

30
00:01:38,350 --> 00:01:41,909
从一个示例应用程序开始，这

31
00:01:41,909 --> 00:01:47,439
是 PageRank 的代码，我将复制

32
00:01:47,439 --> 00:01:52,840
这段代码 火花源

33
00:01:52,840 --> 00:01:56,789
中的一些示例源代码的一些更改

34
00:01:57,520 --> 00:02:01,510
我想它

35
00:02:01,510 --> 00:02:02,680
实际上有点难以阅读让

36
00:02:02,680 --> 00:02:04,240
我给我第二条法则试着

37
00:02:04,240 --> 00:02:06,479
让它更大

38
00:02:14,860 --> 00:02:18,140
好吧如果这是如果这

39
00:02:18,140 --> 00:02:20,120
太难阅读了 注释中是否有它的副本，它

40
00:02:20,120 --> 00:02:22,940
是代码的扩展，

41
00:02:22,940 --> 00:02:26,570
以及论文中的第 3 至 2 节

42
00:02:26,570 --> 00:02:31,040
页面排名，这是一种算法，

43
00:02:31,040 --> 00:02:33,500
谷歌使用非常著名的算法来

44
00:02:33,500 --> 00:02:38,800
计算不同的网络

45
00:02:38,800 --> 00:02:42,380
搜索结果的重要性是什么 PageRank 正在

46
00:02:42,380 --> 00:02:43,400
尝试

47
00:02:43,400 --> 00:02:46,700
实际上做得好 PageRank 被广泛

48
00:02:46,700 --> 00:02:49,180
用作

49
00:02:49,180 --> 00:02:51,350
实际上并不能很好地工作的示例和

50
00:02:51,350 --> 00:02:53,680
MapReduce，原因

51
00:02:53,680 --> 00:02:56,510
是 PageRank 涉及一堆

52
00:02:56,510 --> 00:02:58,640
不同的步骤，更糟糕的是 PageRank

53
00:02:58,640 --> 00:03:01,130
涉及迭代 里面有一个循环

54
00:03:01,130 --> 00:03:03,550
，必须运行很多次，

55
00:03:03,550 --> 00:03:06,130
MapReduce 对迭代无话可说

56
00:03:06,130 --> 00:03:12,970
 

57
00:03:12,970 --> 00:03:15,860
这个版本的 PageRank 的输入 PageRank 只是网络中

58
00:03:15,860 --> 00:03:20,959
每个链接一个行的巨大集合，

59
00:03:20,959 --> 00:03:23,360
然后每行有两个

60
00:03:23,360 --> 00:03:26,120
URLs 包含链接的页面的 URL 以及该页面

61
00:03:26,120 --> 00:03:28,550
指向的链接的 URL，

62
00:03:28,550 --> 00:03:31,730
并且您

63
00:03:31,730 --> 00:03:33,920
知道是否意图是通过

64
00:03:33,920 --> 00:03:36,050
抓取 Web 并查看

65
00:03:36,050 --> 00:03:38,390
所有收集到的所有链接中的所有链接来获取此文件

66
00:03:38,390 --> 00:03:40,370
web 的输入绝对是

67
00:03:40,370 --> 00:03:46,790
巨大的，

68
00:03:46,790 --> 00:03:49,610
从

69
00:03:49,610 --> 00:03:53,180
我实际运行这段代码开始

70
00:03:53,180 --> 00:03:55,400
，这对

71
00:03:55,400 --> 00:03:56,959
我们来说只是一个

72
00:03:56,959 --> 00:03:59,390
愚蠢的小例子 我

73
00:03:59,390 --> 00:04:03,290
使用 u1 是页面的 URL 和 u3

74
00:04:03,290 --> 00:04:07,519
例如作为该页面指向的链接的 URL，

75
00:04:07,519 --> 00:04:09,489
只是为了方便起见

76
00:04:09,489 --> 00:04:12,830
，所以这个输入

77
00:04:12,830 --> 00:04:15,230
文件表示的网络图只有三个

78
00:04:15,230 --> 00:04:21,320
页面，一二三我 可以

79
00:04:21,320 --> 00:04:22,610
解释链接 有一个从

80
00:04:22,610 --> 00:04:24,430
一

81
00:04:24,430 --> 00:04:27,419
二三的链接 从一回到

82
00:04:27,419 --> 00:04:30,240
自身的链接 从二到三的网络链接 从二到

83
00:04:30,240 --> 00:04:32,710
三的网络链接 从二到

84
00:04:32,710 --> 00:04:35,500
自身的网络链接 从三到一的网络链接

85
00:04:35,500 --> 00:04:39,190
就像一个非常简单的图表

86
00:04:39,190 --> 00:04:42,820
构建 PageRank 试图

87
00:04:42,820 --> 00:04:45,100
做的事情 你知道吗 估计

88
00:04:45,100 --> 00:04:47,800
每个页面的重要性 真正的意思是

89
00:04:47,800 --> 00:04:50,620
它

90
00:04:50,620 --> 00:04:53,500
根据其他重要页面是否

91
00:04:53,500 --> 00:04:56,979
有指向给定页面的链接来估计重要性

92
00:04:56,979 --> 00:04:58,210
，而这里真正发生的是这种

93
00:04:58,210 --> 00:05:01,150
建模 估计

94
00:05:01,150 --> 00:05:05,050
点击链接的用户将在

95
00:05:05,050 --> 00:05:08,199
每个给定页面上结束的概率，因此它具有这种用户

96
00:05:08,199 --> 00:05:11,710
模型，其中用户有 85% 的

97
00:05:11,710 --> 00:05:14,289
机会跟随来自用户当前页面的链接跟随来自

98
00:05:14,289 --> 00:05:17,199
用户当前页面的随机

99
00:05:17,199 --> 00:05:19,150
选择的链接

100
00:05:19,150 --> 00:05:21,810
到 无论该链接指向何处，即使没有指向该链接的链接，也有

101
00:05:21,810 --> 00:05:25,900
15% 的机会简单地切换到

102
00:05:25,900 --> 00:05:27,220
其他页面，

103
00:05:27,220 --> 00:05:29,080
如果您知道

104
00:05:29,080 --> 00:05:33,330
直接在浏览器中输入了 URL

105
00:05:33,330 --> 00:05:38,949
r 的想法是，他喝的

106
00:05:38,949 --> 00:05:43,570
算法会反复运行

107
00:05:43,570 --> 00:05:45,400
它，它有点模拟用户

108
00:05:45,400 --> 00:05:48,400
查看页面，然后点击链接

109
00:05:48,400 --> 00:05:51,610
，并将起始页面的重要性添加

110
00:05:51,610 --> 00:05:53,860
到目标页面的重要性，然后

111
00:05:53,860 --> 00:05:55,720
再次运行它

112
00:05:55,720 --> 00:06:00,909
它最终会出现在系统中，就像

113
00:06:00,909 --> 00:06:02,889
SPARC 上的页面排名一样，它将

114
00:06:02,889 --> 00:06:06,280
对所有页面并行运行这个模拟，

115
00:06:06,280 --> 00:06:09,030
或者

116
00:06:09,900 --> 00:06:13,030
说它的想法是它会

117
00:06:13,030 --> 00:06:14,680
跟踪算法会

118
00:06:14,680 --> 00:06:16,780
跟踪页面排名 每个

119
00:06:16,780 --> 00:06:19,560
页面或每个 URL 并

120
00:06:19,560 --> 00:06:22,300
在模拟随机用户

121
00:06:22,300 --> 00:06:24,610
点击时

122
00:06:24,610 --> 00:06:27,870
对其进行更新

123
00:06:27,870 --> 00:06:31,529
 

124
00:06:31,529 --> 00:06:34,739
 

125
00:06:34,739 --> 00:06:37,259
 

126
00:06:37,259 --> 00:06:39,329
痛苦 它不能只是一个 MapReduce

127
00:06:39,329 --> 00:06:45,439
程序 它必须是多个 你知道

128
00:06:45,439 --> 00:06:48,599
对 MapReduce

129
00:06:48,599 --> 00:06:51,359
应用程序的多次调用，其中每个调用都

130
00:06:51,359 --> 00:06:53,879
模拟迭代中的一个步骤，所以

131
00:06:53,879 --> 00:06:55,739
你可以在 M  apReduce 但它很

132
00:06:55,739 --> 00:06:58,049
痛苦，而且它也是一种坡度，因为

133
00:06:58,049 --> 00:07:00,479
MapReduce 它只考虑一个

134
00:07:00,479 --> 00:07:02,429
映射和一个减少，它总是

135
00:07:02,429 --> 00:07:05,279
从磁盘和 GFS 文件系统的 GFS 读取它的输入，

136
00:07:05,279 --> 00:07:07,139
并总是

137
00:07:07,139 --> 00:07:09,089
写入它的输出，这将是

138
00:07:09,089 --> 00:07:12,989
这种更新的 每个

139
00:07:12,989 --> 00:07:17,069
阶段的页面排名也会将每页更新的

140
00:07:17,069 --> 00:07:19,829
排名写入 GFS 中的文件，因此

141
00:07:19,829 --> 00:07:23,009
如果您将其作为一系列 MapReduce 应用程序运行，则会有很多文件 i/o，

142
00:07:23,009 --> 00:07:26,839
 

143
00:07:26,839 --> 00:07:31,279
所以我们在这里有这个总和，

144
00:07:31,279 --> 00:07:32,779
有一个 PageRank 代码 随之

145
00:07:32,779 --> 00:07:35,869
而来的火花我真的会

146
00:07:35,869 --> 00:07:38,629
为你运行它我会为你运行整个

147
00:07:38,629 --> 00:07:40,009
事情

148
00:07:40,009 --> 00:07:42,499
这里显示的输入代码

149
00:07:42,499 --> 00:07:44,359
我只是为了看看最终

150
00:07:44,359 --> 00:07:46,999
输出是什么然后我' 我会看一遍，

151
00:07:46,999 --> 00:07:50,259
我们将一步一步地

152
00:07:52,679 --> 00:07:56,529
展示它是如何执行的

153
00:07:56,529 --> 00:08:02,619
 

154
00:08:02,619 --> 00:08:05,739
 

155
00:08:05,739 --> 00:08:10,199
 

156
00:08:10,199 --> 00:08:14,349
现在这就是我

157
00:08:14,349 --> 00:08:17,019
读它的方式我有哟 你知道我已经

158
00:08:17,019 --> 00:08:19,809
将 SPARC 的副本下载到我的笔记本电脑上，结果证明它

159
00:08:19,809 --> 00:08:23,529
非常简单，如果它是它的预

160
00:08:23,529 --> 00:08:27,129
编译版本，我可以运行它，

161
00:08:27,129 --> 00:08:29,229
只需在 Java 虚拟机

162
00:08:29,229 --> 00:08:30,849
中运行我可以很容易地运行它，所以它实际上是

163
00:08:30,849 --> 00:08:33,789
下载 SPARC 并运行

164
00:08:33,789 --> 00:08:35,769
简单的东西非常

165
00:08:35,769 --> 00:08:37,559
简单，所以我将运行

166
00:08:37,559 --> 00:08:40,149
我显示的代码和我显示的输入

167
00:08:40,149 --> 00:08:43,419
，我们会看到很多

168
00:08:43,419 --> 00:08:48,160
垃圾错误消息，但

169
00:08:48,160 --> 00:08:52,089
最后 support 运行程序并

170
00:08:52,089 --> 00:08:53,620
打印最终结果，我们得到

171
00:08:53,620 --> 00:08:56,399
了我拥有的三个页面的这三个排名，

172
00:08:56,399 --> 00:09:01,889
显然第一页具有最高排名

173
00:09:02,819 --> 00:09:06,490
，我不完全确定为什么，但这

174
00:09:06,490 --> 00:09:09,160
就是算法最终所做的，

175
00:09:09,160 --> 00:09:10,930
所以你当然知道 我们

176
00:09:10,930 --> 00:09:13,439
对算法本身并没有

177
00:09:13,439 --> 00:09:18,790
那么感兴趣，而是我们如何执行 arc

178
00:09:18,790 --> 00:09:26,470
execute 没关系，所以我将亲自

179
00:09:26,470 --> 00:09:29,170
了解编程模型是什么

180
00:09:29,170 --> 00:09:33,339
和 spark，因为它可能

181
00:09:33,339 --> 00:09:36,730
不像我想要的那样

182
00:09:36,730 --> 00:09:40,779
逐行递程序 到 SPARC

183
00:09:40,779 --> 00:09:44,500
解释器，这样你就可以启动这个

184
00:09:44,500 --> 00:09:49,240
spark shell 东西并直接输入代码，

185
00:09:49,240 --> 00:09:53,430
所以我准备了一个

186
00:09:53,430 --> 00:09:57,730
MapReduce 程序版本，我

187
00:09:57,730 --> 00:10:01,029
可以在这里一次运行一行，所以

188
00:10:01,029 --> 00:10:05,800
第一行就是这一行 在其中它

189
00:10:05,800 --> 00:10:08,649
读取或要求 SPARC 读取此

190
00:10:08,649 --> 00:10:11,019
输入文件，并且您知道

191
00:10:11,019 --> 00:10:15,990
我显示的输入文件，其中包含三个页面，

192
00:10:16,110 --> 00:10:19,059
所以这里注意到的一件事

193
00:10:19,059 --> 00:10:23,110
是，当 Sparky 是一个文件时，

194
00:10:23,110 --> 00:10:27,029
实际上正在读取一个文件 来自

195
00:10:27,029 --> 00:10:29,769
像分布式文件系统这样的 GFS，

196
00:10:29,769 --> 00:10:33,519
恰好是 Hadoop 文件

197
00:10:33,519 --> 00:10:36,579
系统的 HDFS，但是这个 HDFS 文件系统

198
00:10:36,579 --> 00:10:38,709
非常像 GFS，所以如果你有一个巨大的文件

199
00:10:38,709 --> 00:10:40,720
，你会得到一个包含所有 URL 的文件，

200
00:10:40,720 --> 00:10:44,110
所有链接和网络 在 HDFS 上，它

201
00:10:44,110 --> 00:10:46,720
会将该文件

202
00:10:46,720 --> 00:10:49,449
分成很多你知道的

203
00:10:49,449 --> 00:10:51,730
大量文件，它会将文件分片到

204
00:10:51,730 --> 00:10:54,850
很多服务器上，因此

205
00:10:54,850 --> 00:10:57,329
读取文件的真正含义

206
00:10:57,329 --> 00:11:00,759
是 spark 将安排

207
00:11:00,759 --> 00:11:02,740
在每个服务器上运行计算 许多许多

208
00:11:02,740 --> 00:11:05,980
机器中的每一个 其中读取

209
00:11:05,980 --> 00:11:10,209
输入文件的一个块或一个分区

210
00:11:10,209 --> 00:11:13,779
，实际上系统最终或

211
00:11:13,779 --> 00:11:16,209
HDFS 最终将文件大

212
00:11:16,209 --> 00:11:17,889
文件拆分为更多

213
00:11:17,889 --> 00:11:19,319
分区，

214
00:11:19,319 --> 00:11:22,389
然后有工作机器，因此

215
00:11:22,389 --> 00:11:23,860
每台工作机器最终

216
00:11:23,860 --> 00:11:26,410
都会 负责查看

217
00:11:26,410 --> 00:11:28,990
输入文件的多个分区，

218
00:11:28,990 --> 00:11:33,440
这很像 map 的工作方式

219
00:11:33,440 --> 00:11:37,670
mapreduce 好的，所以这是程序中的第一行

220
00:11:37,670 --> 00:11:41,270
，你可能想

221
00:11:41,270 --> 00:11:44,180
知道变量行在

222
00:11:44,180 --> 00:11:46,700
打印行的结果时实际包含什么，但使用

223
00:11:46,700 --> 00:11:50,840
线条点 - 事实证明，

224
00:11:50,840 --> 00:11:53,330
即使看起来我们已经键入

225
00:11:53,330 --> 00:11:55,880
了要求系统读取文件的代码行，

226
00:11:55,880 --> 00:11:58,580
实际上它还没有读取文件

227
00:11:58,580 --> 00:12:02,090
并且暂时不会读取

228
00:12:02,090 --> 00:12:03,470
文件 '真的是用这段代码在这里构建

229
00:12:03,470 --> 00:12:07,030
这段代码所做的不是

230
00:12:07,030 --> 00:12:09,830
导致输入被处理，

231
00:12:09,830 --> 00:12:13,130
而是这段代码所做的是构建一个

232
00:12:13,130 --> 00:12:16,400
沿袭图它为我们想要的计算构建一个配方，

233
00:12:16,400 --> 00:12:19,250
就像

234
00:12:19,250 --> 00:12:20,780
一种沿袭图 h 你在论文的图

235
00:12:20,780 --> 00:12:23,450
三中看到，所以这段代码在

236
00:12:23,450 --> 00:12:25,520
做什么它只是构建谱系

237
00:12:25,520 --> 00:12:27,320
图来构建计算配方，

238
00:12:27,320 --> 00:12:30,890
而不是在计算只有

239
00:12:30,890 --> 00:12:32,960
 

240
00:12:32,960 --> 00:12:35,750
在我们执行论文中

241
00:12:35,750 --> 00:12:39,080
所谓的动作时才真正开始发生时才进行计算 是一个像collect这样的函数

242
00:12:39,080 --> 00:12:42,800
，例如最后告诉标记

243
00:12:42,800 --> 00:12:44,390
哦，看我现在真的想要输出

244
00:12:44,390 --> 00:12:48,230
请去实际执行

245
00:12:48,230 --> 00:12:50,360
谱系图并告诉我

246
00:12:50,360 --> 00:12:51,080
结果是

247
00:12:51,080 --> 00:12:53,840
什么所以线条实际上

248
00:12:53,840 --> 00:12:58,790
是谱系图的一部分，现在不是结果

249
00:12:58,790 --> 00:13:01,220
为了了解

250
00:13:01,220 --> 00:13:03,110
当我们最终运行它时计算会做什么，我们

251
00:13:03,110 --> 00:13:07,730
实际上可以在这一点上询问 SPARC，我们可以

252
00:13:07,730 --> 00:13:09,650
让解释器

253
00:13:09,650 --> 00:13:14,840
继续告诉我们你知道什么我实际上

254
00:13:14,840 --> 00:13:16,640
执行了到目前为止的沿袭图

255
00:13:16,640 --> 00:13:19,780
并告诉我们 结果是什么

256
00:13:19,780 --> 00:13:22,310
，你通过调用一个

257
00:13:22,310 --> 00:13:24,350
动作来做到这

258
00:13:24,350 --> 00:13:27,380
一点

259
00:13:27,380 --> 00:13:31,070
 

260
00:13:31,070 --> 00:13:32,930
期待在这里看到的是你知道

261
00:13:32,930 --> 00:13:34,790
我们到目前为止要求它做的所有事情，谱系

262
00:13:34,790 --> 00:13:36,740
图只是说请阅读一个文件，所以

263
00:13:36,740 --> 00:13:38,120
我们期待看到最终

264
00:13:38,120 --> 00:13:40,570
输出只是文件的内容

265
00:13:40,570 --> 00:13:44,020
，实际上这就是我们得到的

266
00:13:44,020 --> 00:13:46,090
 

267
00:13:46,090 --> 00:13:48,890
这个谱系图这个

268
00:13:48,890 --> 00:13:52,520
转换谱系图的

269
00:13:52,520 --> 00:13:57,350
结果只是一次一行的行序列，

270
00:13:57,350 --> 00:14:01,180
所以它实际上是一组行一

271
00:14:01,180 --> 00:14:03,620
组字符串，每个字符串都包含

272
00:14:03,620 --> 00:14:05,720
一行输入，所以这

273
00:14:05,720 --> 00:14:10,010
是第一行 程序的第二

274
00:14:10,010 --> 00:14:17,180
行是 collect 本质上

275
00:14:17,180 --> 00:14:19,760
只是符号执行链的即时编译

276
00:14:19,760 --> 00:14:23,360
 

277
00:14:23,360 --> 00:14:25,280
 

278
00:14:25,280 --> 00:14:28,220
 

279
00:14:28,220 --> 00:14:30,280
 

280
00:14:30,280 --> 00:14:34,190
获取沿袭图

281
00:14:34,190 --> 00:14:37,100
并

282
00:14:37,100 --> 00:14:39,380
生成描述所有

283
00:14:39,380 --> 00:14:40,940
您知道的各种转换的 java 字节码，在这种

284
00:14:40,940 --> 00:14:42,290
情况下它不是很多，因为我们只是在

285
00:14:42,290 --> 00:14:45,170
读取一个文件，但是当

286
00:14:45,170 --> 00:14:48,040
您调用 collect SPARC 时 SPARC 很好

287
00:14:48,040 --> 00:14:50,810
通过查看 HDFS 找出您想要的数据，

288
00:14:50,810 --> 00:14:53,300
您会知道只需选择一组工作

289
00:14:53,300 --> 00:14:57,380
人员来运行以处理

290
00:14:57,380 --> 00:14:59,120
输入数据的不同分区，它将

291
00:14:59,120 --> 00:15:01,580
编译沿袭图，然后我们

292
00:15:01,580 --> 00:15:03,470
将沿袭图转换为

293
00:15:03,470 --> 00:15:05,660
java 字节码 它将字节码

294
00:15:05,660 --> 00:15:08,240
发送到 spark 选择的所有工作机器

295
00:15:08,240 --> 00:15:10,850
，这些工作机器

296
00:15:10,850 --> 00:15:15,530
执行字节码，字节

297
00:15:15,530 --> 00:15:18,050
码说哦，你知道，请阅读告诉

298
00:15:18,050 --> 00:15:19,880
每个工作人员在输入处读取它的分区

299
00:15:19,880 --> 00:15:24,770
，然后最后收集

300
00:15:24,770 --> 00:15:27,730
出去 并

301
00:15:27,730 --> 00:15:32,120
从工作人员那里取回所有结果数据，所以

302
00:15:32,120 --> 00:15:33,590
在你真正想要一个动作之前，这一切都不会发生

303
00:15:33,590 --> 00:15:34,910
，我们有点

304
00:15:34,910 --> 00:15:37,820
过早地运行收集现在你

305
00:15:37,820 --> 00:15:39,170
通常不会这样做，我只是因为我只是

306
00:15:39,170 --> 00:15:40,970
想看看输出是什么

307
00:15:40,970 --> 00:15:43,460
 

308
00:15:43,460 --> 00:15:46,929
 

309
00:15:46,929 --> 00:15:51,490
如果你看一下我展示的代码，

310
00:15:51,490 --> 00:15:58,179
就是要

311
00:15:58,179 --> 00:16:01,779
 

312
00:16:01,779 --> 00:16:03,429
了解转换的效果。 在

313
00:16:03,429 --> 00:16:06,369
哪一组字符串对应于

314
00:16:06,369 --> 00:16:09,550
我们要调用的输入中的行 map

315
00:16:09,550 --> 00:16:11,740
我们已经询问了系统调用 map

316
00:16:11,740 --> 00:16:13,660
并且 map 的作用是它

317
00:16:13,660 --> 00:16:16,660
在输入的每个元素上运行一个函数，

318
00:16:16,660 --> 00:16:18,699
在这种情况下，或者 输入的每一行

319
00:16:18,699 --> 00:16:22,019
和那个小函数都是 S

320
00:16:22,019 --> 00:16:25,089
箭头，它基本上描述了一个

321
00:16:25,089 --> 00:16:27,160
函数，该函数

322
00:16:27,160 --> 00:16:30,069
在每一行上调用 split 函数 split 只接受一个字符串

323
00:16:30,069 --> 00:16:34,990
并返回一个字符串数组，

324
00:16:34,990 --> 00:16:37,360
在有空格的地方

325
00:16:37,360 --> 00:16:39,730
和最后部分断开

326
00:16:39,730 --> 00:16:42,459
引用部分 0 和 1 的这一行表示对于每一

327
00:16:42,459 --> 00:16:44,740
行输入，我们希望在此转换的输出处

328
00:16:44,740 --> 00:16:48,670
成为该行的第一个

329
00:16:48,670 --> 00:16:51,040
字符串，然后是该行的第二个字符串

330
00:16:51,040 --> 00:16:52,269
，因此我们只是进行了一些

331
00:16:52,269 --> 00:16:54,189
转换 为了将这些字符串

332
00:16:54,189 --> 00:16:55,869
变成

333
00:16:55,869 --> 00:16:59,019
更容易处理的东西，再次

334
00:16:59,019 --> 00:17:00,029
出于好奇，

335
00:17:00,029 --> 00:17:02,799
我将调用collect on links one，只是

336
00:17:02,799 --> 00:17:04,689
为了验证我们理解它的

337
00:17:04,689 --> 00:17:09,329
作用，你可以看到

338
00:17:09,329 --> 00:17:13,898
只有字符串行链接一个 现在为每个链接保存一

339
00:17:13,898 --> 00:17:18,490
对从 URL 和到 URL 的字符串，

340
00:17:18,490 --> 00:17:26,470
当它执行时，

341
00:17:26,470 --> 00:17:28,630
这个映射执行它可以完全

342
00:17:28,630 --> 00:17:30,669
独立地在每个工作人员上在其自己

343
00:17:30,669 --> 00:17:32,799
的输入分区上执行，因为它只是

344
00:17:32,799 --> 00:17:34,720
独立考虑每一行

345
00:17:34,720 --> 00:17:37,630
，不同之间不涉及交互

346
00:17:37,630 --> 00:17:39,100
行或不同的分区，

347
00:17:39,100 --> 00:17:41,950
如果这些，则它正在运行，此映射

348
00:17:41,950 --> 00:17:45,220
是对每个输入记录的纯本地操作，

349
00:17:45,220 --> 00:17:47,860
因此可以

350
00:17:47,860 --> 00:17:49,990
在所有分区上的所有工作人员上完全并行运行，

351
00:17:49,990 --> 00:17:55,929
好的，程序中的下一行

352
00:17:55,929 --> 00:17:59,400
是这称为不同的，

353
00:17:59,400 --> 00:18:02,320
这是怎么回事 在这里，我们

354
00:18:02,320 --> 00:18:04,809
只想计算每个链接一次，所以如果

355
00:18:04,809 --> 00:18:07,390
给定页面有多个链接到另一个

356
00:18:07,390 --> 00:18:10,990
页面，我们只想考虑其中一个以

357
00:18:10,990 --> 00:18:15,789
用于 PageRank 的目的，所以

358
00:18:15,789 --> 00:18:17,679
如果你考虑一下它现在只是寻找重复项

359
00:18:17,679 --> 00:18:19,710
实际上需要

360
00:18:19,710 --> 00:18:23,080
在你知道的

361
00:18:23,080 --> 00:18:28,320
多 TB 数据项集合中查找重复项，

362
00:18:28,320 --> 00:18:30,039
这不是开玩笑，

363
00:18:30,039 --> 00:18:32,110
因为数据项是

364
00:18:32,110 --> 00:18:34,299
随机顺序的，并且 输入以及

365
00:18:34,299 --> 00:18:36,909
distinct 需要做什么，因为 e sirup

366
00:18:36,909 --> 00:18:39,669
用单个输入替换每个重复的输入

367
00:18:39,669 --> 00:18:42,940
distinct 需要以某种方式

368
00:18:42,940 --> 00:18:45,970
汇集所有相同的项目

369
00:18:45,970 --> 00:18:48,010
，这将需要

370
00:18:48,010 --> 00:18:49,780
通信 请记住，所有这些

371
00:18:49,780 --> 00:18:51,720
数据都分布在所有工作人员身上

372
00:18:51,720 --> 00:18:54,100
我们要确保您

373
00:18:54,100 --> 00:18:55,659
知道我们带来的任何人我们都会对

374
00:18:55,659 --> 00:18:58,000
数据进行排序，以便任何

375
00:18:58,000 --> 00:18:59,620
两个相同或在同一个工作人员上的项目，

376
00:18:59,620 --> 00:19:00,970
以便该工作人员可以执行此操作我等一下，

377
00:19:00,970 --> 00:19:02,080
其中三个我 '

378
00:19:02,080 --> 00:19:04,450
要用一个来替换这三个

379
00:19:04,450 --> 00:19:06,789
我的意思是这意味着当它

380
00:19:06,789 --> 00:19:09,130
最终执行时需要

381
00:19:09,130 --> 00:19:12,760
通信它是一个洗牌所以

382
00:19:12,760 --> 00:19:13,990
洗牌将由

383
00:19:13,990 --> 00:19:17,110
散列项目或散列项目

384
00:19:17,110 --> 00:19:18,400
以挑选工人来驱动 这将处理

385
00:19:18,400 --> 00:19:20,169
该项目，然后通过网络发送该项目

386
00:19:20,169 --> 00:19:22,059
，或者您知道

387
00:19:22,059 --> 00:19:24,460
您可能会使用排序

388
00:19:24,460 --> 00:19:26,320
或系统排序来实现对所有输入进行排序

389
00:19:26,320 --> 00:19:30,809
，然后拆分排序 编辑输入

390
00:19:31,870 --> 00:19:35,660
总体的工人，我实际上不

391
00:19:35,660 --> 00:19:37,910
知道它是做什么的，但无论如何

392
00:19:37,910 --> 00:19:40,490
，在这种情况下我将需要大量的计算，

393
00:19:40,490 --> 00:19:42,440
但事实上几乎没有

394
00:19:42,440 --> 00:19:44,240
任何事情发生，因为没有

395
00:19:44,240 --> 00:19:49,300
重复，抱歉，哎呀，

396
00:19:49,300 --> 00:19:54,860
链接到好吧，所以任何人 收集和

397
00:19:54,860 --> 00:19:58,370
作为不同输出的链接

398
00:19:58,370 --> 00:20:02,650
基本上是除了顺序

399
00:20:02,650 --> 00:20:05,630
相同的两个链接一个是

400
00:20:05,630 --> 00:20:07,820
该转换的输入并且

401
00:20:07,820 --> 00:20:09,080
订单更改，因为它当然

402
00:20:09,080 --> 00:20:12,230
必须散列或排序或其他

403
00:20:12,230 --> 00:20:19,310
东西下一个转换是 是

404
00:20:19,310 --> 00:20:24,560
按键分组的，

405
00:20:24,560 --> 00:20:27,890
这里我们想要收集

406
00:20:27,890 --> 00:20:33,050
所有链接，结果是

407
00:20:33,050 --> 00:20:35,120
用小 C 进行计算我们希望

408
00:20:35,120 --> 00:20:36,680
 

409
00:20:36,680 --> 00:20:40,400
将给定页面的所有链接收集到一个地方，所以

410
00:20:40,400 --> 00:20:43,100
按键分组 将按它分组它会

411
00:20:43,100 --> 00:20:45,380
从两个 URL 对中移动所有这些记录

412
00:20:45,380 --> 00:20:47,840
它会按来自 URL 的 URL 对它们进行分组

413
00:20:47,840 --> 00:20:51,160
它会将

414
00:20:51,160 --> 00:20:55,490
来自同一

415
00:20:55,490 --> 00:20:57,650
页面的所有链接聚集在一起它会 实际上将

416
00:20:57,650 --> 00:20:59,840
它们折叠

417
00:20:59,840 --> 00:21:02,000
成每个页面的整个链接集合会将

418
00:21:02,000 --> 00:21:04,190
它们折叠成一个链接列表到该

419
00:21:04,190 --> 00:21:07,780
页面的 URL 以及

420
00:21:07,780 --> 00:21:10,970
从该页面开始的链接列表，这再次

421
00:21:10,970 --> 00:21:17,050
需要沟通，尽管

422
00:21:17,050 --> 00:21:19,490
我怀疑 spark 足够聪明

423
00:21:19,490 --> 00:21:21,590
来优化这一点，因为不同的

424
00:21:21,590 --> 00:21:27,620
已经将所有具有相同

425
00:21:27,620 --> 00:21:31,580
来自 URL 的记录放在同一个工作人员上，

426
00:21:31,580 --> 00:21:35,180
按键组可以很容易而且很可能我

427
00:21:35,180 --> 00:21:36,500
根本不需要通信，因为

428
00:21:36,500 --> 00:21:38,090
它可以观察到数据是 已经

429
00:21:38,090 --> 00:21:41,960
按 from URL 键分组了，所以

430
00:21:41,960 --> 00:21:44,570
让我们打印链接三个

431
00:21:44,570 --> 00:21:47,149
让我们运行 collect 实际驱动

432
00:21:47,149 --> 00:21:52,929
计算并查看结果是

433
00:21:52,929 --> 00:21:55,429
什么，实际上我们在这里看到的是

434
00:21:55,429 --> 00:21:59,570
一对数组，其中

435
00:21:59,570 --> 00:22:01,639
每个元组的第一部分是 URL 来自页面

436
00:22:01,639 --> 00:22:05,539
，第二个是从

437
00:22:05,539 --> 00:22:08,209
该首页开始的链接列表，因此您可以

438
00:22:08,209 --> 00:22:10,159
看到 YouTube 有一个链接到您两个

439
00:22:10,159 --> 00:22:12,199
和三个您三个作为链接到只是 u

440
00:22:12,199 --> 00:22:22,909
1 和 u 1 有一个链接到 u  1 & u 3 好的，

441
00:22:22,909 --> 00:22:29,059
所以这是链接 3 现在迭代

442
00:22:29,059 --> 00:22:30,769
将从这里开始几行

443
00:22:30,769 --> 00:22:32,869
它会一遍又一遍地使用这些东西

444
00:22:32,869 --> 00:22:35,929
 

445
00:22:35,929 --> 00:22:39,619
循环的每次迭代都将

446
00:22:39,619 --> 00:22:44,629
在链接 3 中使用此信息以便排序

447
00:22:44,629 --> 00:22:46,549
为了

448
00:22:46,549 --> 00:22:49,429
模拟这些用户点击我

449
00:22:49,429 --> 00:22:52,459
从所有页面到所有其他链接到

450
00:22:52,459 --> 00:22:55,309
两个页面的传播概率，所以这个长度的东西是这些

451
00:22:55,309 --> 00:22:57,139
链接数据将被一遍

452
00:22:57,139 --> 00:22:58,459
又一遍地使用，我们要保存

453
00:22:58,459 --> 00:23:00,259
事实证明，到目前为止，每次我

454
00:23:00,259 --> 00:23:02,709
调用 collect 时，spark 都会

455
00:23:02,709 --> 00:23:05,089
重新执行“从头开始添加计算”，

456
00:23:05,089 --> 00:23:06,979
因此我对 collect 的每次调用

457
00:23:06,979 --> 00:23:09,799
都涉及 spark 重新读取

458
00:23:09,799 --> 00:23:12,289
输入文件重新运行第一个映射

459
00:23:12,289 --> 00:23:14,809
重新运行不同和 如果我要

460
00:23:14,809 --> 00:23:17,149
再次调用 collect 它会按键重新运行这

461
00:23:17,149 --> 00:23:18,769
条路线，但

462
00:23:18,769 --> 00:23:20,299
我们不想在每次循环迭代的多个 TB 链接上一遍又一遍地这样做，

463
00:23:20,299 --> 00:23:25,279
 

464
00:23:25,279 --> 00:23:28,039
因为我们已经计算

465
00:23:28,039 --> 00:23:29,659
过一次它会 说明此

466
00:23:29,659 --> 00:23:31,369
链接列表 将保持不变，我们只是

467
00:23:31,369 --> 00:23:34,669
想保存并重用它，所以

468
00:23:34,669 --> 00:23:38,419
为了告诉 spark 我们想要

469
00:23:38,419 --> 00:23:39,709
一遍又一遍地使用它，

470
00:23:39,709 --> 00:23:43,009
程序员需要明确地在论文中

471
00:23:43,009 --> 00:23:48,679
所说的持久化这些数据，实际上

472
00:23:48,679 --> 00:23:51,800
现代 spark

473
00:23:51,800 --> 00:23:53,270
如果你想在内存中睡觉，你调用的函数不会持久化

474
00:23:53,270 --> 00:23:55,910
，但它被称为现金，因此

475
00:23:55,910 --> 00:23:59,030
链接与我们接受的链接

476
00:23:59,030 --> 00:24:03,560
与我们希望引发的注释相同，

477
00:24:03,560 --> 00:24:06,620
 

478
00:24:06,620 --> 00:24:07,910
因为我们将使用它 一遍又

479
00:24:07,910 --> 00:24:14,300
一遍，所以在循环开始之前我们需要做的最后一件事

480
00:24:14,300 --> 00:24:16,340
是，我们

481
00:24:16,340 --> 00:24:20,510
将为源 URL 索引的每个页面设置一组页面排名

482
00:24:20,510 --> 00:24:23,570
，我们

483
00:24:23,570 --> 00:24:28,250
需要初始化每个页面排名，这并不是

484
00:24:28,250 --> 00:24:29,410
真正的排名，它是 一种

485
00:24:29,410 --> 00:24:33,050
概率，我们要将

486
00:24:33,050 --> 00:24:35,900
所有概率初始化为一个，因此它们都

487
00:24:35,900 --> 00:24:38,300
以具有相同等级的概率开始，

488
00:24:38,300 --> 00:24:41,660
但我们会很好，我们

489
00:24:41,660 --> 00:24:43,700
实际上会编写看起来像是

490
00:24:43,700 --> 00:24:49,610
在改变等级的代码，但实际上当我们

491
00:24:49,610 --> 00:24:52,130
执行 我展示的代码中的循环

492
00:24:52,130 --> 00:24:54,410
确实

493
00:24:54,410 --> 00:24:56,540
为每个循环迭代生成了一个新版本的排名，该迭代被

494
00:24:56,540 --> 00:25:00,170
更新以反映这样一个事实，即

495
00:25:00,170 --> 00:25:02,630
代码算法是一种

496
00:25:02,630 --> 00:25:07,870
从每个 P

497
00:25:07,870 --> 00:25:10,150
到页面的推送页面排名，它链接到所以 让我们

498
00:25:10,150 --> 00:25:13,050
打印排名来看看里面

499
00:25:13,050 --> 00:25:17,260
有什么 只是从源

500
00:25:17,260 --> 00:25:20,470
URL 的 URL 到每个页面的当前页面排名值的映射

501
00:25:20,470 --> 00:25:23,260
ok 不会

502
00:25:23,260 --> 00:25:27,850
在 spark 内部开始执行 允许用户

503
00:25:27,850 --> 00:25:30,220
请求比缓存更细粒度的调度

504
00:25:30,220 --> 00:25:32,500
原语 控制

505
00:25:32,500 --> 00:25:33,700
存储的位置或

506
00:25:33,700 --> 00:25:38,260
计算的执行方式是的，所以

507
00:25:38,260 --> 00:25:41,020
缓存缓存是更

508
00:25:41,020 --> 00:25:44,650
一般的持久调用的一个特例，它可以告诉

509
00:25:44,650 --> 00:25:46,780
spark 看起来我想让你知道将这些

510
00:25:46,780 --> 00:25:49,200
数据保存在内存中，或者我想将它保存在

511
00:25:49,200 --> 00:25:52,179
HDFS 中所以 它被复制并且所有的

512
00:25:52,179 --> 00:25:53,830
崩溃都幸存下来，

513
00:25:53,830 --> 00:25:58,660
所以一般来说

514
00:25:58,660 --> 00:26:00,010
你有

515
00:26:00,010 --> 00:26:04,240
 

516
00:26:04,240 --> 00:26:07,120
一点灵活性

517
00:26:07,120 --> 00:26:09,510
分区是由原始输入文件的分区驱动的，

518
00:26:09,510 --> 00:26:11,650
 

519
00:26:11,650 --> 00:26:16,000
但是当我们运行必须洗牌的转换时，必须

520
00:26:16,000 --> 00:26:17,440
 

521
00:26:17,440 --> 00:26:19,059
像 distinct 那样更改分区，它会这样做，

522
00:26:19,059 --> 00:26:21,700
并且按键组会在

523
00:26:21,700 --> 00:26:25,059
内部做一些事情，如果我们不做任何事情，

524
00:26:25,059 --> 00:26:26,500
我们 不要说什么，它只会

525
00:26:26,500 --> 00:26:28,960
选择一些方案

526
00:26:28,960 --> 00:26:30,990
，例如在可用的工作人员上散列密钥，

527
00:26:30,990 --> 00:26:34,090
但你可以告诉它看起来你知道我

528
00:26:34,090 --> 00:26:35,650
事实证明，这种

529
00:26:35,650 --> 00:26:39,130
对你知道的数据进行分区的特殊方式使用

530
00:26:39,130 --> 00:26:40,510
不同的散列函数或 也许是

531
00:26:40,510 --> 00:26:42,490
按范围而不是散列分区，

532
00:26:42,490 --> 00:26:46,000
如果你喜欢更聪明的方法来控制分区，你可以告诉它，

533
00:26:46,000 --> 00:26:53,950
所以

534
00:26:53,950 --> 00:26:55,170
我要开始

535
00:26:55,170 --> 00:26:57,780
循环做的第一件事，我希望

536
00:26:57,780 --> 00:27:02,340
你能看到第 12 行的代码，我们

537
00:27:02,340 --> 00:27:06,150
实际上要 运行这个连接 这是循环

538
00:27:06,150 --> 00:27:08,760
的第一次迭代的第一个语句，

539
00:27:08,760 --> 00:27:12,900
这个连接正在做的是

540
00:27:12,900 --> 00:27:17,150
连接与排名的链接

541
00:27:17,150 --> 00:27:20,630
，所做的是将

542
00:27:20,630 --> 00:27:22,710
链接 w 中的相应条目拉在一起 hich

543
00:27:22,710 --> 00:27:24,720
说每个 URL 有什么意义

544
00:27:24,720 --> 00:27:28,050
，它有什么链接，我

545
00:27:28,050 --> 00:27:29,820
有点把链接和排名放在一起

546
00:27:29,820 --> 00:27:31,500
，但是排名说的是每个

547
00:27:31,500 --> 00:27:33,720
URL 的当前 PageRank 是什么所以现在

548
00:27:33,720 --> 00:27:38,580
我们在一起和一个项目 对于

549
00:27:38,580 --> 00:27:39,630
每个

550
00:27:39,630 --> 00:27:41,880
页面，它当前的 PageRank 是什么以及

551
00:27:41,880 --> 00:27:43,650
它指向的链接是什么，因为我们要将

552
00:27:43,650 --> 00:27:47,220
每个页面当前的 PageRank 推

553
00:27:47,220 --> 00:27:50,400
送到它指定的所有页面，

554
00:27:50,400 --> 00:27:52,350
并且这个联合是呃，这就是论文

555
00:27:52,350 --> 00:27:57,840
所说的广泛转换，因为它

556
00:27:57,840 --> 00:28:04,110
没有 它不是本地的，我的意思是

557
00:28:04,110 --> 00:28:07,670
它可能需要

558
00:28:07,670 --> 00:28:10,620
通过 URL 键对数据进行洗牌，以便现在

559
00:28:10,620 --> 00:28:13,230
将链接和

560
00:28:13,230 --> 00:28:17,490
排名的相应元素放在一起事实上我相信

561
00:28:17,490 --> 00:28:19,650
spark 足够聪明，可以注意到

562
00:28:19,650 --> 00:28:23,010
链接和排名已经

563
00:28:23,010 --> 00:28:27,210
以相同的方式按键分区实际上

564
00:28:27,210 --> 00:28:30,120
 

565
00:28:30,120 --> 00:28:33,000
假设它在我们创建排名

566
00:28:33,000 --> 00:28:34,880
时巧妙

567
00:28:34,880 --> 00:28:39,510
 

568
00:28:39,510 --> 00:28:41,820
地创建了链接

569
00:28:41,820 --> 00:28:43,530
然后它会注意到链接

570
00:28:43,530 --> 00:28:45,740
和排名以相同的方式传递

571
00:28:45,740 --> 00:28:48,630
，也就是说链接排名

572
00:28:48,630 --> 00:28:53,670
已经在同一个工作人员上，或者抱歉，

573
00:28:53,670 --> 00:28:55,380
具有相同

574
00:28:55,380 --> 00:28:57,050
键的相应分区已经在同一个工作人员中，

575
00:28:57,050 --> 00:29:00,120
希望 spark 会注意到

576
00:29:00,120 --> 00:29:01,950
如果出现问题，则不必移动任何数据，

577
00:29:01,950 --> 00:29:03,210
尽管在链接和

578
00:29:03,210 --> 00:29:04,320
排名中以不同的方式分区，

579
00:29:04,320 --> 00:29:05,700
那么此时数据将不得不移动

580
00:29:05,700 --> 00:29:06,790
 

581
00:29:06,790 --> 00:29:10,410
以连接两者中的相应键，

582
00:29:10,410 --> 00:29:15,130
并且两个 rdd 都可以，因此

583
00:29:15,130 --> 00:29:17,980
包含的 JJ 现在包含两者 如您所见，每个页面的

584
00:29:17,980 --> 00:29:25,510
排名和每个页面的链接列表

585
00:29:25,510 --> 00:29:28,660
现在我们有一个更

586
00:29:28,660 --> 00:29:31,210
复杂的数据结构，它是一个数组

587
00:29:31,210 --> 00:29:34,120
，每个页面都有一个元素，页面

588
00:29:34,120 --> 00:29:37,660
URL 和链接列表，上面的

589
00:29:37,660 --> 00:29:40,420
一点就是你的页面 选择

590
00:29:40,420 --> 00:29:45,040
当前排名，这些都是所有这些

591
00:29:45,040 --> 00:29:47,320
信息是任何类型的单个

592
00:29:47,320 --> 00:29:48,880
记录，其中包含每个页面的所有这些信息

593
00:29:48,880 --> 00:29:52,290
，我们需要它，

594
00:29:52,290 --> 00:29:56,080
好吧下一步是我们

595
00:29:56,080 --> 00:29:58,120
要计算 每个页面都会

596
00:29:58,120 --> 00:30:02,200
将其当前页面排名的一小部分推

597
00:30:02,200 --> 00:30:04,030
到它链接到的所有页面

598
00:30:04,030 --> 00:30:05,440
 

599
00:30:05,440 --> 00:30:07,240
 

600
00:30:07,240 --> 00:30:09,270
 

601
00:30:11,160 --> 00:30:16,440
 

602
00:30:16,440 --> 00:30:18,420
上 正在发生的事情是，

603
00:30:18,420 --> 00:30:23,970
这是对 map 的一个调用，

604
00:30:23,970 --> 00:30:27,060
我们正在映射每个页面

605
00:30:27,060 --> 00:30:29,970
，在该页面指向的 URL 上运行映射

606
00:30:29,970 --> 00:30:32,220
，对于它

607
00:30:32,220 --> 00:30:37,380
指向的每个页面，我们只是在计算这个

608
00:30:37,380 --> 00:30:39,600
数字，即 从页面当前

609
00:30:39,600 --> 00:30:41,550
排名除以

610
00:30:41,550 --> 00:30:44,130
指向的页面总数，所以这种

611
00:30:44,130 --> 00:30:47,040
计算你知道创建一个从

612
00:30:47,040 --> 00:30:50,400
链接名称

613
00:30:50,400 --> 00:30:55,290
到该页面新页面

614
00:30:55,290 --> 00:31:04,050
排名的众多贡献之一的映射，我们可以偷看

615
00:31:04,050 --> 00:31:07,470
它会产生什么 我认为这是一件更

616
00:31:07,470 --> 00:31:10,020
简单的事情，它只是一个 URL 列表

617
00:31:10,020 --> 00:31:13,740
和对 URL 页面排名的贡献

618
00:31:13,740 --> 00:31:15,510
，还有更多你

619
00:31:15,510 --> 00:31:16,950
知道的每个 URL 的记录不止一个，

620
00:31:16,950 --> 00:31:19,740
因为对于任何给定的

621
00:31:19,740 --> 00:31:21,300
页面都会有一个 re 此处为

622
00:31:21,300 --> 00:31:22,800
指向它的每个链接的绳子，

623
00:31:22,800 --> 00:31:27,060
表明从

624
00:31:27,060 --> 00:31:29,400
该链接来自该

625
00:31:29,400 --> 00:31:32,660
页面的任何内容到该页面的贡献 新更新的 PageRank

626
00:31:32,660 --> 00:31:35,130
现在必须发生的是我们

627
00:31:35,130 --> 00:31:38,730
需要总结每个页面，我们需要

628
00:31:38,730 --> 00:31:42,420
总结 该

629
00:31:42,420 --> 00:31:44,220
页面的 PageRank 贡献在 contribs 中，

630
00:31:44,220 --> 00:31:46,470
所以我们需要再次在这里进行洗牌，这

631
00:31:46,470 --> 00:31:49,470
将是一个具有广泛输入的广泛转换，

632
00:31:49,470 --> 00:31:50,850
因为我们需要为

633
00:31:50,850 --> 00:31:55,070
 

634
00:31:55,070 --> 00:31:57,420
我们需要带来的每个页面汇集所有贡献元素 一起

635
00:31:57,420 --> 00:31:59,280
并将同一工作人员分配给同一个

636
00:31:59,280 --> 00:32:03,170
分区，以便将它们全部汇总起来，

637
00:32:03,530 --> 00:32:07,620
并且 PageRank 所做的

638
00:32:07,620 --> 00:32:10,470
方式是通过减少键

639
00:32:10,470 --> 00:32:15,920
调用来减少峰值，他所做的是

640
00:32:15,920 --> 00:32:17,480
首先它汇集了

641
00:32:17,480 --> 00:32:19,990
所有记录 使用相同的键，然后

642
00:32:19,990 --> 00:32:24,350
 

643
00:32:24,350 --> 00:32:26,870
对给定键的每个记录的第二个元素求和，并

644
00:32:26,870 --> 00:32:30,320
生成作为输出的键，即

645
00:32:30,320 --> 00:32:33,740
URL 和数字的总和，

646
00:32:33,740 --> 00:32:39,020
即更新后的 PageRank 实际上有

647
00:32:39,020 --> 00:32:40,700
这里有两个转换，第一个

648
00:32:40,700 --> 00:32:43,100
是通过 key 减少的，第二个是这个

649
00:32:43,100 --> 00:32:46,400
映射值，这

650
00:32:46,400 --> 00:32:49,640
是实现 15% 的

651
00:32:49,640 --> 00:32:52,250
概率进入随机页面和 85%

652
00:32:52,250 --> 00:33:00,220
的概率跟随链接的部分，

653
00:33:00,220 --> 00:33:02,360
让我们看看 顺便说一句，

654
00:33:02,360 --> 00:33:04,460
尽管我们在这里分配了两个等级

655
00:33:04,460 --> 00:33:06,590
，但最终要做的是

656
00:33:06,590 --> 00:33:08,750
创建一个全新的转换

657
00:33:08,750 --> 00:33:12,080
 

658
00:33:12,080 --> 00:33:14,780
 

659
00:33:14,780 --> 00:33:16,070
'不改变任何

660
00:33:16,070 --> 00:33:17,660
已经计算的值它只是

661
00:33:17,660 --> 00:33:20,840
创建一个新的新转换和

662
00:33:20,840 --> 00:33:27,500
新的输出，我们可以看到会

663
00:33:27,500 --> 00:33:29,840
发生什么事实上我们现在有成员

664
00:33:29,840 --> 00:33:32,390
排名最初只是

665
00:33:32,390 --> 00:33:35,930
一堆 URL PageRank 现在再次

666
00:33:35,930 --> 00:33:37,190
出现如果你是 我将给

667
00:33:37,190 --> 00:33:38,540
另一个不同的页面排名，我们实际上已经更新

668
00:33:38,540 --> 00:33:43,210
了它们，一步一步地改变了它们

669
00:33:43,570 --> 00:33:45,700
，我不知道你是否记得

670
00:33:45,700 --> 00:33:48,650
我们看到的原始 PageRank 值，但

671
00:33:48,650 --> 00:33:51,560
这些更接近

672
00:33:51,560 --> 00:33:54,350
我们看到的最终输出，然后是原始

673
00:33:54,350 --> 00:33:58,280
所有一个的最终值都可以​​，所以这

674
00:33:58,280 --> 00:34:01,190
是算法的一次迭代，当循环

675
00:34:01,190 --> 00:34:02,780
回到顶部时，它会

676
00:34:02,780 --> 00:34:08,230
执行相同的连接平面映射并按键减少

677
00:34:08,230 --> 00:34:13,340
，每次它再次你

678
00:34:13,340 --> 00:34:15,110
知道循环实际上在做什么是 生成

679
00:34:15,110 --> 00:34:18,620
这个谱系图，因此它没有

680
00:34:18,620 --> 00:34:20,330
更新循环中提到的变量它实际上是

681
00:34:20,330 --> 00:34:21,650
在

682
00:34:21,650 --> 00:34:25,210
创建本质上将新的

683
00:34:25,210 --> 00:34:27,739
转换节点附加

684
00:34:27,739 --> 00:34:30,399
到它正在构建的谱系图

685
00:34:30,399 --> 00:34:34,280
但我只在循环之后运行了一次 Elite

686
00:34:34,280 --> 00:34:37,520
，然后这就是

687
00:34:37,520 --> 00:34:39,290
真正的代码

688
00:34:39,290 --> 00:34:42,409
在这一点上实际运行真正的代码，所以

689
00:34:42,409 --> 00:34:43,790
他们在真正的PageRank实现中

690
00:34:43,790 --> 00:34:46,668
只是在这一点上，计算

691
00:34:46,668 --> 00:34:49,129
甚至开始，因为

692
00:34:49,129 --> 00:34:50,480
这里调用collect，我开始阅读

693
00:34:50,480 --> 00:34:52,550
我们的最终负担 通过

694
00:34:52,550 --> 00:34:54,909
所有这些转换和洗牌

695
00:34:54,909 --> 00:34:57,890
对输入进行广泛的依赖，最后

696
00:34:57,890 --> 00:34:59,720
在

697
00:34:59,720 --> 00:35:02,420
运行该程序

698
00:35:02,420 --> 00:35:03,530
的计算机上通过运行计算机的方式收集输出

699
00:35:03,530 --> 00:35:05,390
论文称它为

700
00:35:05,390 --> 00:35:07,940
驱动程序的程序 驱动程序计算机

701
00:35:07,940 --> 00:35:09,650
是实际运行这个扇贝程序的程序

702
00:35:09,650 --> 00:35:13,220
，它有点驱动火花

703
00:35:13,220 --> 00:35:15,950
计算，然后程序接受

704
00:35:15,950 --> 00:35:18,859
这个输出变量，并

705
00:35:18,859 --> 00:35:26,660
在每条记录上通过格式精美的打印运行它

706
00:35:26,660 --> 00:35:35,210
在收集中好吧

707
00:35:35,210 --> 00:35:37,630
，这

708
00:35:39,140 --> 00:35:41,210
就是人们用于 Scala 的那种编程风格

709
00:35:41,210 --> 00:35:48,880
，我的意思是 spark

710
00:35:51,910 --> 00:35:54,289
相对于 MapReduce 有一点需要注意的

711
00:35:54,289 --> 00:35:57,920
是，这个程序你很

712
00:35:57,920 --> 00:35:59,630
熟悉，看起来有点复杂，

713
00:35:59,630 --> 00:36:02,720
但事实上 是这个程序正在

714
00:36:02,720 --> 00:36:07,630
做许多 MapReduce

715
00:36:07,630 --> 00:36:09,680
的工作，或者做大量的工作

716
00:36:09,680 --> 00:36:12,049
需要许多单独的 MapReduce

717
00:36:12,049 --> 00:36:16,700
程序才能实现，所以你知道它有

718
00:36:16,700 --> 00:36:18,859
21 行，也许你使用了两个

719
00:36:18,859 --> 00:36:20,240
比这更简单的 MapReduce 程序

720
00:36:20,240 --> 00:36:22,579
，但这是 为 21 行做了很多工作，

721
00:36:22,579 --> 00:36:25,339
结果证明这是

722
00:36:25,339 --> 00:36:27,109
你知道这是一种真正的

723
00:36:27,109 --> 00:36:29,450
算法，所以它就像一个非常

724
00:36:29,450 --> 00:36:32,059
简洁且易于编程的程序

725
00:36:32,059 --> 00:36:37,069
一种表达大量大数据

726
00:36:37,069 --> 00:36:42,769
计算的方法，你知道人们喜欢非常

727
00:36:42,769 --> 00:36:50,770
成功，所以再次

728
00:36:50,770 --> 00:36:52,690
只想重复这一点，直到最终

729
00:36:52,690 --> 00:36:54,700
收集或这段代码正在

730
00:36:54,700 --> 00:36:56,740
生成一个沿袭图，而不是

731
00:36:56,740 --> 00:36:58,600
处理它实际产生的数据和沿袭

732
00:36:58,600 --> 00:37:01,390
图 论文

733
00:37:01,390 --> 00:37:01,690
 

734
00:37:01,690 --> 00:37:05,020
我刚刚从论文中复制了这个 这

735
00:37:05,020 --> 00:37:06,280
就是谱系图的

736
00:37:06,280 --> 00:37:09,700
样子 你知道这就是

737
00:37:09,700 --> 00:37:11,740
程序正在生成的全部 它只是这个

738
00:37:11,740 --> 00:37:14,650
图直到最终收集你

739
00:37:14,650 --> 00:37:16,210
可以看到它是这些

740
00:37:16,210 --> 00:37:20,350
处理阶段的序列 我们读取文件

741
00:37:20,350 --> 00:37:21,580
以生成链接，然后完全

742
00:37:21,580 --> 00:37:23,050
分开生成这些初始

743
00:37:23,050 --> 00:37:26,680
等级，然后重复连接

744
00:37:26,680 --> 00:37:34,300
并通过键对减少每个循环

745
00:37:34,300 --> 00:37:41,170
迭代产生一个连接，并且

746
00:37:41,170 --> 00:37:42,700
这些对中的每一个都是一个循环迭代，

747
00:37:42,700 --> 00:37:44,230
您可以再次看到 循环

748
00:37:44,230 --> 00:37:46,510
将越来越多的节点附加到

749
00:37:46,510 --> 00:37:49,420
图上，而不是它没有做的事情

750
00:37:49,420 --> 00:37:51,960
，特别是它没有产生

751
00:37:51,960 --> 00:37:56,800
循环图循环正在产生所有

752
00:37:56,800 --> 00:37:59,470
这些 gra  phs 是一个循环 另一个

753
00:37:59,470 --> 00:38:01,000
需要注意的是，你不会看到

754
00:38:01,000 --> 00:38:03,700
MapReduce 是

755
00:38:03,700 --> 00:38:05,200
这里的数据是我们兑现的数据，我们

756
00:38:05,200 --> 00:38:07,330
持久化的数据被一遍又一遍地使用

757
00:38:07,330 --> 00:38:09,490
，每次循环迭代，所以它

758
00:38:09,490 --> 00:38:12,360
会激发这个 在内存中，

759
00:38:12,360 --> 00:38:16,500
它会多次查询它，

760
00:38:20,070 --> 00:38:26,380
所以它实际上在执行过程中发生，

761
00:38:26,380 --> 00:38:28,570
执行是什么

762
00:38:28,570 --> 00:38:36,190
样子的，假设是

763
00:38:36,190 --> 00:38:39,040
输入数据开始的数据

764
00:38:39,040 --> 00:38:45,540
在 HDFS 中被预分区，

765
00:38:45,540 --> 00:38:48,460
我们假设我们的一个文件 这是我们的输入

766
00:38:48,460 --> 00:38:51,100
文件已经分成很多你

767
00:38:51,100 --> 00:38:53,470
知道64兆字节或

768
00:38:53,470 --> 00:38:58,560
HDFS中可能发生的任何碎片火花知道

769
00:38:58,560 --> 00:39:01,030
当你开始时你实际上调用

770
00:39:01,030 --> 00:39:02,530
收集计算的开始火花

771
00:39:02,530 --> 00:39:03,760
知道输入数据已经

772
00:39:03,760 --> 00:39:08,070
分区HDFS并且它会尝试

773
00:39:08,070 --> 00:39:11,440
以相应的方式分配工作人员的工作，

774
00:39:11,440 --> 00:39:13,840
所以如果它

775
00:39:13,840 --> 00:39:15,940
知道我实际上不知道

776
00:39:15,940 --> 00:39:19,990
细节是什么，它实际上可能

777
00:39:19,990 --> 00:39:21,340
会尝试在

778
00:39:21,340 --> 00:39:25,420
存储 HDFS 数据的同一台机器，或者它

779
00:39:25,420 --> 00:39:31,650
可能只是设置了一堆工作人员来

780
00:39:31,650 --> 00:39:35,140
读取每个 HDFS 分区，

781
00:39:35,140 --> 00:39:37,330
并且每个工作人员可能有多个

782
00:39:37,330 --> 00:39:41,740
分区，所以我们有

783
00:39:41,740 --> 00:39:45,580
输入文件，第一件事

784
00:39:45,580 --> 00:39:50,650
是 每个工作人员都作为

785
00:39:50,650 --> 00:39:53,260
输入文件的一部分读取，因此

786
00:39:53,260 --> 00:39:55,960
如果您还记得下一步

787
00:39:55,960 --> 00:39:57,760
是一个映射，每个工作人员

788
00:39:57,760 --> 00:39:59,980
应该映射一个小函数，该函数将

789
00:39:59,980 --> 00:40:02,770
输入的每一行拆分为来自两个

790
00:40:02,770 --> 00:40:06,040
链接的元组的一个小函数，因此这是读取他们的文件 但这是一个纯粹的

791
00:40:06,040 --> 00:40:08,410
本地操作，所以它可以

792
00:40:08,410 --> 00:40:10,660
在同一个工作人员中继续，所以我们假设我们

793
00:40:10,660 --> 00:40:13,450
读取数据，然后在同一个

794
00:40:13,450 --> 00:40:16,600
工作人员中，火花会做那个初始

795
00:40:16,600 --> 00:40:19,750
地图，所以你知道我正在画一个箭头

796
00:40:19,750 --> 00:40:21,670
这里真的 从每个工作人员到自身的箭头，

797
00:40:21,670 --> 00:40:22,960
因此确实不

798
00:40:22,960 --> 00:40:24,730
涉及网络通信，只是

799
00:40:24,730 --> 00:40:28,540
您知道我们运行第一次读取，并且

800
00:40:28,540 --> 00:40:30,190
输出可以直接馈送到那

801
00:40:30,190 --> 00:40:33,700
个小地图函数，事实上，这就是

802
00:40:33,700 --> 00:40:39,210
那个初始地图，实际上是火花

803
00:40:39,210 --> 00:40:40,980
 

804
00:40:40,980 --> 00:40:43,020
通过这些转换逐条记录数据记录，

805
00:40:43,020 --> 00:40:45,260
而不是读取整个输入

806
00:40:45,260 --> 00:40:47,609
分区，然后

807
00:40:47,609 --> 00:40:52,020
在整个输入分区上

808
00:40:52,020 --> 00:40:53,700
 

809
00:40:53,700 --> 00:40:56,310
运行映射

810
00:40:56,310 --> 00:40:58,650
 

811
00:40:58,650 --> 00:41:02,010
实际上，如果在继续并从文件中读取下一点之前进行许多转换，我实际上会运行 E 的每条记录，这样它就

812
00:41:02,010 --> 00:41:05,310
 

813
00:41:05,310 --> 00:41:06,660
 

814
00:41:06,660 --> 00:41:08,190
 

815
00:41:08,190 --> 00:41:10,050
不必存储是的，这些文件

816
00:41:10,050 --> 00:41:13,109
可能非常大 它不是一半，所以

817
00:41:13,109 --> 00:41:14,849
就像存储整个输入文件一样，

818
00:41:14,849 --> 00:41:16,950
仅按记录处理它的效率要高得多，

819
00:41:16,950 --> 00:41:18,990
所以有一个

820
00:41:18,990 --> 00:41:22,109
问题，所以每个链中的第一个节点

821
00:41:22,109 --> 00:41:24,420
是持有 HDFS 块的工作人员

822
00:41:24,420 --> 00:41:26,580
和链中的其余节点 是

823
00:41:26,580 --> 00:41:28,349
血统中的节点哦，是的，

824
00:41:28,349 --> 00:41:29,640
恐怕我在这里有点困惑

825
00:41:29,640 --> 00:41:32,220
我认为考虑这一点的方式是

826
00:41:32,220 --> 00:41:35,070
，到目前为止，所有这些都发生

827
00:41:35,070 --> 00:41:37,800
在单个工人身上，所以这

828
00:41:37,800 --> 00:41:40,460
可能是工人一号 这是另一个工作人员

829
00:41:40,460 --> 00:41:43,460
，

830
00:41:45,890 --> 00:41:48,560
每个工作人员都在

831
00:41:48,560 --> 00:41:50,210
独立进行，我想象

832
00:41:50,210 --> 00:41:53,030
他们都在存储 HTTPS fob 的不同分区的同一台机器上运行，

833
00:41:53,030 --> 00:41:55,220
 

834
00:41:55,220 --> 00:41:57,170
但这里可能有网络

835
00:41:57,170 --> 00:41:59,630
通信从 HDFS

836
00:41:59,630 --> 00:42:02,360
到 负责的工作人员，但在

837
00:42:02,360 --> 00:42:04,990
那之后，这是非常快速的本地

838
00:42:04,990 --> 00:42:17,450
操作，所以这就是人们所

839
00:42:17,450 --> 00:42:20,090
发生的情况，

840
00:42:20,090 --> 00:42:22,540
称为狭义

841
00:42:23,210 --> 00:42:25,619
依赖关系，这种转换

842
00:42:25,619 --> 00:42:28,529
看起来独立地考虑每条数据记录，

843
00:42:28,529 --> 00:42:30,809
而

844
00:42:30,809 --> 00:42:33,749
不必担心关系 到其他

845
00:42:33,749 --> 00:42:37,319
记录，所以顺便说一下，这

846
00:42:37,319 --> 00:42:39,239
可能比 MapReduce 更有效

847
00:42:39,239 --> 00:42:43,400
，那是因为如果我们

848
00:42:43,400 --> 00:42:46,769
在这里有多个映射阶段，

849
00:42:46,769 --> 00:42:48,420
它们只是在内存中串在一起，

850
00:42:48,420 --> 00:42:50,999
而 MapReduce 如果你不是超级

851
00:42:50,999 --> 00:42:51,630
聪明，

852
00:42:51,630 --> 00:42:54,630
如果你运行多个 MapReduce 甚至 如果

853
00:42:54,630 --> 00:42:56,479
它们是一种退化的映射，只有

854
00:42:56,479 --> 00:42:59,640
MapReduce 应用程序每个阶段都会

855
00:42:59,640 --> 00:43:02,489
减少来自 G of s 计算和

856
00:43:02,489 --> 00:43:04,619
写入的输入 它的输出返回到 GFS 然后

857
00:43:04,619 --> 00:43:07,079
下一阶段将正确计算，所以

858
00:43:07,079 --> 00:43:08,309
在这里我们已经消除了其中的

859
00:43:08,309 --> 00:43:10,680
读写，你知道这不是一个非常

860
00:43:10,680 --> 00:43:14,309
深刻的优势，但它确实有助于

861
00:43:14,309 --> 00:43:20,630
极大的 Li 提高效率，但是

862
00:43:20,630 --> 00:43:23,130
并不是所有的转换都是狭窄的

863
00:43:23,130 --> 00:43:26,509
只是逐个记录地读取他们的输入

864
00:43:26,509 --> 00:43:28,529
记录，每条

865
00:43:28,529 --> 00:43:30,359
记录都独立于其他记录

866
00:43:30,359 --> 00:43:32,489
，所以我担心的是

867
00:43:32,489 --> 00:43:34,710
不同的调用，它需要知道所有

868
00:43:34,710 --> 00:43:37,559
实例，所有具有

869
00:43:37,559 --> 00:43:39,839
特定键的记录类似地逐个键

870
00:43:39,839 --> 00:43:42,749
需要知道 关于所有

871
00:43:42,749 --> 00:43:45,779
具有键连接的实例，它也必须移动

872
00:43:45,779 --> 00:43:50,210
一些东西，以便需要两个输入需要将两个输入的

873
00:43:50,210 --> 00:43:53,400
所有键连接在一起

874
00:43:53,400 --> 00:43:54,960
，这样

875
00:43:54,960 --> 00:43:56,279
两个输入的所有记录都是相同的键，

876
00:43:56,279 --> 00:43:58,650
所以有一堆这些非本地的

877
00:43:58,650 --> 00:44:01,440
论文称之为

878
00:44:01,440 --> 00:44:04,469
广泛转换的转换，因为它们

879
00:44:04,469 --> 00:44:05,989
可能必须查看

880
00:44:05,989 --> 00:44:08,579
输入的所有分区，这

881
00:44:08,579 --> 00:44:12,269
很像 MapReduce 中的 reduce 服务示例

882
00:44:12,269 --> 00:44:14,430
不同的 exposi  ng 我们正在

883
00:44:14,430 --> 00:44:18,839
谈论不同的阶段，您知道不同的阶段

884
00:44:18,839 --> 00:44:20,489
也将在多个工作人员上运行，

885
00:44:20,489 --> 00:44:24,660
并且每个键都没有独立的工作

886
00:44:24,660 --> 00:44:27,299
，因此我们可以

887
00:44:27,299 --> 00:44:31,589
按键对计算进行分区，但

888
00:44:31,589 --> 00:44:33,239
目前的数据根本没有按键分区

889
00:44:33,239 --> 00:44:34,529
实际上并没有真正

890
00:44:34,529 --> 00:44:36,569
被任何东西分区，只是有点，但是

891
00:44:36,569 --> 00:44:41,329
HDFS 有我的扭曲所以四个不同

892
00:44:41,329 --> 00:44:44,479
我们将在所有单词

893
00:44:44,479 --> 00:44:46,019
分区和所有工作人员上运行不同的

894
00:44:46,019 --> 00:44:50,009
分区，但你知道任何一个

895
00:44:50,009 --> 00:44:52,799
工作人员都需要查看所有

896
00:44:52,799 --> 00:44:54,930
具有给定键的输入记录，该键可能

897
00:44:54,930 --> 00:45:00,380
分布

898
00:45:00,680 --> 00:45:04,190
在前面转换的所有先前工作人员中，

899
00:45:04,190 --> 00:45:07,499
并且所有你知道的

900
00:45:07,499 --> 00:45:09,239
所有工作人员都负责

901
00:45:09,239 --> 00:45:10,469
不同的键，但键可能

902
00:45:10,469 --> 00:45:13,039
分布在

903
00:45:16,849 --> 00:45:19,569
工作人员身上 对于前面的

904
00:45:19,569 --> 00:45:21,319
转换，现在实际上工作人员

905
00:45:21,319 --> 00:45:23,359
是相同的，通常它将是

906
00:45:23,359 --> 00:45:25,759
相同的工作人员运行地图正在

907
00:45:25,759 --> 00:45:27,559
运行不同但数据

908
00:45:27,559 --> 00:45:28,940
需要在

909
00:45:28,940 --> 00:45:30,920
将所有键

910
00:45:30,920 --> 00:45:33,049
组合在一起的两个转换，因此火花实际上

911
00:45:33,049 --> 00:45:34,489
会做什么，它将获取此映射的输出，

912
00:45:34,489 --> 00:45:38,269
通过其键对每个记录进行哈希处理，

913
00:45:38,269 --> 00:45:40,519
并使用您知道的

914
00:45:40,519 --> 00:45:42,769
工作人员数量来选择哪些工作人员应该

915
00:45:42,769 --> 00:45:46,220
看到它，事实上 该

916
00:45:46,220 --> 00:45:48,349
实现很像您的 MapReduce 实现。

917
00:45:48,349 --> 00:45:51,019
 

918
00:45:51,019 --> 00:45:55,549
在最后一个狭窄阶段中发生的最后一件事

919
00:45:55,549 --> 00:45:59,029
是，输出将被

920
00:45:59,029 --> 00:46:01,700
分成与不同工作人员相对应的存储桶，以

921
00:46:01,700 --> 00:46:05,690
进行

922
00:46:05,690 --> 00:46:06,890
下一次转换

923
00:46:06,890 --> 00:46:10,640
等待他们取来我看到的

924
00:46:10,640 --> 00:46:13,579
独家新闻是每个工人

925
00:46:13,579 --> 00:46:15,499
运行尽可能多的阶段所有

926
00:46:15,499 --> 00:46:16,940
窄阶段他们可以通过

927
00:46:16,940 --> 00:46:19,849
完成并将输出

928
00:46:19,849 --> 00:46:21,289
分成存储桶，当所有这些都

929
00:46:21,289 --> 00:46:24,969
完成时，我们可以开始 运行

930
00:46:24,969 --> 00:46:27,859
工人进行不同的转换，

931
00:46:27,859 --> 00:46:30,349
其第一步是从

932
00:46:30,349 --> 00:46:32,660
其他每个工人那里获取

933
00:46:32,660 --> 00:46:35,180
最后一个窄阶段输出的相关桶

934
00:46:35,180 --> 00:46:38,239
，然后我们 可以运行不同的，因为

935
00:46:38,239 --> 00:46:40,160
所有给定的键都在同一个

936
00:46:40,160 --> 00:46:42,259
工人身上，并且它们现在都可以开始

937
00:46:42,259 --> 00:46:46,150
自己产生输出

938
00:46:48,199 --> 00:46:50,669
当然这些 Y

939
00:46:50,669 --> 00:46:52,709
转换非常昂贵，

940
00:46:52,709 --> 00:46:54,239
现在转换非常高效，

941
00:46:54,239 --> 00:46:56,459
因为我们只是在获取每条

942
00:46:56,459 --> 00:46:58,289
记录和

943
00:46:58,289 --> 00:47:00,929
完全在本地运行一堆函数 Y

944
00:47:00,929 --> 00:47:02,759
转换需要推送大量

945
00:47:02,759 --> 00:47:04,349
数据 影响

946
00:47:04,349 --> 00:47:06,239
PageRank 中的所有数据 你知道你得到了

947
00:47:06,239 --> 00:47:08,880
TB 的输入数据，这意味着

948
00:47:08,880 --> 00:47:10,649
你知道在这个阶段它仍然是相同的数据，

949
00:47:10,649 --> 00:47:12,359
因为它是 所有的链接

950
00:47:12,359 --> 00:47:15,059
，然后在网络上，所以现在我们正在

951
00:47:15,059 --> 00:47:17,309
通过网络推送 TB 和 TB 的数据，

952
00:47:17,309 --> 00:47:19,319
以实现从

953
00:47:19,319 --> 00:47:23,009
映射函数的

954
00:47:23,009 --> 00:47:24,659
输出到不同函数的输入的这种洗牌，所以这些

955
00:47:24,659 --> 00:47:28,229
广泛的转换是相当

956
00:47:28,229 --> 00:47:28,709
重量级

957
00:47:28,709 --> 00:47:31,529
的 通信，它们也是

958
00:47:31,529 --> 00:47:33,479
一种计算障碍，因为我们

959
00:47:33,479 --> 00:47:35,669
必须等待所有狭窄的

960
00:47:35,669 --> 00:47:37,589
处理完成，然后才能

961
00:47:37,589 --> 00:47:42,919
继续 因此，可以进行广泛的

962
00:47:45,979 --> 00:47:53,239
转换，

963
00:47:54,289 --> 00:47:57,469
因为

964
00:47:57,469 --> 00:47:59,819
SPARC 有一个视图

965
00:47:59,819 --> 00:48:04,949
 

966
00:48:04,949 --> 00:48:06,659
，因此可以

967
00:48:06,659 --> 00:48:08,429
 

968
00:48:08,429 --> 00:48:10,139
进行一些优化

969
00:48:10,139 --> 00:48:13,499
如果有

970
00:48:13,499 --> 00:48:15,599
一系列狭窄的阶段

971
00:48:15,599 --> 00:48:17,099
在同一台机器上运行它们，则肯定会运行所有这些阶段，基本上是通过

972
00:48:17,099 --> 00:48:19,619
对每个输入记录的顺序函数调用，

973
00:48:19,619 --> 00:48:21,479
这绝对是一种优化

974
00:48:21,479 --> 00:48:24,179
，只有在你同时

975
00:48:24,179 --> 00:48:26,929
看到整个谱系图时才能注意到

976
00:48:26,929 --> 00:48:30,889
另一种优化

977
00:48:34,470 --> 00:48:37,230
当数据已经全部被分区时，spark 会注意到数据

978
00:48:37,230 --> 00:48:40,140
已经被分区，因为

979
00:48:40,140 --> 00:48:42,330
数据

980
00:48:42,330 --> 00:48:44,310
已经

981
00:48:44,310 --> 00:48:47,450
按照下一次广泛转换所需的方式进行分区，

982
00:48:47,450 --> 00:48:51,240
所以在我们的原始

983
00:48:51,240 --> 00:48:57,990
程序中，让我们看看我 认为我们

984
00:48:57,990 --> 00:49:00,030
连续有两个广泛的转换

985
00:49:00,030 --> 00:49:02,940
需要洗牌，但按键分组

986
00:49:02,940 --> 00:49:05,849
也会带来 将

987
00:49:05,849 --> 00:49:08,190
具有给定键的所有记录放在一起，并

988
00:49:08,190 --> 00:49:11,609
用每个键的列表替换它们

989
00:49:11,609 --> 00:49:14,670
从该 URL 开始您知道的链接列表

990
00:49:14,670 --> 00:49:16,859
这些都是宽运算符，它们

991
00:49:16,859 --> 00:49:19,710
都按键分组，所以也许

992
00:49:19,710 --> 00:49:21,150
我们必须对 不同

993
00:49:21,150 --> 00:49:24,150
但 spark 可以巧妙地识别出一个你知道的高点

994
00:49:24,150 --> 00:49:25,560
，它已经以

995
00:49:25,560 --> 00:49:26,880
一种适合按键组的方式洗牌，

996
00:49:26,880 --> 00:49:28,920
我们不必在其他洗牌中这样做，

997
00:49:28,920 --> 00:49:30,450
所以即使按键组

998
00:49:30,450 --> 00:49:32,730
原则上它可能是一个广泛的

999
00:49:32,730 --> 00:49:36,300
转变 事实上，我怀疑 spark

1000
00:49:36,300 --> 00:49:38,130
在没有通信的情况下实现它，

1001
00:49:38,130 --> 00:49:39,900
因为数据已经

1002
00:49:39,900 --> 00:49:44,540
按键进行了分区，所以

1003
00:49:45,569 --> 00:49:48,400
在这种特殊情况

1004
00:49:48,400 --> 00:49:53,640
下，可以按键进行分组，而无需对数据进行洗牌

1005
00:49:53,999 --> 00:49:56,349
，当然你知道只能这样做，

1006
00:49:56,349 --> 00:49:58,329
因为它产生了整个谱系

1007
00:49:58,329 --> 00:50:00,579
图 首先，然后才运行

1008
00:50:00,579 --> 00:50:02,559
计算，因此这部分有机会

1009
00:50:02,559 --> 00:50:07,329
检查和优化，并

1010
00:50:07,329 --> 00:50:10,410
可能转换图形，

1011
00:50:13,770 --> 00:50:16,890
以便看起来主题实际上任何

1012
00:50:16,890 --> 00:50:20,730
关于谱系图的问题 或者

1013
00:50:20,730 --> 00:50:21,840
事情是

1014
00:50:21,840 --> 00:50:28,380
如何执行

1015
00:50:28,380 --> 00:50:33,020
 

1016
00:50:33,020 --> 00:50:40,080
 

1017
00:50:40,080 --> 00:50:41,730
 

1018
00:50:41,730 --> 00:50:42,990
 

1019
00:50:42,990 --> 00:50:45,120
 

1020
00:50:45,120 --> 00:50:46,620
的 想要数据库 你

1021
00:50:46,620 --> 00:50:48,600
真的不能承受丢失

1022
00:50:48,600 --> 00:50:49,950
任何东西 你真正想要的是

1023
00:50:49,950 --> 00:50:53,400
一个永远不会在这里丢失数据的数据库

1024
00:50:53,400 --> 00:50:54,900
我们正在寻找的容错性

1025
00:50:54,900 --> 00:50:58,740
更像是如果我们

1026
00:50:58,740 --> 00:51:00,540
必须重复我们完全可以完全计算的计算是很昂贵的

1027
00:51:00,540 --> 00:51:02,310
如果我们必须重复这个计算，

1028
00:51:02,310 --> 00:51:04,590
但你知道这会花费我们

1029
00:51:04,590 --> 00:51:06,870
几个小时，这很烦人，但

1030
00:51:06,870 --> 00:51:09,510
不是世界末日，所以我们希望

1031
00:51:09,510 --> 00:51:12,630
你知道容忍常见错误，但我们

1032
00:51:12,630 --> 00:51:15,140
不一定非要 必须

1033
00:51:15,140 --> 00:51:19,580
有防弹能力来容忍

1034
00:51:19,580 --> 00:51:26,700
任何可能的错误，例如

1035
00:51:26,700 --> 00:51:29,520
，如果驱动

1036
00:51:29,520 --> 00:51:31,890
 

1037
00:51:31,890 --> 00:51:33,180
程序控制计算并且知道

1038
00:51:33,180 --> 00:51:34,860
驱动程序崩溃我

1039
00:51:34,860 --> 00:51:36,120
认为你必须重新运行整个事情，

1040
00:51:36,120 --> 00:51:38,280
但你知道任何只有任何一台机器

1041
00:51:38,280 --> 00:51:40,470
可能每隔几个月才会崩溃一次，所以

1042
00:51:40,470 --> 00:51:41,430
这没什么大不了的

1043
00:51:41,430 --> 00:51:45,900
另一件事要注意的是 HDFS 是

1044
00:51:45,900 --> 00:51:48,090
一种独立的东西 SPARC 只是

1045
00:51:48,090 --> 00:51:52,050
假设输入

1046
00:51:52,050 --> 00:51:55,290
在 HDFS 上以容错方式复制，实际上

1047
00:51:55,290 --> 00:51:58,290
就像 GFS HDFS 确实

1048
00:51:58,290 --> 00:51:59,760
在多个服务器上保留多个数据副本，

1049
00:51:59,760 --> 00:52:02,310
如果其中一个崩溃可以

1050
00:52:02,310 --> 00:52:05,220
继续使用另一个副本，因此

1051
00:52:05,220 --> 00:52:09,630
假设输入数据是

1052
00:52:09,630 --> 00:52:11,340
相对容错，

1053
00:52:11,340 --> 00:52:12,780
这意味着在最高

1054
00:52:12,780 --> 00:52:17,310
级别上，如果其中一个

1055
00:52:17,310 --> 00:52:20,640
工作人员失败，则火花策略只是重新计算

1056
00:52:20,640 --> 00:52:23,730
该工作人员负责的任何内容，

1057
00:52:23,730 --> 00:52:26,570
以重复

1058
00:52:26,570 --> 00:52:29,340
他们在其他工作人员和其他工作人员上与工作人员一起丢失的那些计算

1059
00:52:29,340 --> 00:52:32,420
其他一些机器，

1060
00:52:32,420 --> 00:52:37,130
所以这基本上是正在发生的事情

1061
00:52:37,130 --> 00:52:40,110
，你知道如果你

1062
00:52:40,110 --> 00:52:42,150
有很长的血统可能需要一段时间，就像你

1063
00:52:42,150 --> 00:52:44,340
实际上会得到 PageRank，因为你

1064
00:52:44,340 --> 00:52:45,270
知道 PageRank 多次迭代

1065
00:52:45,270 --> 00:52:50,310
会产生一个非常长的谱系图

1066
00:52:50,310 --> 00:52:53,790
，Spark 使它变得不那么糟糕的一种方式，

1067
00:52:53,790 --> 00:52:55,500
它必须是可能必须是计算机

1068
00:52:55,500 --> 00:52:56,880
如果一个工作人员失败，一切从头开始

1069
00:52:56,880 --> 00:53:00,780
是每个工作人员实际上

1070
00:53:00,780 --> 00:53:02,790
负责输入处的多个分区，

1071
00:53:02,790 --> 00:53:06,150
因此 Spark 可以移动 这些部分的

1072
00:53:06,150 --> 00:53:08,910
移动只为每个剩余的工作人员提供了

1073
00:53:08,910 --> 00:53:10,410
一个分区，并且他们将能够通过在不同的工作人员上并行运行其每个分区来

1074
00:53:10,410 --> 00:53:13,850
基本上瘫痪

1075
00:53:13,850 --> 00:53:17,310
失败工作人员丢失的重新计算，

1076
00:53:17,310 --> 00:53:19,140
 

1077
00:53:19,140 --> 00:53:22,140
因此如果所有

1078
00:53:22,140 --> 00:53:24,870
其他工作都失败了火花 只是

1079
00:53:24,870 --> 00:53:27,840
从输入回到开始，只是

1080
00:53:27,840 --> 00:53:29,310
重新计算在该机器上运行的所有内容，

1081
00:53:29,310 --> 00:53:36,990
但是现在我们的

1082
00:53:36,990 --> 00:53:38,880
依赖关系几乎

1083
00:53:38,880 --> 00:53:39,690
是故事的结尾，

1084
00:53:39,690 --> 00:53:42,030
但实际上存在

1085
00:53:42,030 --> 00:53:43,800
广泛依赖关系的问题，这使得该

1086
00:53:43,800 --> 00:53:48,210
故事不那么有吸引力 正如您可能

1087
00:53:48,210 --> 00:53:53,580
希望的那样，这是一个主题，这是

1088
00:53:53,580 --> 00:53:58,730
一个失败的节点 1

1089
00:54:00,920 --> 00:54:05,160
在具有广泛依赖关系的沿袭图中失败的工作人员，

1090
00:54:05,160 --> 00:54:13,200
因此

1091
00:54:13,200 --> 00:54:14,730
您可能拥有的合理或某种示例图是

1092
00:54:14,730 --> 00:54:16,799
您知道也许您有一个依赖关系

1093
00:54:16,799 --> 00:54:19,529
图，您知道该依赖关系图从一些

1094
00:54:19,529 --> 00:54:26,549
电源依赖关系开始，但过了一段

1095
00:54:26,549 --> 00:54:29,519
时间您有一个广泛的依赖关系，因此您

1096
00:54:29,519 --> 00:54:37,740
得到的转换依赖于

1097
00:54:37,740 --> 00:54:39,299
所有前面的转换，然后

1098
00:54:39,299 --> 00:54:44,190
一些小的狭窄的 好吧，你

1099
00:54:44,190 --> 00:54:45,960
知道游戏是一个工人

1100
00:54:45,960 --> 00:54:48,119
失败了，我们需要

1101
00:54:48,119 --> 00:54:50,579
在我们进行

1102
00:54:50,579 --> 00:54:55,200
最后的行动并产生输出之前重建 Maeby 的场，所以

1103
00:54:55,200 --> 00:54:57,450
我们需要重建重新计算

1104
00:54:57,450 --> 00:55:02,220
这上面的内容 现场工作，

1105
00:55:02,220 --> 00:55:05,009
这里的破坏性事情是，通常

1106
00:55:05,009 --> 00:55:09,359
当 spark 沿着它执行时，你知道

1107
00:55:09,359 --> 00:55:12,920
它执行每个转换

1108
00:55:12,920 --> 00:55:14,700
都会为我们提供下一个

1109
00:55:14,700 --> 00:55:16,380
转换的输出，但不会

1110
00:55:16,380 --> 00:55:18,599
保留原始输出，除非

1111
00:55:18,599 --> 00:55:20,930
你碰巧告诉它 就像链接

1112
00:55:20,930 --> 00:55:24,509
数据通过该缓存调用保持不变，

1113
00:55:24,509 --> 00:55:27,509
但通常不会保留数据

1114
00:55:27,509 --> 00:55:31,069
，因为现在如果您有类似的

1115
00:55:31,069 --> 00:55:34,349
PageRank 沿袭图可能有几十个或

1116
00:55:34,349 --> 00:55:35,940
数百个步骤，你不想

1117
00:55:35,940 --> 00:55:37,739
保留所有的数据，它

1118
00:55:37,739 --> 00:55:40,710
太多了，无法放入内存，所以当

1119
00:55:40,710 --> 00:55:42,180
SPARC 进行这些

1120
00:55:42,180 --> 00:55:45,559
转换时，它会丢弃

1121
00:55:45,559 --> 00:55:48,509
与早期转换相关的所有数据，

1122
00:55:48,509 --> 00:55:50,279
这意味着当我们到达这里时 如果这个

1123
00:55:50,279 --> 00:55:53,940
工人失败了，我们需要我们现在需要

1124
00:55:53,940 --> 00:55:56,640
在另一个工人上重新开始它的计算，

1125
00:55:56,640 --> 00:55:58,799
这样我们就可以成为输入，

1126
00:55:58,799 --> 00:56:01,670
也许可以做最初的窄

1127
00:56:01,670 --> 00:56:04,250
转换，

1128
00:56:04,250 --> 00:56:05,690
它们只依赖于我们

1129
00:56:05,690 --> 00:56:07,250
必须重新读取的输入，但是如果我们得到

1130
00:56:07,250 --> 00:56:08,660
这个 y 转换我们有这个

1131
00:56:08,660 --> 00:56:11,480
问题，它不仅需要

1132
00:56:11,480 --> 00:56:13,970
来自同一个工作人员的同一分区的输入，

1133
00:56:13,970 --> 00:56:15,680
还需要来自所有其他

1134
00:56:15,680 --> 00:56:18,440
分区的输入，并且这些工作人员因此他们

1135
00:56:18,440 --> 00:56:20,839
仍然活着，在这个例子中已经

1136
00:56:20,839 --> 00:56:23,450
进行了这个转换，

1137
00:56:23,450 --> 00:56:28,450
因此丢弃了输出 这种

1138
00:56:28,450 --> 00:56:31,310
转换，因为它可能

1139
00:56:31,310 --> 00:56:33,700
是不久前的，因此

1140
00:56:33,700 --> 00:56:36,770
我们从所有

1141
00:56:36,770 --> 00:56:39,260
其他分区的重新计算需要的输入不再存在

1142
00:56:39,260 --> 00:56:41,839
，所以如果我们是 不小心这

1143
00:56:41,839 --> 00:56:44,690
意味着为了重建

1144
00:56:44,690 --> 00:56:46,819
这个现场工作人员的计算，我们

1145
00:56:46,819 --> 00:56:51,680
实际上可能不得不重新执行

1146
00:56:51,680 --> 00:56:55,040
所有其他工作人员的这一部分以及

1147
00:56:55,040 --> 00:56:58,250
失败工作人员的整个血统图

1148
00:56:58,250 --> 00:57:01,250
，所以这可能是非常

1149
00:57:01,250 --> 00:57:02,839
有害的 对，如果我们在谈论，哦，

1150
00:57:02,839 --> 00:57:05,089
我的意思是我已经运行

1151
00:57:05,089 --> 00:57:07,490
了一天的这个巨大的火花工作，然后

1152
00:57:07,490 --> 00:57:10,369
一千台机器中的一台出现故障，这可能意味着

1153
00:57:10,369 --> 00:57:12,440
我们必须知道比这更聪明的事情

1154
00:57:12,440 --> 00:57:13,970
，我们必须回去

1155
00:57:13,970 --> 00:57:15,170
从头开始对每个

1156
00:57:15,170 --> 00:57:18,680
工作人员进行重新计算，然后从头开始重新计算整个事情

1157
00:57:18,680 --> 00:57:21,530
不，这将是相同

1158
00:57:21,530 --> 00:57:22,730
数量的工作，需要在同

1159
00:57:22,730 --> 00:57:27,109
一天重新计算一天的计算，所以

1160
00:57:27,109 --> 00:57:30,170
这是不可接受的，我们真的很

1161
00:57:30,170 --> 00:57:32,119
喜欢这样 如果如果一千个工人中有一个工人

1162
00:57:32,119 --> 00:57:33,680
崩溃，我们必须做

1163
00:57:33,680 --> 00:57:36,800
相对较少的工作来从中恢复

1164
00:57:36,800 --> 00:57:42,560
，并且因为这个火花允许

1165
00:57:42,560 --> 00:57:46,130
你检查点来进行

1166
00:57:46,130 --> 00:57:48,560
特定转换的定期检查点

1167
00:57:48,560 --> 00:57:52,640
所以嗯所以在这张图中我们w 应该做的

1168
00:57:52,640 --> 00:57:57,260
是在我们将调用的扇贝程序中

1169
00:57:57,260 --> 00:57:59,599
我认为它是持久调用实际上

1170
00:57:59,599 --> 00:58:00,920
我们使用一个特殊参数调用持久调用，

1171
00:58:00,920 --> 00:58:04,730
它说照顾你

1172
00:58:04,730 --> 00:58:06,520
计算这个

1173
00:58:06,520 --> 00:58:09,770
转换的输出请将输出保存到

1174
00:58:09,770 --> 00:58:11,770
HDFS

1175
00:58:11,770 --> 00:58:14,750
等等一切，然后如果有什么

1176
00:58:14,750 --> 00:58:18,560
失败，火花会知道，aha

1177
00:58:18,560 --> 00:58:21,410
正在进行的转换的输出

1178
00:58:21,410 --> 00:58:24,680
是安全的，所以我们只需

1179
00:58:24,680 --> 00:58:28,510
要从每个 DFS 读取它，而不是

1180
00:58:28,510 --> 00:58:30,770
重新计算所有分区的所有分区，

1181
00:58:30,770 --> 00:58:34,280
回到时间的开始，

1182
00:58:34,280 --> 00:58:36,260
因为 HDFS 是 一个单独的存储

1183
00:58:36,260 --> 00:58:38,570
系统，它本身以

1184
00:58:38,570 --> 00:58:40,250
容错方式复制一个工作人员失败的事实

1185
00:58:40,250 --> 00:58:43,190
你知道

1186
00:58:43,190 --> 00:58:47,950
即使一个工作人员失败，HDFS仍然可用，

1187
00:58:49,690 --> 00:58:55,390
所以我认为对于我们的示例 PageRank

1188
00:58:55,390 --> 00:58:59,480
我认为传统的方法

1189
00:58:59,480 --> 00:59:02,350
是 告诉

1190
00:59:02,350 --> 00:59:06,410
spark 检查点输出以检查

1191
00:59:06,410 --> 00:59:08,720
put 等级，你甚至不知道你

1192
00:59:08,720 --> 00:59:10,340
可以告诉它只定期检查点，

1193
00:59:10,340 --> 00:59:12,500
所以你知道你是否要

1194
00:59:12,500 --> 00:59:16,010
运行这个东西 100 次迭代 ns

1195
00:59:16,010 --> 00:59:18,410
实际上，将整个排名保存到 HDFS 需要相当长的时间，

1196
00:59:18,410 --> 00:59:24,020
因为

1197
00:59:24,020 --> 00:59:25,610
我们再次谈论的

1198
00:59:25,610 --> 00:59:28,250
是总共 TB 的数据，所以也许我们可以

1199
00:59:28,250 --> 00:59:31,730
告诉 SPARC

1200
00:59:31,730 --> 00:59:38,150
每 10 次迭代只查看一次到 HDFS 的检查点排名或

1201
00:59:38,150 --> 00:59:40,640
其他东西 限制扩展，尽管

1202
00:59:40,640 --> 00:59:42,530
您知道这是在

1203
00:59:42,530 --> 00:59:44,870
昂贵的反复将内容保存到

1204
00:59:44,870 --> 00:59:48,290
磁盘与如果工人

1205
00:59:48,290 --> 00:59:51,700
失败您必须返回并重做它的成本之间的权衡，

1206
00:59:55,630 --> 00:59:59,910
伯莎是一个问题，当我们称之为

1207
00:59:59,910 --> 01:00:02,220
确实充当检查点时 知道

1208
01:00:02,220 --> 01:00:03,810
好吧，所以这是一个很好的问题

1209
01:00:03,810 --> 01:00:05,490
，我不知道

1210
01:00:05,490 --> 01:00:08,100
观察结果的答案是我们可以

1211
01:00:08,100 --> 01:00:10,890
在这里调用现金，我们确实可以打电话给收银员，我们可以

1212
01:00:10,890 --> 01:00:14,010
打电话给收银员，通常使用现金

1213
01:00:14,010 --> 01:00:18,960
只是为了将数据保存在内存中

1214
01:00:18,960 --> 01:00:21,540
为了重用它，这肯定是为什么

1215
01:00:21,540 --> 01:00:22,740
在这里调用它的原因，因为我们正在

1216
01:00:22,740 --> 01:00:26,490
使用链接，但在我的示例中，它

1217
01:00:26,490 --> 01:00:30,690
也会产生使

1218
01:00:30,690 --> 01:00:32,400
该阶段的输出在内存中可用的效果，

1219
01:00:32,400 --> 01:00:34,980
尽管不是在 HDFS 上而是在

1220
01:00:34,980 --> 01:00:39,030
我 大多数这些工人和报纸

1221
01:00:39,030 --> 01:00:45,360
从来没有谈论过这种可能性，

1222
01:00:45,360 --> 01:00:46,920
我不确定发生了什么，

1223
01:00:46,920 --> 01:00:49,890
也许这会奏效，或者

1224
01:00:49,890 --> 01:00:52,980
现金请求只是

1225
01:00:52,980 --> 01:00:56,460
建议性的，如果工人用完空间，可能会被驱逐

1226
01:00:56,460 --> 01:00:59,480
意味着

1227
01:00:59,480 --> 01:01:01,740
打电话 现金不会给你它

1228
01:01:01,740 --> 01:01:04,860
不像一个可靠的指示来

1229
01:01:04,860 --> 01:01:06,660
确保数据真的可用它

1230
01:01:06,660 --> 01:01:08,940
很好它可能会在大多数节点上可用，

1231
01:01:08,940 --> 01:01:10,440
但不是所有节点都可用，因为记住

1232
01:01:10,440 --> 01:01:16,680
即使是单个节点也会丢失它的数据，

1233
01:01:16,680 --> 01:01:17,760
我们' 将不得不进行大量的

1234
01:01:17,760 --> 01:01:22,280
重新计算，所以 III 我猜

1235
01:01:22,280 --> 01:01:25,920
，复制持续存在是一个坚定的

1236
01:01:25,920 --> 01:01:28,230
指令，以保证

1237
01:01:28,230 --> 01:01:29,850
即使出现故障，数据也将可用

1238
01:01:29,850 --> 01:01:30,210
 

1239
01:01:30,210 --> 01:01:34,340
我真的不知道这是一个好问题，

1240
01:01:40,110 --> 01:01:46,650
好吧，那就是 编程

1241
01:01:46,650 --> 01:01:48,630
模型、执行模型和

1242
01:01:48,630 --> 01:01:52,430
故障策略，顺便说

1243
01:01:52,430 --> 01:01:54,600
一下，在故障策略上

1244
01:01:54,600 --> 01:01:56,820
稍微多一点这些系统进行

1245
01:01:56,820 --> 01:02:00,450
故障恢复的方式并不是一件

1246
01:02:00,450 --> 01:02:04,440
小事，因为人们构建双

1247
01:02:04,440 --> 01:02:06,420
拥有成千上万台机器的更大和更大的集群

1248
01:02:06,420 --> 01:02:08,430
你

1249
01:02:08,430 --> 01:02:10,020
知道作业将

1250
01:02:10,020 --> 01:02:13,200
被至少一个工人故障打断的概率它

1251
01:02:13,200 --> 01:02:16,700
确实开始接近一个，因此

1252
01:02:16,700 --> 01:02:20,040
最近旨在

1253
01:02:20,040 --> 01:02:22,740
在大型集群上运行的设计确实

1254
01:02:22,740 --> 01:02:25,920
是 很大程度上受故障

1255
01:02:25,920 --> 01:02:28,170
恢复策略支配，

1256
01:02:28,170 --> 01:02:31,680
例如，这就是为什么 SPARC

1257
01:02:31,680 --> 01:02:35,240
坚持认为转换是

1258
01:02:35,240 --> 01:02:39,780
确定性的以及为什么这些

1259
01:02:39,780 --> 01:02:44,340
rdd 是不可变的，因为你知道

1260
01:02:44,340 --> 01:02:47,820
这就是它可以

1261
01:02:47,820 --> 01:02:49,800
通过简单地重新计算一个来从故障中恢复的原因

1262
01:02:49,800 --> 01:02:51,570
分区而不是必须从头开始

1263
01:02:51,570 --> 01:02:53,750
整个计算，并且

1264
01:02:53,750 --> 01:02:56,460
过去有大量

1265
01:02:56,460 --> 01:02:59,850
提出的集群大数据

1266
01:02:59,850 --> 01:03:02,490
执行模型，其中确实存在

1267
01:03:02,490 --> 01:03:03,930
可变数据，并且

1268
01:03:03,930 --> 01:03:06,330
 

1269
01:03:06,330 --> 01:03:08,130
如果您查找分布式计算可能是非确定性的 共享

1270
01:03:08,130 --> 01:03:10,860
内存系统都支持可变

1271
01:03:10,860 --> 01:03:14,340
数据并且它们支持非确定性

1272
01:03:14,340 --> 01:03:18,090
执行但是 因为他们往往

1273
01:03:18,090 --> 01:03:20,480
没有一个好的故障策略，所以

1274
01:03:20,480 --> 01:03:22,860
你知道三十年前，当一个大

1275
01:03:22,860 --> 01:03:25,410
集群用于计算机时，这些都不

1276
01:03:25,410 --> 01:03:26,970
重要，因为故障概率

1277
01:03:26,970 --> 01:03:29,250
非常低，而且当时有这么多

1278
01:03:29,250 --> 01:03:32,990
不同类型的计算模型

1279
01:03:32,990 --> 01:03:36,240
似乎是合理的，但作为

1280
01:03:36,240 --> 01:03:37,710
集群已经发展到

1281
01:03:37,710 --> 01:03:41,600
成百上千的工人，真正

1282
01:03:41,600 --> 01:03:44,130
幸存下来的模型是

1283
01:03:44,130 --> 01:03:47,400
那些你可以设计一个非常有效的

1284
01:03:47,400 --> 01:03:49,350
故障恢复策略的模型，

1285
01:03:49,350 --> 01:03:52,890
不需要从

1286
01:03:52,890 --> 01:03:53,730
一开始就备份

1287
01:03:53,730 --> 01:03:56,160
并重新启动论文所讨论的

1288
01:03:56,160 --> 01:03:57,750
当它批评

1289
01:03:57,750 --> 01:04:01,140
我是分布式共享内存时，

1290
01:04:01,140 --> 01:04:05,900
这是一个非常有效的

1291
01:04:05,900 --> 01:04:14,030
 

1292
01:04:14,030 --> 01:04:17,220
 

1293
01:04:17,220 --> 01:04:19,640
 

1294
01:04:19,640 --> 01:04:23,880
批评 批量数据

1295
01:04:23,880 --> 01:04:25,440
处理，所以如果你有 TB 的

1296
01:04:25,440 --> 01:04:27,660
数据，并且你想知道，你需要花

1297
01:04:27,660 --> 01:04:31,500
几个小时咀嚼它，

1298
01:04:31,500 --> 01:04:34,290
如果你是聪明的，那就太好了 重新经营一家银行，您需要

1299
01:04:34,290 --> 01:04:37,530
处理银行转账或人们的

1300
01:04:37,530 --> 01:04:40,050
余额查询，那么 SPARC

1301
01:04:40,050 --> 01:04:43,650
与

1302
01:04:43,650 --> 01:04:45,600
已知的那种处理或

1303
01:04:45,600 --> 01:04:48,119
我登录的典型网站无关，您知道我访问

1304
01:04:48,119 --> 01:04:52,260
亚马逊，我想订购一些

1305
01:04:52,260 --> 01:04:53,880
纸巾 并将它们放入我的购物

1306
01:04:53,880 --> 01:04:55,670
车 SPARC 不会帮助您

1307
01:04:55,670 --> 01:04:58,680
维护这部分购物车

1308
01:04:58,680 --> 01:05:00,480
SPARC 可能有助于分析您的

1309
01:05:00,480 --> 01:05:03,800
客户离线购买习惯，

1310
01:05:03,800 --> 01:05:07,400
但不适用于在线

1311
01:05:07,400 --> 01:05:11,369
处理另一种更

1312
01:05:11,369 --> 01:05:14,250
接近的 在论文中引发

1313
01:05:14,250 --> 01:05:15,900
的不太擅长的情况是流

1314
01:05:15,900 --> 01:05:18,359
处理 i SPARC 肯定

1315
01:05:18,359 --> 01:05:19,790
假设所有输入都已经可用，

1316
01:05:19,790 --> 01:05:22,590
但在许多情况下，

1317
01:05:22,590 --> 01:05:26,010
人们拥有的输入实际上是输入流，

1318
01:05:26,010 --> 01:05:28,680
就像他们正在记录所有用户点击一样

1319
01:05:28,680 --> 01:05:30,180
他们的网站，他们想分析

1320
01:05:30,180 --> 01:05:32,369
它们以了解用户行为 你

1321
01:05:32,369 --> 01:05:35,100
知道这不是一种固定数量的

1322
01:05:35,100 --> 01:05:36,740
数据实际上是输入数据流

1323
01:05:36,740 --> 01:05:40,470
你知道 SPARC 就像在 de 写

1324
01:05:40,470 --> 01:05:42,510
这篇论文并没有真正

1325
01:05:42,510 --> 01:05:46,109
谈论处理数据流，

1326
01:05:46,109 --> 01:05:47,520
但事实证明，

1327
01:05:47,520 --> 01:05:51,480
对于喜欢使用 spark 的人来说，它离家很近，

1328
01:05:51,480 --> 01:05:52,890
现在有一种称为 spark 流的 SPARC 变

1329
01:05:52,890 --> 01:05:54,810
体，它

1330
01:05:54,810 --> 01:05:57,420
更多一点 准备好在

1331
01:05:57,420 --> 01:05:59,550
数据到达时对其进行处理，并且您知道

1332
01:05:59,550 --> 01:06:01,500
将其分解为较小的批次并

1333
01:06:01,500 --> 01:06:05,390
一次分批运行以激发火花，

1334
01:06:05,390 --> 01:06:07,680
因此它对很多坏东西都有好处，但这

1335
01:06:07,680 --> 01:06:10,920
肯定是正确的

1336
01:06:10,920 --> 01:06:13,620
包装 在 UH 上，您应该将 spark 视为

1337
01:06:13,620 --> 01:06:16,920
MapReduce 之后的一种演变，

1338
01:06:16,920 --> 01:06:19,940
我可能会解决一些表达性和

1339
01:06:19,940 --> 01:06:25,080
性能方面的问题，或者

1340
01:06:25,080 --> 01:06:28,800
MapReduce 有很多 SPARC

1341
01:06:28,800 --> 01:06:31,080
正在做的事情是使数据流图变得

1342
01:06:31,080 --> 01:06:34,410
明确，他希望你这样做

1343
01:06:34,410 --> 01:06:36,360
 

1344
01:06:36,360 --> 01:06:39,000
以整个谱系图的图三的方式思考

1345
01:06:39,000 --> 01:06:41,610
计算阶段以及在这些阶段之间移动的数据

1346
01:06:41,610 --> 01:06:44,460
，并

1347
01:06:44,460 --> 01:06:47,310
在此图上进行优化，故障恢复

1348
01:06:47,310 --> 01:06:49,140
非常考虑林 eage

1349
01:06:49,140 --> 01:06:52,440
图也是如此，因此它实际上是

1350
01:06:52,440 --> 01:06:54,120
更大的举措和大数据处理的一部分，

1351
01:06:54,120 --> 01:06:57,600
朝着明确考虑数据

1352
01:06:57,600 --> 01:07:00,480
流图作为描述

1353
01:07:00,480 --> 01:07:04,500
计算的一种方式，许多特定的胜利

1354
01:07:04,500 --> 01:07:06,980
和 SPARC 与

1355
01:07:06,980 --> 01:07:09,630
前面的性能部分有关，这些很

1356
01:07:09,630 --> 01:07:11,040
简单 但是

1357
01:07:11,040 --> 01:07:13,980
重要的一些性能

1358
01:07:13,980 --> 01:07:15,780
来自于在转换之间将数据留在内存中，

1359
01:07:15,780 --> 01:07:18,750
而不是您知道

1360
01:07:18,750 --> 01:07:20,460
将它们写入 GFS，然后

1361
01:07:20,460 --> 01:07:21,600
在下一次转换开始时将它们读回，

1362
01:07:21,600 --> 01:07:23,490
这

1363
01:07:23,490 --> 01:07:25,950
实际上与 MapReduce 相关，另一个

1364
01:07:25,950 --> 01:07:28,530
是能力 定义这些数据集，

1365
01:07:28,530 --> 01:07:32,760
这些是 Dedes 并告诉 SPARC

1366
01:07:32,760 --> 01:07:34,920
将此 RDD 留在内存中，因为我将

1367
01:07:34,920 --> 01:07:37,920
再次重用它和后续阶段，

1368
01:07:37,920 --> 01:07:39,750
重用它比

1369
01:07:39,750 --> 01:07:41,760
重新计算它更便宜，而且这种

1370
01:07:41,760 --> 01:07:45,600
事情很容易而且 SPARC 并且

1371
01:07:45,600 --> 01:07:48,720
在 MapReduce 中很难获得，结果是一个

1372
01:07:48,720 --> 01:07:51,120
非常成功且使用

1373
01:07:51,120 --> 01:07:55,560
非常广泛的系统，如果你值得

1374
01:07:55,560 --> 01:07:59,820
真正的成功，好吧 这就是我

1375
01:07:59,820 --> 01:08:01,980
要说的，如果有人有问题，我很乐意回答

1376
01:08:01,980 --> 01:08:04,820
 

1377
01:08:09,910 --> 01:08:11,970
你

