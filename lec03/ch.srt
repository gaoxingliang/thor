1
00:00:00,600 --> 00:00:05,640
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
好啦，咱们开始上课

2
00:00:05,640 --> 00:00:09,389
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
今天咱们谈谈 GFS

3
00:00:09,389 --> 00:00:10,980
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
也就是就是今天我们要读的论文《The Google File System》

4
00:00:10,980 --> 00:00:12,660
这也是在咱们这门课里

5
00:00:12,660 --> 00:00:15,540
众多 case 里要学的第一篇

6
00:00:15,540 --> 00:00:17,160
关于如何构建大型存储的文章

7
00:00:17,160 --> 00:00:19,410
关于如何构建大型存储的文章

8
00:00:19,410 --> 00:00:29,310
这里“大型存储”是一个很大的话题

9
00:00:29,310 --> 00:00:31,410
为什么是存储？

10
00:00:31,410 --> 00:00:34,260
因为存储被证明是一种关键抽象

11
00:00:34,260 --> 00:00:35,850
如果你还不知道的话

12
00:00:35,850 --> 00:00:37,230
你可以想象在分布式系统中

13
00:00:37,230 --> 00:00:40,050
你希望使用的各种不同的抽象

14
00:00:40,050 --> 00:00:42,030
你希望使用的各种不同的抽象

15
00:00:42,030 --> 00:00:43,650
但事实表明

16
00:00:43,650 --> 00:00:47,730
简单的存储接口往往更有用而且更加通用

17
00:00:47,730 --> 00:00:50,010
简单的存储接口往往更有用而且更加通用

18
00:00:50,010 --> 00:00:51,480
构建分布式系统

19
00:00:51,480 --> 00:00:53,280
大多都是关于如何设计存储系统

20
00:00:53,280 --> 00:00:55,170
或是设计其它类型的系统

21
00:00:55,170 --> 00:00:57,630
在它的底层

22
00:00:57,630 --> 00:01:00,180
运行着一个不错的大型分布式存储系统

23
00:01:00,180 --> 00:01:02,989
运行着一个不错的大型分布式存储系统

24
00:01:02,989 --> 00:01:05,519
运行着一个不错的大型分布式存储系统

25
00:01:05,519 --> 00:01:07,500
所以我们会更加关注

26
00:01:07,500 --> 00:01:09,360
如何为大型分布式存储系统设计一个优秀的接口

27
00:01:09,360 --> 00:01:12,420
如何为大型分布式存储系统设计一个优秀的接口

28
00:01:12,420 --> 00:01:14,159
以及如何设计存储系统的内部结构

29
00:01:14,159 --> 00:01:18,030
这样它才具备良好的行为

30
00:01:18,030 --> 00:01:19,229
通过阅读这篇论文可以让我们起步

31
00:01:19,229 --> 00:01:20,850
通过阅读这篇论文可以让我们起步

32
00:01:20,850 --> 00:01:22,530
论文也涉及到很多本课程常出现的话题

33
00:01:22,530 --> 00:01:24,900
论文也涉及到很多本课程常出现的话题

34
00:01:24,900 --> 00:01:27,060
主要包括并行性能、容错、复制和一致性

35
00:01:27,060 --> 00:01:31,740
主要包括并行性能、容错、复制和一致性

36
00:01:31,740 --> 00:01:34,140
论文的内容也像 Go 语言那样，简单明了

37
00:01:34,140 --> 00:01:36,390
论文的内容也像 Go 语言那样，简单明了

38
00:01:36,390 --> 00:01:38,670
这也是一篇非常优秀的系统论文

39
00:01:38,670 --> 00:01:40,560
从硬件到软件

40
00:01:40,560 --> 00:01:43,229
到最终构建出整个系统都有涉及

41
00:01:43,229 --> 00:01:45,960
到最终构建出整个系统都有涉及

42
00:01:45,960 --> 00:01:49,320
而且在现实世界中 它也设计的相当成功

43
00:01:49,320 --> 00:01:51,030
尽管这是在学术会议上发表的论文

44
00:01:51,030 --> 00:01:53,189
尽管这是在学术会议上发表的论文

45
00:01:53,189 --> 00:01:54,890
但是文章里介绍的东西(GFS)也相当成功

46
00:01:54,890 --> 00:01:57,030
在现实世界中也使用了相当长的时间

47
00:01:57,030 --> 00:01:58,650
所以，在这里

48
00:01:58,650 --> 00:02:02,340
咱们讨论的这些东西 真的相当牛逼

49
00:02:02,340 --> 00:02:07,110
咱们讨论的这些东西 真的相当牛逼

50
00:02:07,110 --> 00:02:09,149
不过在讨论 GFS 前

51
00:02:09,149 --> 00:02:11,279
我想聊聊一点关于分布式存储系统的空间

52
00:02:11,279 --> 00:02:13,030
我想聊聊一点关于分布式存储系统的空间

53
00:02:13,030 --> 00:02:18,810
首先 为什么它会如此之难？

54
00:02:19,920 --> 00:02:23,560
你需要做大量的工作才能让他变得正确

55
00:02:23,560 --> 00:02:25,900
但在 6.824 里

56
00:02:25,900 --> 00:02:28,330
会有一些特殊的讲述方式

57
00:02:28,330 --> 00:02:32,140
在未来很多系统里你将会接触到

58
00:02:32,140 --> 00:02:34,180
人们设计大型分布式系统

59
00:02:34,180 --> 00:02:35,890
或大型存储系统 通常的出发点是

60
00:02:35,890 --> 00:02:37,330
为了获得巨大的综合性能

61
00:02:37,330 --> 00:02:39,340
为了获得巨大的综合性能

62
00:02:39,340 --> 00:02:43,090
要能利用数百台机器的资源 来完成大量工作

63
00:02:43,090 --> 00:02:44,620
要能利用数百台机器的资源 来完成大量工作

64
00:02:44,620 --> 00:02:48,000
因此 性能问题就成为了最初的诉求

65
00:02:48,000 --> 00:02:54,430
因此 性能问题就成为了最初的诉求

66
00:02:54,430 --> 00:02:57,010
因此有个很自然的想法

67
00:02:57,010 --> 00:02:59,019
将数据进行分割 放到大量服务器上

68
00:02:59,019 --> 00:03:00,640
将数据进行分割 放到大量服务器上

69
00:03:00,640 --> 00:03:04,420
从而能够并行地 从多台服务器读取数据

70
00:03:04,420 --> 00:03:05,769
通常 我们把这种方式称为 分片(sharding)

71
00:03:05,769 --> 00:03:11,160
如果你将数据分片到成百上千台服务器上

72
00:03:11,160 --> 00:03:13,600
如果你将数据分片到成百上千台服务器上

73
00:03:13,600 --> 00:03:15,970
你会发现出错成了常态

74
00:03:15,970 --> 00:03:17,140
在上千台服务器中 总有那么几台会宕机

75
00:03:17,140 --> 00:03:20,680
在上千台服务器中 总有那么几台会宕机

76
00:03:20,680 --> 00:03:25,540
所以每天 每小时都在发生错误

77
00:03:25,540 --> 00:03:27,250
所以 我们需要自动化的方法去纠正它

78
00:03:27,250 --> 00:03:29,350
你不可能靠人工去发现并纠正这些错误

79
00:03:29,350 --> 00:03:31,890
所以 得需要有一个自动化的 容错(fault-tolerant, ft)系统

80
00:03:31,890 --> 00:03:38,290
所以 得需要有一个自动化的 容错(fault-tolerant, ft)系统

81
00:03:38,290 --> 00:03:43,090
这就引出 容错 这个话题

82
00:03:43,090 --> 00:03:44,920
实现容错最有用的一种方法是使用复制

83
00:03:44,920 --> 00:03:46,630
实现容错最有用的一种方法是使用复制

84
00:03:46,630 --> 00:03:48,190
只需保留两三个或更多数量数据副本

85
00:03:48,190 --> 00:03:52,390
只要其中有一个失败，你就可以使用另一个

86
00:03:52,390 --> 00:03:56,010
所以，如果想要容错能力，就得有 复制（replication）

87
00:03:56,010 --> 00:04:03,100
如果有复制 两份数据的副本

88
00:04:03,100 --> 00:04:05,470
如果有复制 两份数据的副本

89
00:04:05,470 --> 00:04:07,329
可以确定的是 如果你不小心 它们就会不一致

90
00:04:07,329 --> 00:04:09,010
所以如果你有 2 个数据副本（replicas）

91
00:04:09,010 --> 00:04:10,750
你就能使用其中之一替换另一个 进行容错

92
00:04:10,750 --> 00:04:12,549
你就能使用其中之一替换另一个 进行容错

93
00:04:12,549 --> 00:04:14,170
你就能使用其中之一替换另一个 进行容错

94
00:04:14,170 --> 00:04:15,670
如果你不小心弄出两个几乎不同的 replicas

95
00:04:15,670 --> 00:04:18,640
如果你不小心弄出两个几乎不同的 replicas

96
00:04:18,640 --> 00:04:20,289
严格来讲它们就算不上 replicas

97
00:04:20,289 --> 00:04:22,180
那么 你获得的数据 将取决于与向哪个服务器请求

98
00:04:22,180 --> 00:04:24,039
那么 你获得的数据 将取决于与向哪个服务器请求

99
00:04:24,039 --> 00:04:25,240
这样的话 应用程序用起来就有点棘手

100
00:04:25,240 --> 00:04:28,420
这样的话 应用程序用起来就有点棘手

101
00:04:28,420 --> 00:04:34,330
所以如果采用复制 就可能遇到奇怪的不一致问题

102
00:04:34,330 --> 00:04:41,800
所以如果采用复制 就可能遇到奇怪的不一致问题

103
00:04:41,800 --> 00:04:45,400
当然 有聪明的设计 可以让你避免不一致

104
00:04:45,400 --> 00:04:47,680
并使数据看起来是行为良好的

105
00:04:47,680 --> 00:04:49,450
但这种设计的代价是 你得做更多额外的工作

106
00:04:49,450 --> 00:04:51,210
但这种设计的代价是 你得做更多额外的工作

107
00:04:51,210 --> 00:04:53,140
以及网络中所有不同服务器和客户端之间的额外通信

108
00:04:53,140 --> 00:04:54,610
以及网络中所有不同服务器和客户端之间的额外通信

109
00:04:54,610 --> 00:04:58,470
这样性能也就变低了

110
00:04:59,550 --> 00:05:09,190
因此 如果要保持一致性 你的性能就会变低

111
00:05:09,190 --> 00:05:11,740
当然这也违背了我们的初衷

112
00:05:11,740 --> 00:05:13,420
当然这是绝对的

113
00:05:13,420 --> 00:05:14,650
你可以构建 高性能的系统

114
00:05:14,650 --> 00:05:16,990
在设计这些系统的时候 这些事情你都需要去面对

115
00:05:16,990 --> 00:05:19,480
在设计这些系统的时候 这些事情你都需要去面对

116
00:05:19,480 --> 00:05:21,370
在设计这些系统的时候 这些事情你都需要去面对

117
00:05:21,370 --> 00:05:24,670
所以这就会导致你需要在

118
00:05:24,670 --> 00:05:26,920
性能目标和实现良好的一致性之间做权衡

119
00:05:26,920 --> 00:05:29,020
性能目标和实现良好的一致性之间做权衡

120
00:05:29,020 --> 00:05:31,720
并因此付出一些代价

121
00:05:31,720 --> 00:05:33,730
如果你不想付出代价 那你就得接受系统的异常行为

122
00:05:33,730 --> 00:05:35,830
如果你不想付出代价 那你就得接受系统的异常行为

123
00:05:35,830 --> 00:05:37,930
我把这些东西写在这里

124
00:05:37,930 --> 00:05:39,840
因为在未来许多系统里 你都能经常见到这些东西

125
00:05:39,840 --> 00:05:42,310
因为在未来许多系统里 你都能经常见到这些东西

126
00:05:42,310 --> 00:05:45,580
有很多人都不太愿意在良好的一致性（强一致性）上面花费精力

127
00:05:45,580 --> 00:05:48,070
有很多人都不太愿意在良好的一致性（强一致性）上面花费精力

128
00:05:48,070 --> 00:05:52,930
有很多人都不太愿意在良好的一致性（强一致性）上面花费精力

129
00:05:52,930 --> 00:05:57,520
在接下来的课程里我将会讨论更多关于良好一致性的话题

130
00:05:57,520 --> 00:06:02,050
在接下来的课程里我将会讨论更多关于良好一致性的话题

131
00:06:02,050 --> 00:06:04,000
在接下来的课程里我将会讨论更多关于良好一致性的话题

132
00:06:04,000 --> 00:06:07,000
你可以把“强一致性”(strong consistency)

133
00:06:07,000 --> 00:06:09,280
或是“良好一致性”的系统想象成就像是一台单机 server 一样

134
00:06:09,280 --> 00:06:11,410
或是“良好一致性”的系统想象成就像是一台单机 server 一样

135
00:06:11,410 --> 00:06:13,930
应用程序或是客户端和它通信，感觉就像是和一台 server 通信

136
00:06:13,930 --> 00:06:15,610
应用程序或是客户端和它通信，感觉就像是和一台 server 通信

137
00:06:15,610 --> 00:06:18,760
应用程序或是客户端和它通信，感觉就像是和一台 server 通信

138
00:06:18,760 --> 00:06:20,260
在数百台机器上的构建的理想的强一致模型的系统

139
00:06:20,260 --> 00:06:23,170
在数百台机器上的构建的理想的强一致模型的系统

140
00:06:23,170 --> 00:06:25,000
在同一时刻你只能请求到一台 server 上的一个数据副本

141
00:06:25,000 --> 00:06:26,560
在同一时刻你只能请求到一台 server 上的一个数据副本

142
00:06:26,560 --> 00:06:31,810
在同一时刻你只能请求到一台 server 上的一个数据副本

143
00:06:31,810 --> 00:06:34,349
这是思考强一致的一种最直觉的方式

144
00:06:34,349 --> 00:06:41,169
这是思考强一致的一种最直觉的方式

145
00:06:41,169 --> 00:06:42,789
这是思考强一致的一种最直觉的方式

146
00:06:42,789 --> 00:06:45,490
你可以想象你有一台服务器

147
00:06:45,490 --> 00:06:47,020
这里假设它是单线程服务

148
00:06:47,020 --> 00:06:49,210
在同一时刻它处理来自多个客户端的请求

149
00:06:49,210 --> 00:06:50,919
在同一时刻它处理来自多个客户端的请求

150
00:06:50,919 --> 00:06:52,569
这很重要，因为有大量客户端可能会同时并发的请求 server

151
00:06:52,569 --> 00:06:55,509
这很重要，因为有大量客户端可能会同时并发的请求 server

152
00:06:55,509 --> 00:06:57,370
server 看到这些请求后

153
00:06:57,370 --> 00:06:59,020
首先会从中挑选一个出来

154
00:06:59,020 --> 00:07:00,729
首先会从中挑选一个出来

155
00:07:00,729 --> 00:07:04,090
处理请求结束后 然后继续处理下一个

156
00:07:04,090 --> 00:07:06,099
对于存储服务来说 你知道它会有一块磁盘

157
00:07:06,099 --> 00:07:07,629
对于存储服务来说 你知道它会有一块磁盘

158
00:07:07,629 --> 00:07:10,060
这意味着处理一条请求可能会写入一条 item

159
00:07:10,060 --> 00:07:12,610
这意味着处理一条请求可能会写入一条 item

160
00:07:12,610 --> 00:07:14,710
也可能是给某个 item 做自增

161
00:07:14,710 --> 00:07:17,979
这里自增一个 item 是指它是否是一个可修改操作

162
00:07:17,979 --> 00:07:21,069
我有一些数据记录在这个表中

163
00:07:21,069 --> 00:07:23,680
它可能是通过 key-value 进行索引的数据

164
00:07:23,680 --> 00:07:25,240
它可能是通过 key-value 进行索引的数据

165
00:07:25,240 --> 00:07:27,039
然后我们打算更新这个表

166
00:07:27,039 --> 00:07:28,240
如果一条请求进来读取它

167
00:07:28,240 --> 00:07:30,099
只需要把写入的数据拉出来就行了

168
00:07:30,099 --> 00:07:36,759
这里有一条法则

169
00:07:36,759 --> 00:07:39,580
要想使得 server 行为良好

170
00:07:39,580 --> 00:07:41,740
那么 server 必须以一种简单的模型去运行

171
00:07:41,740 --> 00:07:44,710
即同一时刻，只处理一条请求

172
00:07:44,710 --> 00:07:48,129
即同一时刻，只处理一条请求

173
00:07:48,129 --> 00:07:49,990
任何请求看到的数据

174
00:07:49,990 --> 00:07:51,819
都能反应出在这之前所有的有序的操作

175
00:07:51,819 --> 00:07:53,560
所以 如果有一系列的写操作请求同时到来

176
00:07:53,560 --> 00:07:55,360
server 就会有序的处理它们

177
00:07:55,360 --> 00:07:58,060
当你读取的时候 你就能读取到你期望的值

178
00:07:58,060 --> 00:08:00,009
当你读取的时候 你就能读取到你期望的值

179
00:08:00,009 --> 00:08:05,169
当你读取的时候 你就能读取到你期望的值

180
00:08:05,169 --> 00:08:07,029
这个行为仍然没那么简单

181
00:08:07,029 --> 00:08:09,659
你不得不花上几秒的时间去考虑一些事情

182
00:08:09,659 --> 00:08:11,919
你不得不花上几秒的时间去考虑一些事情

183
00:08:11,919 --> 00:08:13,629
你不得不花上几秒的时间去考虑一些事情

184
00:08:13,629 --> 00:08:19,539
比如我们有几个客户端

185
00:08:19,539 --> 00:08:25,180
客户端 C1 发起写请求写 x 并把它的值设置成 1

186
00:08:25,180 --> 00:08:27,460
客户端 C1 发起写请求写 x 并把它的值设置成 1

187
00:08:27,460 --> 00:08:30,460
在同一时刻 客户端 C2 发起请求也写 x

188
00:08:30,460 --> 00:08:32,159
但是它想把值设置成一个不同的值(2)

189
00:08:32,159 --> 00:08:34,360
但是它想把值设置成一个不同的值(2)

190
00:08:34,360 --> 00:08:35,860
但是它想把值设置成一个不同的值(2)

191
00:08:35,860 --> 00:08:38,409
现在有别的事情发生了

192
00:08:38,409 --> 00:08:42,490
客户端 C3 请求读并得到一个结果

193
00:08:42,490 --> 00:08:44,020
或者说 C3 在写请求结束后读取会得到一个结果

194
00:08:44,020 --> 00:08:47,220
或者说 C3 在写请求结束后读取会得到一个结果

195
00:08:47,220 --> 00:08:50,290
客户端 C4 读取 x 也得到一个结果

196
00:08:50,290 --> 00:08:51,999
那么这两个客户端看到的结果是多少？

197
00:08:51,999 --> 00:09:00,959
(提问)

198
00:09:04,700 --> 00:09:07,200
很好，这个问题不错

199
00:09:07,200 --> 00:09:09,060
这里的客户端 C1 和 C2

200
00:09:09,060 --> 00:09:10,770
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
我假设它们是在同时发起的请求

201
00:09:10,770 --> 00:09:12,720
如果监控网络的话 我们能看到 2 个请求同时到达服务器

202
00:09:12,720 --> 00:09:14,190
如果监控网络的话 我们能看到 2 个请求同时到达服务器

203
00:09:14,190 --> 00:09:16,500
如果监控网络的话 我们能看到 2 个请求同时到达服务器

204
00:09:16,500 --> 00:09:19,710
接下来在某个时刻后 服务器会回复它们

205
00:09:19,710 --> 00:09:20,520
接下来在某个时刻后 服务器会回复它们

206
00:09:20,520 --> 00:09:23,790
这里不足以判断客户端是否收到了第一条请求的回复

207
00:09:23,790 --> 00:09:26,070
这里不足以判断客户端是否收到了第一条请求的回复

208
00:09:26,070 --> 00:09:28,530
不足以判断第一条请求是否被处理

209
00:09:28,530 --> 00:09:30,780
也不足以判断服务器是以何种方式处理的它们

210
00:09:30,780 --> 00:09:32,880
也不足以判断服务器是以何种方式处理的它们

211
00:09:32,880 --> 00:09:35,460
也不足以判断服务器是以何种方式处理的它们

212
00:09:35,460 --> 00:09:38,580
当然了，如果它先处理这个请求

213
00:09:38,580 --> 00:09:41,760
然后就意味着它会处理这边这条请求 把值设置成 2

214
00:09:41,760 --> 00:09:43,800
然后就意味着它会处理这边这条请求 把值设置成 2

215
00:09:43,800 --> 00:09:46,350
接下来后续的读将看到 2

216
00:09:46,350 --> 00:09:48,030
如果 server 先处理这条请求

217
00:09:48,030 --> 00:09:50,250
然后再处理这条请求

218
00:09:50,250 --> 00:09:52,020
这意味着最终的结果是 1

219
00:09:52,020 --> 00:09:54,060
然后这两条读请求就会看到 1

220
00:09:54,060 --> 00:09:56,670
提出这个问题的目的是想说明

221
00:09:56,670 --> 00:09:58,950
即使是在一个非常简单的系统里也会存在模棱两可的结果

222
00:09:58,950 --> 00:10:01,230
即使是在一个非常简单的系统里也会存在模棱两可的结果

223
00:10:01,230 --> 00:10:04,020
你没办法判断出服务器到底会先处理哪条请求

224
00:10:04,020 --> 00:10:05,190
也无法判断哪条回复会被先发出去

225
00:10:05,190 --> 00:10:08,820
你能做到的只是判断

226
00:10:08,820 --> 00:10:11,250
在可能的执行上 产生的结果是一致还是不一致的

227
00:10:11,250 --> 00:10:13,470
在可能的执行上 产生的结果是一致还是不一致的

228
00:10:13,470 --> 00:10:17,850
所以我们肯定能看到有一些完全错误的结果

229
00:10:17,850 --> 00:10:21,060
所以我们肯定能看到有一些完全错误的结果

230
00:10:21,060 --> 00:10:24,030
如果客户端 C3 看到了 2

231
00:10:24,030 --> 00:10:27,210
客户端 C4 最好也要能看到 2

232
00:10:27,210 --> 00:10:29,040
因为我们的模型保证第二次写之后是没有问题的

233
00:10:29,040 --> 00:10:30,750
客户端 C3 能看到 2 意味着这条请求一定是第 2 次执行

234
00:10:30,750 --> 00:10:33,870
客户端 C3 能看到 2 意味着这条请求一定是第 2 次执行

235
00:10:33,870 --> 00:10:35,700
最好是这样 当客户端 C4 能读取到 2 时

236
00:10:35,700 --> 00:10:37,620
它也必须是第二次写入

237
00:10:37,620 --> 00:10:41,220
希望这些东西足够直白

238
00:10:41,220 --> 00:10:43,410
希望这些东西足够简单 且如预期那样

239
00:10:43,410 --> 00:10:47,790
因为它就是强一致性的直观模型

240
00:10:47,790 --> 00:10:49,200
因为它就是强一致性的直观模型

241
00:10:49,200 --> 00:10:53,190
ok 这有什么问题呢？

242
00:10:53,190 --> 00:10:54,300
问题在于单个服务器的容错能力很差

243
00:10:54,300 --> 00:10:56,370
问题在于单个服务器的容错能力很差

244
00:10:56,370 --> 00:10:57,840
如果它 crash 了 或是磁盘坏了

245
00:10:57,840 --> 00:11:00,870
那就什么东西都留不下来了

246
00:11:00,870 --> 00:11:02,520
所以在现实世界中的分布式系统

247
00:11:02,520 --> 00:11:05,430
我们实际上都会构建一个复制系统

248
00:11:05,430 --> 00:11:06,930
但是 当我们有了第二份数据副本时

249
00:11:06,930 --> 00:11:08,220
但是 当我们有了第二份数据副本时

250
00:11:08,220 --> 00:11:12,060
这成为了所有问题的发源地

251
00:11:12,060 --> 00:11:16,180
这里有一个最糟糕的副本设计方案

252
00:11:16,180 --> 00:11:19,220
我写这个是为了警告你

253
00:11:19,220 --> 00:11:20,810
这个问题在 GFS 中你也会发现

254
00:11:20,810 --> 00:11:23,960
好 这里应该写 bad replication design

255
00:11:23,960 --> 00:11:30,380
假设现在我们有 2 台 server

256
00:11:30,380 --> 00:11:32,630
每台都有一份完整的数据副本

257
00:11:32,630 --> 00:11:38,510
然后在磁盘上 他们都有这样一个 key-value 表格

258
00:11:38,510 --> 00:11:40,730
然后在磁盘上 他们都有这样一个 key-value 表格

259
00:11:40,730 --> 00:11:44,810
直观上 当然了 我们希望让这两张表完全一致

260
00:11:44,810 --> 00:11:47,090
直观上 当然了 我们希望让这两张表完全一致

261
00:11:47,090 --> 00:11:49,880
直观上 当然了 我们希望让这两张表完全一致

262
00:11:49,880 --> 00:11:51,650
所以 如果其中一台 server 失败了

263
00:11:51,650 --> 00:11:53,720
我们可以读写另一台服务器

264
00:11:53,720 --> 00:11:55,490
这意味着 每一个写操作都必须在所有的 server 处理

265
00:11:55,490 --> 00:11:59,210
这意味着 每一个写操作都必须在所有的 server 处理

266
00:11:59,210 --> 00:12:00,890
另外 read 只能在单台 server 处理 否则就无法容错了

267
00:12:00,890 --> 00:12:02,570
另外 read 只能在单台 server 处理 否则就无法容错了

268
00:12:02,570 --> 00:12:04,280
因为 如果 read 必须同时和 2 台服务器打交道

269
00:12:04,280 --> 00:12:07,940
就无法在失去其中一台 server 的情况下幸免

270
00:12:07,940 --> 00:12:13,160
所以问题就来了

271
00:12:13,160 --> 00:12:17,030
假设客户端 C1 和 C2 同时想执行这些写操作

272
00:12:17,030 --> 00:12:19,190
假设客户端 C1 和 C2 同时想执行这些写操作

273
00:12:19,190 --> 00:12:20,570
其中一个写 1 另一个写 2

274
00:12:20,570 --> 00:12:22,250
其中一个写 1 另一个写 2

275
00:12:22,250 --> 00:12:25,790
所以客户端 C1 需要将请求 Wx1 发送给两台服务器

276
00:12:25,790 --> 00:12:29,270
因为我们就是想更新这 2 台 server

277
00:12:29,270 --> 00:12:32,600
客户端 C2 将请求 Wx2 发给这 2 台 server

278
00:12:32,600 --> 00:12:41,800
所以这里就导致出错了

279
00:12:41,800 --> 00:12:46,280
(提问) 是的 我们没有做任何事情来保障

280
00:12:46,280 --> 00:12:48,410
2 台 server 以相同的顺序处理这 2 个请求

281
00:12:48,410 --> 00:12:51,590
2 台 server 以相同的顺序处理这 2 个请求

282
00:12:51,590 --> 00:12:53,930
这个设计真的不怎么样

283
00:12:53,930 --> 00:12:57,800
如果 S1 先处理 C1 的请求

284
00:12:57,800 --> 00:13:01,100
处理结束后这里这个值变成 1

285
00:13:01,100 --> 00:13:02,600
处理结束后这里这个值变成 1

286
00:13:02,600 --> 00:13:04,610
接下来 C2 请求过来 覆盖了这个值变成了 2

287
00:13:04,610 --> 00:13:07,610
如果 S2 在接收网络报文的时候

288
00:13:07,610 --> 00:13:09,350
刚好是不同的顺序 先收到 C2 的请求先把值设置成 2

289
00:13:09,350 --> 00:13:11,020
刚好是不同的顺序 先收到 C2 的请求先把值设置成 2

290
00:13:11,020 --> 00:13:13,310
刚好是不同的顺序 先收到 C2 的请求先把值设置成 2

291
00:13:13,310 --> 00:13:15,350
然后收到 C1 的请求 把值设置成了 1

292
00:13:15,350 --> 00:13:18,140
然后收到 C1 的请求 把值设置成了 1

293
00:13:18,140 --> 00:13:20,450
那么现在 后来的客户端读取的话

294
00:13:20,450 --> 00:13:22,760
你应该很清楚 如果碰巧 C3 请求了这台 server

295
00:13:22,760 --> 00:13:25,520
你应该很清楚 如果碰巧 C3 请求了这台 server

296
00:13:25,520 --> 00:13:26,720
而 C4 碰巧访问了另一台 server

297
00:13:26,720 --> 00:13:28,610
于是我们就陷入了一种可怕的场景

298
00:13:28,610 --> 00:13:30,320
他们读取到的值不同

299
00:13:30,320 --> 00:13:33,410
尽管我们对正确服务的直观模型表明

300
00:13:33,410 --> 00:13:35,990
在随后的 2 次读他们都产生了相同的值

301
00:13:35,990 --> 00:13:39,589
在随后的 2 次读他们都产生了相同的值

302
00:13:39,589 --> 00:13:41,930
但这种问题仍然以另一种方式被暴露出来

303
00:13:41,930 --> 00:13:43,579
假设客户端尝试

304
00:13:43,579 --> 00:13:45,920
只从 S1 或是 S2 读取来修复这个问题

305
00:13:45,920 --> 00:13:48,829
只从 S1 或是 S2 读取来修复这个问题

306
00:13:48,829 --> 00:13:51,350
如果我们这样做了 然后也发生了这种情况

307
00:13:51,350 --> 00:13:53,089
过了一会儿 这 2 个客户端都去读这个 server

308
00:13:53,089 --> 00:13:55,279
这 2 个客户端或许都能看见值 2

309
00:13:55,279 --> 00:13:57,649
但是 S1 突然宕机了

310
00:13:57,649 --> 00:14:00,290
x 读取到的值从 2 变成了 1 尽管没有写操作

311
00:14:00,290 --> 00:14:02,050
x 读取到的值从 2 变成了 1 尽管没有写操作

312
00:14:02,050 --> 00:14:04,850
因为 S1 宕机了 所有的客户端都会切换到 S2

313
00:14:04,850 --> 00:14:07,130
因为 S1 宕机了 所有的客户端都会切换到 S2

314
00:14:07,130 --> 00:14:09,079
这并不是这种数据产生的离奇变化 它不和任何写操作对应

315
00:14:09,079 --> 00:14:11,570
这并不是这种数据产生的离奇变化 它不和任何写操作对应

316
00:14:11,570 --> 00:14:13,190
这种事情不会在这种简单的服务模型中发生

317
00:14:13,190 --> 00:14:15,680
这种事情不会在这种简单的服务模型中发生

318
00:14:15,680 --> 00:14:23,329
这种事情不会在这种简单的服务模型中发生

319
00:14:23,329 --> 00:14:25,940
当然了 这个问题可以被修复

320
00:14:25,940 --> 00:14:28,220
修复它需要 server 之间进行更多的通信

321
00:14:28,220 --> 00:14:33,529
某些地方也会变得更加复杂

322
00:14:33,529 --> 00:14:36,649
因为想获得强一致性 不可避免的需要更多开销

323
00:14:36,649 --> 00:14:37,820
因为想获得强一致性 不可避免的需要更多开销

324
00:14:37,820 --> 00:14:41,180
有大量的解决方案可以获得更好的一致性

325
00:14:41,180 --> 00:14:43,610
有大量的解决方案可以获得更好的一致性

326
00:14:43,610 --> 00:14:45,769
也有大量解决方案可以获得让人感觉还能接受的一致性

327
00:14:45,769 --> 00:14:48,350
也有大量解决方案可以获得让人感觉还能接受的一致性

328
00:14:48,350 --> 00:14:52,250
也有大量解决方案可以获得让人感觉还能接受的一致性

329
00:14:52,250 --> 00:14:54,890
就算出现一些小瑕疵也还能接受

330
00:14:54,890 --> 00:14:57,560
好 关于这个灾难性的模型 还有什么问题吗？

331
00:14:57,560 --> 00:15:03,910
好 关于这个灾难性的模型 还有什么问题吗？

332
00:15:04,649 --> 00:15:07,779
okay 这些就是关于 GFS 的讨论

333
00:15:07,779 --> 00:15:13,209
一些关于实现 GFS 的思考 GFS 怎么修复这些问题

334
00:15:13,209 --> 00:15:17,079
一些关于实现 GFS 的思考  GFS 怎么修复这些问题

335
00:15:17,079 --> 00:15:21,790
他们做的挺好 但是还不够完美

336
00:15:21,790 --> 00:15:24,179
GFS 是在 2003 年提出的 已经过去相当长一段时间

337
00:15:24,179 --> 00:15:27,730
那时候 web 发展到相当规模了 人们也在建立大型网站

338
00:15:27,730 --> 00:15:29,379
那时候 web 发展到相当规模了 人们也在建立大型网站

339
00:15:29,379 --> 00:15:31,569
那时候 web 发展到相当规模了 人们也在建立大型网站

340
00:15:31,569 --> 00:15:35,439
此外 分布式系统领域也有了几十年的研究

341
00:15:35,439 --> 00:15:37,540
此外 分布式系统领域也有了几十年的研究

342
00:15:37,540 --> 00:15:39,009
人们知道至少在学术领域

343
00:15:39,009 --> 00:15:40,509
如何构建各种类型的 高度并行化的且具备容错的系统

344
00:15:40,509 --> 00:15:43,119
如何构建各种类型的 高度并行化的且具备容错的系统

345
00:15:43,119 --> 00:15:44,739
但是学术上的点子 很少有能应用在工业领域

346
00:15:44,739 --> 00:15:49,589
但是学术上的点子 很少有能应用在工业领域

347
00:15:49,589 --> 00:15:52,239
但从这篇论文发表之后

348
00:15:52,239 --> 00:15:54,759
像 Google 这样的大型网站才开始真正建立严格意义上分布式系统

349
00:15:54,759 --> 00:15:57,399
像 Google 这样的大型网站才开始真正建立严格意义上分布式系统

350
00:15:57,399 --> 00:16:01,569
这件事让人热血沸腾 其中就包括我

351
00:16:01,569 --> 00:16:03,699
这件事让人热血沸腾 其中就包括我

352
00:16:03,699 --> 00:16:06,879
作为学术界的一份子

353
00:16:06,879 --> 00:16:10,119
我切实体会到了所有想法在工业界得以实现

354
00:16:10,119 --> 00:16:11,769
在 Google, 有海量的数据

355
00:16:11,769 --> 00:16:14,470
这些数据多到单个磁盘远远无法存储

356
00:16:14,470 --> 00:16:16,360
这些数据多到单个磁盘远远无法存储

357
00:16:16,360 --> 00:16:20,769
就比如说整个互联网抓取的网页副本

358
00:16:20,769 --> 00:16:22,119
或者在这篇文章后边一点有个巨大的 YouTube 视频

359
00:16:22,119 --> 00:16:25,480
他们就会有一份比如中间文件的东西 用来建立索引用于搜索

360
00:16:25,480 --> 00:16:27,669
他们就会有一份比如中间文件的东西 用来建立索引用于搜索

361
00:16:27,669 --> 00:16:28,299
他们就会有一份比如中间文件的东西 用来建立索引用于搜索

362
00:16:28,299 --> 00:16:30,790
他们的 web 服务器显然会有大量的日志文件

363
00:16:30,790 --> 00:16:32,679
他们的 web 服务器显然会有大量的日志文件

364
00:16:32,679 --> 00:16:34,029
以便用作未来分析

365
00:16:34,029 --> 00:16:36,910
他们有大量的数据集 并且使用大量的磁盘来存储他们

366
00:16:36,910 --> 00:16:39,339
他们有大量的数据集 并且使用大量的磁盘来存储他们

367
00:16:39,339 --> 00:16:41,139
借助 MapReduce 这样的工具可以快速的处理这些数据

368
00:16:41,139 --> 00:16:42,399
借助 MapReduce 这样的工具可以快速的处理这些数据

369
00:16:42,399 --> 00:16:44,709
因此他们需要能高度并行化的访问海量数据

370
00:16:44,709 --> 00:16:47,529
因此他们需要能高度并行化的访问海量数据

371
00:16:47,529 --> 00:16:51,819
okay 所以他们的目标是

372
00:16:51,819 --> 00:16:53,669
这个存储系统需要 大容量 速度快

373
00:16:53,669 --> 00:17:00,009
他们还需要一个文件系统 从某种意义上来说

374
00:17:00,009 --> 00:17:02,470
这个文件系统必须是 Global 的（覆盖在整个数据中心上）

375
00:17:02,470 --> 00:17:04,148
从某种意义上来说 各种不同的应用程序都能从中读取数据

376
00:17:04,148 --> 00:17:06,490
有一种建立大型存储系统的方法

377
00:17:06,490 --> 00:17:07,990
假设你有一些特殊的应用程序或是采集程序

378
00:17:07,990 --> 00:17:09,398
假设你有一些特殊的应用程序或是采集程序

379
00:17:09,398 --> 00:17:11,260
你可以编写一个专用的存储系统 专门适应这些特别的应用程序

380
00:17:11,260 --> 00:17:13,119
你可以编写一个专用的存储系统 专门适应这些特别的应用程序

381
00:17:13,119 --> 00:17:14,829
如果你隔壁办公室的人也需要用到大型存储

382
00:17:14,829 --> 00:17:17,079
他们就得自己去编写自己的存储系统 而无法复用你的程序

383
00:17:17,079 --> 00:17:17,680
他们就得自己去编写自己的存储系统 而无法复用你的程序

384
00:17:17,680 --> 00:17:21,099
你要是有一个通用的 Global 且可利用的存储系统

385
00:17:21,099 --> 00:17:25,300
你要是有一个通用的 Global 且可重用的存储系统

386
00:17:25,300 --> 00:17:28,030
这意味着 如果我存储大量从 web 中抓取的数据

387
00:17:28,030 --> 00:17:29,710
这意味着 如果我存储大量从 web 中抓取的数据

388
00:17:29,710 --> 00:17:31,600
并且你也想查看我抓取的 web 页

389
00:17:31,600 --> 00:17:35,290
并且你也想看我抓取的 web 页

390
00:17:35,290 --> 00:17:36,580
因为我们都在相同的沙盒中折腾

391
00:17:36,580 --> 00:17:38,740
且使用了相同的存储系统

392
00:17:38,740 --> 00:17:40,750
只要访问控制允许的话 你就可以读取我存的文件

393
00:17:40,750 --> 00:17:43,480
只要访问控制允许的话 你就可以读取我存的文件

394
00:17:43,480 --> 00:17:45,190
所以就有了构建文件系统的想法

395
00:17:45,190 --> 00:17:47,110
任何在 Google 的人 都可以给任何文件命名或是读取它

396
00:17:47,110 --> 00:17:50,080
任何在 Google 的人 都可以给任何文件命名或是读取它

397
00:17:50,080 --> 00:17:57,010
目的就是为了共享

398
00:17:57,010 --> 00:17:58,540
为了能得到大容量 速度快的特性

399
00:17:58,540 --> 00:18:00,300
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
他们需要把数据进行分割

400
00:18:00,300 --> 00:18:04,990
每个文件都将自动地被 GFS 分割到许多 server 上

401
00:18:04,990 --> 00:18:07,900
每个文件都将自动地被 GFS 分割到许多 server 上

402
00:18:07,900 --> 00:18:08,950
只要有许多客户端大量读取文件 这样读写操作将会自动变快（注：并行化读写）

403
00:18:08,950 --> 00:18:10,780
只要有许多客户端大量读取文件 这样读写操作将会自动变快（注：并行化读写）

404
00:18:10,780 --> 00:18:12,730
只要有许多客户端大量读取文件 这样读写操作将会自动变快（注：并行化读写）

405
00:18:12,730 --> 00:18:14,770
只要有许多客户端大量读取文件 这样读写操作将会自动变快（注：并行化读写）

406
00:18:14,770 --> 00:18:17,860
你就能获得更高的呑吐量

407
00:18:17,860 --> 00:18:20,230
而且能够让单个文件比单个磁盘还要大

408
00:18:20,230 --> 00:18:21,670
而且能够让单个文件比单个磁盘还要大

409
00:18:21,670 --> 00:18:24,730
因为我们构建的东西在数百台服务器之上

410
00:18:24,730 --> 00:18:26,170
因为我们构建的东西在数百台服务器之上

411
00:18:26,170 --> 00:18:36,430
所以我们希望这些服务器能够自动的从错误中恢复

412
00:18:36,430 --> 00:18:37,480
如果数百台机器中 每时每刻都有机器发生故障

413
00:18:37,480 --> 00:18:38,860
如果数百台机器中 每时每刻都有机器发生故障

414
00:18:38,860 --> 00:18:40,540
这时候你必须得有个人跑到机器去 对着 server 干一些事情

415
00:18:40,540 --> 00:18:42,490
这时候你必须得有个人跑到机器去 对着 server 干一些事情

416
00:18:42,490 --> 00:18:44,830
比如重启它 或者是迁移数据 或是别的什么也好

417
00:18:44,830 --> 00:18:46,870
比如重启它 或者是迁移数据 或是别的什么也好

418
00:18:46,870 --> 00:18:50,130
你肯定不愿意用这样的服务 是吧 它都不能自我修复

419
00:18:50,130 --> 00:18:54,370
还有一些并非是目标 比如 GFS 被设计成只在单数据中心上运行

420
00:18:54,370 --> 00:18:55,930
还有一些并非是目标 比如 GFS 被设计成只在单数据中心上运行

421
00:18:55,930 --> 00:18:57,340
我们并不会讨论如何把副本放到世界各地

422
00:18:57,340 --> 00:18:59,950
我们并不会讨论如何把副本放到世界各地

423
00:18:59,950 --> 00:19:02,410
单个 GFS 只安装在一个大机房里 只会运行在一个数据中心上

424
00:19:02,410 --> 00:19:05,200
单个 GFS 只安装在一个大机房里 只会运行在一个数据中心上

425
00:19:05,200 --> 00:19:12,190
让这样的系统能够在副本彼此相距甚远的情况下工作

426
00:19:12,190 --> 00:19:14,860
让这样的系统能够在副本彼此相距甚远的情况下工作

427
00:19:14,860 --> 00:19:17,550
是一个有价值的目标 但是这还是挺难的

428
00:19:17,550 --> 00:19:22,720
这个单数据中心并不是面向客户的服务

429
00:19:22,720 --> 00:19:25,540
这个单数据中心并不是面向客户的服务

430
00:19:25,540 --> 00:19:27,920
GFS 是 Google 工程师开发的内部使用的工具

431
00:19:27,920 --> 00:19:30,210
GFS 是 Google 工程师开发的内部使用的工具

432
00:19:30,210 --> 00:19:32,400
所以他们并不会直接出售这套程序

433
00:19:32,400 --> 00:19:33,810
但他们可能会出售他们使用的服务

434
00:19:33,810 --> 00:19:37,170
GFS 是内部使用的 他们不会直接出售的

435
00:19:37,170 --> 00:19:38,520
GFS 是内部使用的 他们不会直接出售的

436
00:19:38,520 --> 00:19:45,660
GFS 是内部使用的 他们不会直接出售的

437
00:19:45,660 --> 00:19:48,630
而且它是为大型顺序文件读写以多种方式定制的

438
00:19:48,630 --> 00:19:51,180
而且它是为大型顺序文件读写以多种方式定制的

439
00:19:51,180 --> 00:19:54,180
有一个完全不同的领域 比如为小块数据专门优化的存储系统

440
00:19:54,180 --> 00:19:56,490
有一个完全不同的领域 比如为小块数据专门优化的存储系统

441
00:19:56,490 --> 00:19:58,590
有一个完全不同的领域 比如为小块数据专门优化的存储系统

442
00:19:58,590 --> 00:20:00,090
比如银行余额需要有一个数据库

443
00:20:00,090 --> 00:20:02,100
它可以读、写和更新 100 字节存有人们银行余额的记录

444
00:20:02,100 --> 00:20:04,380
它可以读、写和更新 100 字节存有人们银行余额的记录

445
00:20:04,380 --> 00:20:07,230
它可以读、写和更新 100 字节存有人们银行余额的记录

446
00:20:07,230 --> 00:20:10,230
GFS 可不是这样的系统 它就是为了处理“大文件”

447
00:20:10,230 --> 00:20:12,600
比如 GB TB 大小的文件

448
00:20:12,600 --> 00:20:22,640
它只处理大文件的顺序访问 而不是随机访问

449
00:20:22,640 --> 00:20:24,690
从某种程度上讲 它有点像批处理的风格

450
00:20:24,690 --> 00:20:26,340
它没有花费过多的精力让延迟变的更低

451
00:20:26,340 --> 00:20:27,840
它没有花费过多的精力让延迟变的更低

452
00:20:27,840 --> 00:20:30,000
而是把重点放在巨大的呑吐量上

453
00:20:30,000 --> 00:20:32,880
而是把重点放在巨大的呑吐量上

454
00:20:32,880 --> 00:20:36,780
比如数兆字节的操作

455
00:20:36,780 --> 00:20:39,560
这篇论文 2003 年发表在 SOSP 上

456
00:20:39,560 --> 00:20:46,860
一个顶级系统学术会议

457
00:20:46,860 --> 00:20:49,080
通常在这样的会议上 论文标准是需要有很多创新研究

458
00:20:49,080 --> 00:20:51,260
通常在这样的会议上 论文标准是需要有很多创新研究

459
00:20:51,260 --> 00:20:54,060
这些创新研究在课堂上一定不会有的

460
00:20:54,060 --> 00:20:55,920
这篇论文中的点子 在那个时候并不特别新颖

461
00:20:55,920 --> 00:20:57,750
这篇论文中的点子 在那个时候并不特别新颖

462
00:20:57,750 --> 00:21:00,990
像分布式、分片(sharding)、容错这些

463
00:21:00,990 --> 00:21:02,510
像分布式、分片(sharding)、容错这些

464
00:21:02,510 --> 00:21:05,340
你能很好的理解并实现它们

465
00:21:05,340 --> 00:21:07,620
但是这篇论文描述的系统 是建立在成百上千台机器上的

466
00:21:07,620 --> 00:21:09,480
但是这篇论文描述的系统 是建立在成百上千台机器上的

467
00:21:09,480 --> 00:21:11,970
但是这篇论文描述的系统 是建立在成百上千台机器上的

468
00:21:11,970 --> 00:21:13,680
但是这篇论文描述的系统 是建立在成百上千台机器上的

469
00:21:13,680 --> 00:21:16,400
数量远远超过了以往学术界建立的系统所使用的机器

470
00:21:16,400 --> 00:21:18,960
事实上 它被用于工业界 并折射现实世界的经验

471
00:21:18,960 --> 00:21:21,450
事实上 它被用于工业界 并折射现实世界的经验

472
00:21:21,450 --> 00:21:23,370
比如 对于已经部署的系统  什么不该做 什么该做

473
00:21:23,370 --> 00:21:25,490
比如 对于已经部署的系统  什么不该做 什么该做

474
00:21:25,490 --> 00:21:28,950
什么样的开销是最有效率的 这些都是非常有价值的

475
00:21:28,950 --> 00:21:34,080
什么样的开销是最有效率的 这些都是非常有价值的

476
00:21:34,080 --> 00:21:39,090
这篇论文提出了一个相当异端的观点

477
00:21:39,090 --> 00:21:40,800
认为存储系统具有弱一致性是可以接受的

478
00:21:40,800 --> 00:21:41,270
认为存储系统具有弱一致性是可以接受的

479
00:21:41,270 --> 00:21:45,440
在那时候 学术界的观念认为存储系统就应该具有良好的行为

480
00:21:45,440 --> 00:21:46,550
在那时候 学术界的观念认为存储系统就应该具有良好的行为

481
00:21:46,550 --> 00:21:47,780
在那时候 学术界的观念认为存储系统就应该具有良好的行为

482
00:21:47,780 --> 00:21:48,830
像这里的这个糟糕的复制系统 它返回了错误的数据

483
00:21:48,830 --> 00:21:50,780
像这里的这个糟糕的复制系统 它返回了错误的数据

484
00:21:50,780 --> 00:21:53,750
像这里的这个糟糕的复制系统 它返回了错误的数据

485
00:21:53,750 --> 00:21:55,400
它为什么要这样做 而不是构建一个能返回正确数据的系统

486
00:21:55,400 --> 00:21:57,020
它为什么要这样做 而不是构建一个能返回正确数据的系统

487
00:21:57,020 --> 00:21:59,240
它为什么要这样做 而不是构建一个能返回正确数据的系统

488
00:21:59,240 --> 00:22:02,570
在这篇论文里 它确实没有保证返回的正确的数据

489
00:22:02,570 --> 00:22:05,960
它的目的是获取更好的性能

490
00:22:05,960 --> 00:22:07,130
它的目的是获取更好的性能

491
00:22:07,130 --> 00:22:09,440
它的目的是获取更好的性能

492
00:22:09,440 --> 00:22:11,900
最后一件事 这篇论文里 使用的是单个 master

493
00:22:11,900 --> 00:22:13,580
最后一件事 这篇论文里 使用的是单个 master

494
00:22:13,580 --> 00:22:16,370
在学术论文里 你可能会有自动容错的副本 用以恢复 master

495
00:22:16,370 --> 00:22:18,020
在学术论文里 你可能会有自动容错的副本 用以恢复 master

496
00:22:18,020 --> 00:22:20,900
在学术论文里 你可能会有自动容错的副本 用以恢复 master

497
00:22:20,900 --> 00:22:24,110
或许有许多的 master 进行分工

498
00:22:24,110 --> 00:22:25,550
但是在这篇论文里

499
00:22:25,550 --> 00:22:26,960
它得以侥幸的只使用一个 master 并且能工作的很好

500
00:22:26,960 --> 00:22:39,260
它得以侥幸的只使用一个 master 并且能工作的很好

501
00:22:39,260 --> 00:22:40,610
(提问) 很讽刺的是 谁关心 web 页面上投票的数量是否正确呢

502
00:22:40,610 --> 00:22:43,010
(提问) 很讽刺的是 谁关心 web 页面上投票的数量是否正确呢

503
00:22:43,010 --> 00:22:44,920
又或是别的什么错误呢

504
00:22:44,920 --> 00:22:47,510
如果你在搜索引擎上执行搜索

505
00:22:47,510 --> 00:22:50,480
可能会发生 20000 条结果里有一条搜索结果丢失这样的事情

506
00:22:50,480 --> 00:22:51,890
可能会发生 20000 条结果里有一条搜索结果丢失这样的事情

507
00:22:51,890 --> 00:22:54,860
这些结果的排序可能也不正确

508
00:22:54,860 --> 00:22:58,130
所以在这类系统中 它对错误数据容错能力不需要像银行系统那样高

509
00:22:58,130 --> 00:22:59,510
所以在这类系统中 它对错误数据容错能力不需要像银行系统那样高

510
00:22:59,510 --> 00:23:02,210
所以在这类系统中 它对错误数据容错能力不需要像银行系统那样高

511
00:23:02,210 --> 00:23:04,070
这并不是说所有数据所有的 web 网站都可以是错误的

512
00:23:04,070 --> 00:23:05,630
这并不是说所有数据所有的 web 网站都可以是错误的

513
00:23:05,630 --> 00:23:07,880
比如你收了别人的钱 给人家打广告

514
00:23:07,880 --> 00:23:09,890
你最好还是得保证数字的正确性 这不一定就是这样哈

515
00:23:09,890 --> 00:23:15,830
另外 GFS 中有一些提供数据的方法 可以在应用程序中进行补偿

516
00:23:15,830 --> 00:23:18,370
另外 GFS 中有一些提供数据的方法 可以在应用程序中进行补偿

517
00:23:18,370 --> 00:23:21,770
另外 GFS 中有一些提供数据的方法 可以在应用程序中进行补偿

518
00:23:21,770 --> 00:23:23,540
比如论文中介绍的 应用程序应当把数据及其校验和一起使用

519
00:23:23,540 --> 00:23:25,490
比如论文中介绍的 应用程序应当把数据及其校验和一起使用

520
00:23:25,490 --> 00:23:28,040
比如论文中介绍的 应用程序应当把数据及其校验和一起使用

521
00:23:28,040 --> 00:23:30,260
并且要清晰的标记记录的边界

522
00:23:30,260 --> 00:23:32,380
所以应用程序就能从 GFS 中恢复数据

523
00:23:32,380 --> 00:23:40,970
提供服务可能并不需要强烈保证数据的正确性

525
00:23:40,970 --> 00:23:44,730
好，所以一般的结构是……就在这篇论文的图 1 里

526
00:23:44,730 --> 00:23:48,840
好，所以一般的结构是……就在这篇论文的图 1 里

527
00:23:48,840 --> 00:23:53,850
我们有很多客户端 上百个吧 还有一个 master

528
00:23:53,850 --> 00:23:57,920
我们有很多客户端 上百个吧 还有一个 master

529
00:23:59,450 --> 00:24:02,040
尽管存在 master 的多个副本

530
00:24:02,040 --> 00:24:07,140
在这里 master 保存有从文件名到数据存储位置的映射

531
00:24:07,140 --> 00:24:09,510
在这里 master 保存有从文件名到数据存储位置的映射

532
00:24:09,510 --> 00:24:10,980
实际上是有 2 张表

533
00:24:10,980 --> 00:24:14,100
然后 还有许多的 chunk server（块服务器）

534
00:24:14,100 --> 00:24:18,390
然后 还有许多的 chunk server（块服务器）

535
00:24:18,390 --> 00:24:21,090
可能会有上百个 每一个可能都会有一两块磁盘

536
00:24:21,090 --> 00:24:23,640
这里的 master 用来管理命名和追踪 chunk 的位置

537
00:24:23,640 --> 00:24:25,320
这里的 master 用来管理命名和追踪 chunk 的位置

538
00:24:25,320 --> 00:24:27,480
chunk server 会存储实际的数据

539
00:24:27,480 --> 00:24:29,400
chunk server 会存储实际的数据

540
00:24:29,400 --> 00:24:31,020
这看起来是设计中最好的地方了

541
00:24:31,020 --> 00:24:32,760
这两个地方完全彼此隔离起来

542
00:24:32,760 --> 00:24:35,880
并能使用独立的特性进行独立设计

543
00:24:35,880 --> 00:24:41,700
并能使用独立的特性进行独立设计

544
00:24:41,700 --> 00:24:43,170
master 知道所有的文件 并且能追踪这些 chunk、chunk 标识符

545
00:24:43,170 --> 00:24:44,970
master 知道所有的文件 并且能追踪这些 chunk、chunk 标识符

546
00:24:44,970 --> 00:24:48,260
master 知道所有的文件 并且能追踪这些 chunk、chunk 标识符

547
00:24:48,260 --> 00:24:50,880
chunk 中包含文件的连续片断 每个 chunk 大小是 64MB

548
00:24:50,880 --> 00:24:53,400
chunk 中包含文件的连续片断 每个 chunk 大小是 64MB

549
00:24:53,400 --> 00:24:57,090
如果我有 1GB 的文件

550
00:24:57,090 --> 00:24:58,590
master 就会知道这个文件的第 1 个 chunk 保存在这里

551
00:24:58,590 --> 00:25:00,059
第 2 个 chunk 保存在这里

552
00:25:00,059 --> 00:25:01,559
第 3 个 chunk 保存在这里

553
00:25:01,559 --> 00:25:03,780
如果我想读取这个文件中的任意一部分

554
00:25:03,780 --> 00:25:05,490
就需要询问 master 这个 chunk 在哪个 server 上

555
00:25:05,490 --> 00:25:07,260
就需要询问 master 这个 chunk 在哪个 server 上

556
00:25:07,260 --> 00:25:09,000
然后就去找那个 server 读取 chunk 粗略的说就是这样

557
00:25:09,000 --> 00:25:17,130
然后就去找那个 server 读取 chunk 粗略的说就是这样

558
00:25:17,130 --> 00:25:21,150
说的细一点 我们需要证明我们所讨论的

559
00:25:21,150 --> 00:25:23,190
关于系统如何保持一致性 以及如何处理错误的问题

560
00:25:23,190 --> 00:25:24,690
关于系统如何保持一致性 以及如何处理错误的问题

561
00:25:24,690 --> 00:25:27,360
关于系统如何保持一致性 以及如何处理错误的问题

562
00:25:27,360 --> 00:25:29,100
我们需要了解 master 实际存储的是什么这些细节

563
00:25:29,100 --> 00:25:36,190
我们需要了解 master 实际存储的是什么这些细节

565
00:25:36,190 --> 00:25:38,900
master data 我们所关心的是它实际存储的 2 个主要 table

566
00:25:38,900 --> 00:25:41,360
其中一个是 filename 到 chunk ID(或chunk handle) 数组的映射

567
00:25:41,360 --> 00:25:52,460
其中一个是 filename 到 chunk ID(或chunk handle) 数组的映射

568
00:25:52,460 --> 00:26:00,830
这张表是为了告诉你在哪里可以找到数据 或者说这些 chunk 是什么

569
00:26:00,830 --> 00:26:03,050
这张表是为了告诉你在哪里可以找到数据 或者说这些 chunk 是什么

570
00:26:03,050 --> 00:26:05,030
这张表是为了告诉你在哪里可以找到数据 或者说这些 chunk 是什么

571
00:26:05,030 --> 00:26:06,620
拿着这样一个 chunk id 你还没办法做其它事

572
00:26:06,620 --> 00:26:08,840
但是 master 碰巧它还有第 2 张表

573
00:26:08,840 --> 00:26:11,440
但是 master 碰巧它还有第 2 张表

574
00:26:11,440 --> 00:26:17,570
它记录了每个 chunk handle 到一些数据之间的映射

575
00:26:17,570 --> 00:26:21,110
它记录了每个 chunk handle 到一些数据之间的映射

576
00:26:21,110 --> 00:26:23,330
其中一项是 chunk server 的列表

577
00:26:23,330 --> 00:26:25,900
这些 chunk server 保存数据的副本

578
00:26:25,900 --> 00:26:28,040
每个 chunk 被存储在多个 chunk server 上

579
00:26:28,040 --> 00:26:39,650
所以这里应该写上 chunk server 列表

580
00:26:39,650 --> 00:26:42,400
每一个 chunk 都有一个当前版本号

581
00:26:42,400 --> 00:26:46,610
所以 master 还得记住每个 chunk 的版本号

582
00:26:46,610 --> 00:26:50,150
对于 chunk 的所有写操作

583
00:26:50,150 --> 00:26:51,950
都必须在 chunk primary (主 chunk) 上顺序化

584
00:26:51,950 --> 00:26:54,910
这个 primary 是所有副本之一

585
00:26:54,910 --> 00:26:58,880
所以 master 记住了哪个 chunk server 是 primary

586
00:26:58,880 --> 00:27:00,980
primary 只能在规定的某个租约时间里才能担任 primary

587
00:27:00,980 --> 00:27:02,570
primary 只能在规定的某个租约时间里才能担任 primary

588
00:27:02,570 --> 00:27:05,450
primary 只能在规定的某个租约时间里才能担任 primary

589
00:27:05,450 --> 00:27:13,370
所以 master 还应该记住这个租约的过期时间

590
00:27:13,370 --> 00:27:17,240
这些东西全部存储在 RAM(内存) 中

591
00:27:17,240 --> 00:27:19,670
如果 master 宕机 这些东西就全部丢失了

592
00:27:19,670 --> 00:27:24,530
为了能重启 master 并且不丢失文件系统相关的信息

593
00:27:24,530 --> 00:27:26,570
为了能重启 master 并且不丢失文件系统相关的信息

594
00:27:26,570 --> 00:27:29,150
为了能重启 master 并且不丢失文件系统相关的信息

595
00:27:29,150 --> 00:27:30,710
master 会把这些数据存储到磁盘上 和在内存里一样

596
00:27:30,710 --> 00:27:35,180
master 会把这些数据存储到磁盘上 和在内存里一样

597
00:27:35,180 --> 00:27:38,270
读数据的时候 只从内存里读

598
00:27:38,270 --> 00:27:40,490
读数据的时候 只从内存里读

599
00:27:40,490 --> 00:27:42,140
但是写数据 至少这部分数据 必须也要写入磁盘

600
00:27:42,140 --> 00:27:45,500
所以这种管理方式 要求所有的 master 在磁盘上都有一个 log

601
00:27:45,500 --> 00:27:47,510
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
所以这种管理方式 要求所有的 master 在磁盘上都有一个 log

602
00:27:47,510 --> 00:27:51,290
所以这种管理方式 要求所有的 master 在磁盘上都有一个 log

603
00:27:51,290 --> 00:27:53,750
任何时候有数据变更 就会在磁盘上的日志追加一个条目 并定期创建 checkpoint

604
00:27:53,750 --> 00:27:59,380
任何时候有数据变更 就会在磁盘上的日志追加一个条目 并定期创建 checkpoint

605
00:28:04,480 --> 00:28:07,220
有些东西它必须要保存到磁盘上 有些不用 我猜测是这样

606
00:28:07,220 --> 00:28:10,600
有些东西它必须要保存到磁盘上 有些不用 我猜测是这样

607
00:28:10,600 --> 00:28:12,980
有些东西它必须要保存到磁盘上 有些不用 我猜测是这样

608
00:28:12,980 --> 00:28:16,190
当然了 chunk handle 数组那肯定要保存到磁盘上

609
00:28:16,190 --> 00:28:18,050
所以这里我里写一个 NV(non-valatile, 非易失)

610
00:28:18,050 --> 00:28:20,510
所以这里我里写一个 NV(non-valatile, 非易失)

611
00:28:20,510 --> 00:28:22,850
表示它会被反射到磁盘上

612
00:28:22,850 --> 00:28:25,610
chunk server 列表不会保存到磁盘上

613
00:28:25,610 --> 00:28:28,370
因为 master 重启后会和所有 chunk server 通信

614
00:28:28,370 --> 00:28:29,720
并询问它们保存了哪些 chunk

615
00:28:29,720 --> 00:28:32,710
并询问它们保存了哪些 chunk

616
00:28:32,710 --> 00:28:36,290
所以我觉得它不用写入磁盘

617
00:28:36,290 --> 00:28:38,450
版本号要不要写入磁盘 这得要求了解系统如何工作

618
00:28:38,450 --> 00:28:42,950
版本号要不要写入磁盘 这得要求了解系统如何工作

619
00:28:42,950 --> 00:28:51,830
不过我偏向于它会写入磁盘（nv）

620
00:28:51,830 --> 00:28:55,790
不过我偏向于它会写入磁盘（nv）

621
00:28:55,790 --> 00:28:57,500
稍后我们讨论系统如何工作的时候再来争论这个问题

622
00:28:57,500 --> 00:29:04,790
primary 标识不用写入到磁盘 所以应该是 volatile

623
00:29:04,790 --> 00:29:06,560
primary 标识不用写入到磁盘 所以应该是 volatile

624
00:29:06,560 --> 00:29:10,640
因为 master 在重启后就会忘记谁是 primary

625
00:29:10,640 --> 00:29:13,010
因为 master 在重启后就会忘记谁是 primary

626
00:29:13,010 --> 00:29:15,680
因为 master 在重启后就会忘记谁是 primary

627
00:29:15,680 --> 00:29:17,330
对于一个 chunk 来说 只要简单的等待 60 秒 等待租约过期

628
00:29:17,330 --> 00:29:19,910
对于一个 chunk 来说 只要简单的等待 60 秒 等待租约过期

629
00:29:19,910 --> 00:29:21,920
然后它便知道对于这个 chunk 来说确实没有 primary 在工作

630
00:29:21,920 --> 00:29:23,540
然后它便知道对于这个 chunk 来说确实没有 primary 在工作

631
00:29:23,540 --> 00:29:24,920
这时候它可以安全的指定一个不同的 primary

632
00:29:24,920 --> 00:29:27,020
这时候它可以安全的指定一个不同的 primary

633
00:29:27,020 --> 00:29:29,660
类似的 租约过期时间也是 volatile

634
00:29:29,660 --> 00:29:32,840
任何时候文件达到 64MB 边界时需要创建一个新 chunk

635
00:29:32,840 --> 00:29:35,030
又或是新的 primary 被指派导致版本号发生改变时

636
00:29:35,030 --> 00:29:40,100
又或是新的 primary 被指派导致版本号发生改变时

637
00:29:40,100 --> 00:29:42,710
master 都必须首先追加一点记录到日志中

638
00:29:42,710 --> 00:29:45,740
master 都必须首先追加一点记录到日志中

639
00:29:45,740 --> 00:29:48,440
master 都必须首先追加一点记录到日志中

640
00:29:48,440 --> 00:29:50,900
内容大概是 我刚添加了个 chunk 到这个文件里

641
00:29:50,900 --> 00:29:53,510
内容大概是 我刚添加了个 chunk 到这个文件里

642
00:29:53,510 --> 00:29:56,420
或者是 我刚修改一下版本号

643
00:29:56,420 --> 00:29:57,530
所以每次我修改这些东西都需要写入磁盘

644
00:29:57,530 --> 00:29:59,360
所以每次我修改这些东西都需要写入磁盘

645
00:29:59,360 --> 00:30:00,830
这篇论文并没的讨论这么多细节

646
00:30:00,830 --> 00:30:02,870
但是你得知道 master 修改这些东西总会存在一些速率限制

647
00:30:02,870 --> 00:30:05,090
但是你得知道 master 修改这些东西总会存在一些速率限制

648
00:30:05,090 --> 00:30:07,039
因为你每秒能写磁盘的次数就那么多

649
00:30:07,039 --> 00:30:09,340
因为你每秒能写磁盘的次数就那么多

650
00:30:09,340 --> 00:30:12,950
使用日志而不是数据库的原因是

651
00:30:12,950 --> 00:30:16,279
你应该了解过 b-tree 或是 hash 表

652
00:30:16,279 --> 00:30:20,179
你应该了解过 b-tree 或是 hash 表

653
00:30:20,179 --> 00:30:23,980
使用日志是因为追加日志非常高效

654
00:30:24,010 --> 00:30:26,600
你有一堆最近的日志记录需要被添加

655
00:30:26,600 --> 00:30:28,309
你有一堆最近的日志记录需要被添加

656
00:30:28,309 --> 00:30:29,539
在一次磁盘旋转后 一次把他们写入磁盘上某个位置

657
00:30:29,539 --> 00:30:32,149
在一次磁盘旋转后 一次把他们写入磁盘上某个位置

658
00:30:32,149 --> 00:30:33,649
在一次磁盘旋转后 一次把他们写入磁盘上某个位置

659
00:30:33,649 --> 00:30:36,080
这个位置包含了日志文件的结尾(EOF)

660
00:30:36,080 --> 00:30:38,899
然而 如果使用 b-tree 来表达这些数据的话

661
00:30:38,899 --> 00:30:42,080
然而 如果使用 b-tree 来表达这些数据的话

662
00:30:42,080 --> 00:30:43,370
那就还得去磁盘上寻找一个随机位置写入一点数据

663
00:30:43,370 --> 00:30:45,169
那就还得去磁盘上寻找一个随机位置写入一点数据

664
00:30:45,169 --> 00:30:46,519
所以日志会让这种写操作稍稍快一些

665
00:30:46,519 --> 00:30:51,620
为了把这些操作反射到磁盘上

666
00:30:51,620 --> 00:30:56,570
然而如果 master 宕机并且必须重建它的状态

667
00:30:56,570 --> 00:30:58,789
然而如果 master 宕机并且必须重建它的状态

668
00:30:58,789 --> 00:31:00,409
你可能并不想从日志文件从头开始读取重建

669
00:31:00,409 --> 00:31:02,570
你可能并不想从日志文件从头开始读取重建

670
00:31:02,570 --> 00:31:04,159
因为 server 第一次安装启动的时间开始距今可能有数年

671
00:31:04,159 --> 00:31:06,559
因为 server 第一次安装启动的时间开始距今可能有数年

672
00:31:06,559 --> 00:31:08,870
所以 master 有时候会额外的创建一份它完整状态的快照到磁盘

673
00:31:08,870 --> 00:31:10,940
所以 master 有时候会额外的创建一份它完整状态的快照到磁盘

674
00:31:10,940 --> 00:31:15,110
这可能会花费几十秒 比如一分钟的时间

675
00:31:15,110 --> 00:31:17,779
这可能会花费几十秒 比如一分钟的时间

676
00:31:17,779 --> 00:31:20,210
当它重启的时候 它只要回到最近的 checkpoint 的位置

677
00:31:20,210 --> 00:31:21,860
当它重启的时候 它只要回到最近的 checkpoint 的位置

678
00:31:21,860 --> 00:31:24,620
然后重演从 checkpoint 之后的日志就行了

679
00:31:24,620 --> 00:31:26,480
然后重演从 checkpoint 之后的日志就行了

680
00:31:26,480 --> 00:31:30,019
然后重演从 checkpoint 之后的日志就行了

681
00:31:30,019 --> 00:31:39,340
关于 master 数据大家还有啥疑问没 okay

682
00:31:40,360 --> 00:31:44,029
所以基于以上 我打算列出这些在读和写中的步骤

683
00:31:44,029 --> 00:31:46,340
所以基于以上 我打算列出这些在读和写中的步骤

684
00:31:46,340 --> 00:31:46,879
所以基于以上 我打算列出这些在读和写中的步骤

685
00:31:46,879 --> 00:31:49,129
所有的步骤我会写在这里 然后和你们一起讨论

686
00:31:49,129 --> 00:31:50,960
所有的步骤我会写在这里 然后和你们一起讨论

687
00:31:50,960 --> 00:31:53,840
对于每一个失败 我可以思考在失败之后为什么系统要这样做

688
00:31:53,840 --> 00:31:56,389
对于每一个失败 我可以思考在失败之后为什么系统要这样做

689
00:31:56,389 --> 00:31:58,639
但是在做这件事前 我们需要理解这些数据和数据中的操作

690
00:31:58,639 --> 00:32:00,740
但是在做这件事前 我们需要理解这些数据和数据中的操作

691
00:32:00,740 --> 00:32:03,470
但是在做这件事前 我们需要理解这些数据和数据中的操作

692
00:32:03,470 --> 00:32:11,210
okay 这里是 read 第一步是客户端

693
00:32:11,210 --> 00:32:12,980
read 意思是应用程序知道有一个文件名

694
00:32:12,980 --> 00:32:14,749
read 意思是应用程序知道有一个文件名

695
00:32:14,749 --> 00:32:17,450
read 意思是应用程序知道有一个文件名

696
00:32:17,450 --> 00:32:19,279
以及一个应用程序想从某个位置读取的偏移量

697
00:32:19,279 --> 00:32:21,799
所以应用程序会把文件名和偏移发送给 master

698
00:32:21,799 --> 00:32:23,869
master 从文件表里查询文件名

699
00:32:23,869 --> 00:32:25,759
你知道每个 chunk 大小是 64MB

700
00:32:25,759 --> 00:32:28,309
你知道每个 chunk 大小是 64MB

701
00:32:28,309 --> 00:32:30,889
它可以利用偏移量除以 64MB 来查找是哪个 chunk

702
00:32:30,889 --> 00:32:33,649
然后再从 chunk 表里找到 chunk server 列表

703
00:32:33,649 --> 00:32:39,409
然后再从 chunk 表里找到 chunk server 列表

704
00:32:39,409 --> 00:32:41,869
然后再从 chunk 表里找到 chunk server 列表

705
00:32:41,869 --> 00:32:44,509
再把包含这些数据的副本的 chunk server 列表返回给客户端

706
00:32:44,509 --> 00:32:52,249
所以第一步是把文件名和偏移量发给 master

707
00:32:52,249 --> 00:32:56,809
所以第一步是把文件名和偏移量发给 master

708
00:32:56,809 --> 00:33:05,720
然后 master 发送 chunk handle(记作 H) 和 server 列表（给客户端)

709
00:33:05,720 --> 00:33:11,450
然后 master 发送 chunk handle(记作 H) 和 server 列表（给客户端)

710
00:33:11,450 --> 00:33:13,070
现在我有一些选择 我可以查询这个 server 列表中的任意一个

711
00:33:13,070 --> 00:33:15,590
现在我有一些选择 我可以查询这个 server 列表中的任意一个

712
00:33:15,590 --> 00:33:17,990
论文里说客户端会尝试猜测

713
00:33:17,990 --> 00:33:19,429
网络上（也可能是一个机架上）哪个 server 距离它最近

714
00:33:19,429 --> 00:33:23,360
网络上（也可能是一个机架上）哪个 server 距离它最近

715
00:33:23,360 --> 00:33:27,279
然后发送读请求到那个副本上

716
00:33:28,480 --> 00:33:32,649
客户端实际上会缓存这些结果

717
00:33:35,550 --> 00:33:37,930
如果它尝试再次读取这个 chunk 的话

718
00:33:37,930 --> 00:33:39,820
如果它尝试再次读取这个 chunk 的话

719
00:33:39,820 --> 00:33:41,560
客户端可能从返回的 chunk 中读取 1MB 或是 64KB 的片段

720
00:33:41,560 --> 00:33:45,550
客户端可能从返回的 chunk 中读取 1MB 或是 64KB 的片段

721
00:33:45,550 --> 00:33:47,620
客户端可能最终会读取同一个 chunk 中不同的位置连续的区域多次

722
00:33:47,620 --> 00:33:49,410
客户端可能最终会读取同一个 chunk 中不同的位置连续的区域多次

723
00:33:49,410 --> 00:33:51,730
客户端可能最终会读取同一个 chunk 中不同的位置连续的区域多次

724
00:33:51,730 --> 00:33:56,050
所以需要缓存给定的 chunk 所对应的是哪个 server

725
00:33:56,050 --> 00:33:57,310
对于相同的信息 它就不用一遍又一遍的去访问 master

726
00:33:57,310 --> 00:33:59,020
对于相同的信息 它就不用一遍又一遍的去访问 master

727
00:33:59,020 --> 00:34:02,550
对于相同的信息 它就不用一遍又一遍的去访问 master

728
00:34:03,150 --> 00:34:07,330
客户端和 chunk server 之一进行通信

729
00:34:07,330 --> 00:34:12,880
发送一个 chunk handle 以及一个偏移

730
00:34:12,880 --> 00:34:16,540
chunk server 存储这些 chunk

731
00:34:16,540 --> 00:34:19,060
每个 chunk 在硬盘上都是一个独立的 Linux 文件

732
00:34:19,060 --> 00:34:21,340
位于普通的 Linux 文件系统里

733
00:34:21,340 --> 00:34:24,699
假定这些 chunk 文件就是通过 handle 来命名

734
00:34:24,699 --> 00:34:26,800
假定这些 chunk 文件就是通过 handle 来命名

735
00:34:26,800 --> 00:34:28,659
所以 chunk server 需要做的就是使用正确的名字找到这个文件

736
00:34:28,659 --> 00:34:31,210
所以 chunk server 需要做的就是使用正确的名字找到这个文件

737
00:34:31,210 --> 00:34:33,449
找到整个 chunk 后 读取客户端期望的字节范围数据

738
00:34:33,449 --> 00:34:35,560
找到整个 chunk 后 读取客户端期望的字节范围数据

739
00:34:35,560 --> 00:34:38,130
找到整个 chunk 后 读取客户端期望的字节范围数据

740
00:34:38,130 --> 00:34:46,570
最后返回数据给客户端

741
00:34:46,570 --> 00:34:51,909
不要问我怎么执行读操作 我讨厌这样的问题

742
00:34:51,909 --> 00:34:54,370
(提问) 我是否能再重复讲一遍 step 1

743
00:34:54,370 --> 00:34:57,880
step 1 表示应用程序想读取

744
00:34:57,880 --> 00:35:00,040
某个特定的文件的某个特定的偏移上的数据

745
00:35:00,040 --> 00:35:02,890
某个特定的文件的某个特定的偏移上的数据

746
00:35:02,890 --> 00:35:04,420
某个特定范围里 比如 1000 到 2000 字节范围的数据

747
00:35:04,420 --> 00:35:05,830
某个特定范围里 比如 1000 到 2000 字节范围的数据

748
00:35:05,830 --> 00:35:09,010
所以它只要发送一个文件名和要读取的字节范围给 master

749
00:35:09,010 --> 00:35:12,160
所以它只要发送一个文件名和要读取的字节范围给 master

750
00:35:12,160 --> 00:35:14,050
然后 master 从文件表里查询这个文件名

751
00:35:14,050 --> 00:35:18,610
找到包含这个字节范围的 chunk

752
00:35:18,610 --> 00:35:23,820
找到包含这个字节范围的 chunk

753
00:35:30,980 --> 00:35:34,119

754
00:35:34,150 --> 00:35:36,500
我不知道详细的细节

755
00:35:36,500 --> 00:35:38,200
我印象中是如果应用程序想读取超过 64MB 的数据

756
00:35:38,200 --> 00:35:40,309
我印象中是如果应用程序想读取超过 64MB 的数据

757
00:35:40,309 --> 00:35:42,319
或者仅仅只是想读取 2 个字节数据但是却跨越了 chunk 的边界

758
00:35:42,319 --> 00:35:44,779
或者仅仅只是想读取 2 个字节数据但是却跨越了 chunk 的边界

759
00:35:44,779 --> 00:35:47,869
应用程序所链接的依赖库

760
00:35:47,869 --> 00:35:52,099
就是那个底层发送数据到不同 server 的依赖库

761
00:35:52,099 --> 00:35:54,230
就是那个底层发送数据到不同 server 的依赖库

762
00:35:54,230 --> 00:35:56,690
它将会注意到这个读请求跨越了一个 chunk 边界

763
00:35:56,690 --> 00:35:58,490
于是它会把这条读请求分割成 2 个读请求发送到 master

764
00:35:58,490 --> 00:36:01,039
于是它会把这条读请求分割成 2 个读请求发送到 master

765
00:36:01,039 --> 00:36:02,480
意思是可能你只和 master 通信 1 次但你会得到 2 条结果

766
00:36:02,480 --> 00:36:04,069
意思是可能你只和 master 通信 1 次但你会得到 2 条结果

767
00:36:04,069 --> 00:36:06,710
但是从逻辑上讲 请求 master 2 次

768
00:36:06,710 --> 00:36:08,269
接下来就会请求 2 个不同的 chunk server

769
00:36:08,269 --> 00:36:19,609
接下来就会请求 2 个不同的 chunk server

770
00:36:19,609 --> 00:36:21,650
至少在一开始对于给定的文件 客户端不知道需要哪个 chunk

771
00:36:21,650 --> 00:36:26,829
至少在一开始对于给定的文件 客户端不知道需要哪个 chunk

772
00:36:26,829 --> 00:36:35,990
至少在一开始对于给定的文件 客户端不知道需要哪个 chunk

773
00:36:35,990 --> 00:36:37,720
是的，客户端能够计算出来它需要第 17 个 chunk

774
00:36:37,720 --> 00:36:40,130
但是它需要知道是哪个 chunk server 持有这个文件的第 17 个 chunk

775
00:36:40,130 --> 00:36:42,109
但是它需要知道是哪个 chunk server 持有这个文件的第 17 个 chunk

776
00:36:42,109 --> 00:36:44,839
客户端需要和 master 通信才能知道这个信息

777
00:36:44,839 --> 00:36:47,599
客户端需要和 master 通信才能知道这个信息

778
00:36:47,599 --> 00:36:58,490
(提问)

779
00:36:58,490 --> 00:36:59,839
我不保证到底是哪种方式来判断它是文件件第 17 个 chunk

780
00:36:59,839 --> 00:37:01,130
我不保证到底是哪种方式来判断它是文件件第 17 个 chunk

781
00:37:01,130 --> 00:37:03,170
我不保证到底是哪种方式来判断它是文件件第 17 个 chunk

782
00:37:03,170 --> 00:37:06,380
但是 master 它能找到第 17 个 chunk 的 handler 标识符

783
00:37:06,380 --> 00:37:07,849
但是 master 它能找到第 17 个 chunk 的 handler 标识符

784
00:37:07,849 --> 00:37:09,950
它只要查一下它的表就能知道哪个哪个 chunk server 持有这个 chunk

785
00:37:09,950 --> 00:37:12,589
它只要查一下它的表就能知道哪个哪个 chunk server 持有这个 chunk

786
00:37:12,589 --> 00:37:17,349
它只要查一下它的表就能知道哪个哪个 chunk server 持有这个 chunk

787
00:37:25,609 --> 00:37:35,480
(提问) 你的意思是如果客户端请求的字节范围跨越了 chunk 边界

788
00:37:35,480 --> 00:37:38,010
你的意思是如果客户端请求的字节范围跨越了 chunk 边界

789
00:37:38,010 --> 00:37:46,400
你的意思是如果客户端请求的字节范围跨越了 chunk 边界

790
00:37:46,400 --> 00:37:49,049
嗯，客户端本身链接了 GFS 的 lib 库

791
00:37:49,049 --> 00:37:50,490
嗯，客户端本身链接了 GFS 的 lib 库

792
00:37:50,490 --> 00:37:52,950
嗯，客户端本身链接了 GFS 的 lib 库

793
00:37:52,950 --> 00:37:56,190
lib 库能注意到并知道如何把读请求分割

794
00:37:56,190 --> 00:38:00,270
然后把它们的返回结果合并起来

795
00:38:00,270 --> 00:38:01,290
所以 lib 会和 master 进行通信

796
00:38:01,290 --> 00:38:02,910
master 将会告诉他

797
00:38:02,910 --> 00:38:05,130
好的好的 chunk 7 号在这个 server 上

798
00:38:05,130 --> 00:38:07,589
chunk 8 在那个 server 上

799
00:38:07,589 --> 00:38:09,270
lib 就能对 chunk server 说

800
00:38:09,270 --> 00:38:10,859
oh 我要 chunk 7 号的最后 2 个字节

801
00:38:10,859 --> 00:38:12,240
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
chunk 8 号的头 2 个字节

802
00:38:12,240 --> 00:38:15,420
接下来把请求到的数据一起放到 buffer 里返回给应用层

803
00:38:15,420 --> 00:38:17,819
接下来把请求到的数据一起放到 buffer 里返回给应用层

804
00:38:17,819 --> 00:38:21,980
接下来把请求到的数据一起放到 buffer 里返回给应用层

805
00:38:26,030 --> 00:38:28,530
master 会告诉它关于 chunk 的信息

806
00:38:28,530 --> 00:38:30,900
lib 能够在给定的 chunk 中找到应用程序想要的数据

807
00:38:30,900 --> 00:38:32,700
lib 能够在给定的 chunk 中找到应用程序想要的数据

808
00:38:32,700 --> 00:38:34,950
lib 能够在给定的 chunk 中找到应用程序想要的数据

809
00:38:34,950 --> 00:38:36,240
应用程序只要想好文件名 以及整个文件中的偏移位置

810
00:38:36,240 --> 00:38:38,609
应用程序只要想好文件名 以及整个文件中的偏移位置

811
00:38:38,609 --> 00:38:41,280
应用程序只要想好文件名 以及整个文件中的偏移位置

812
00:38:41,280 --> 00:38:45,200
master 就能根据这些信息返回 chunk 信息

813
00:38:45,500 --> 00:38:48,500
(提问)

814
00:38:50,349 --> 00:38:55,400
sorry 我得离你近一点 你再讲一遍

815
00:38:55,400 --> 00:39:03,289
所以问题是 从哪个 chunk server 读取数据很重要吗

816
00:39:03,289 --> 00:39:06,109
所以问题是 从哪个 chunk server 读取数据很重要吗

817
00:39:06,109 --> 00:39:08,929
哈哈 是或不是都行 从概念上讲他们都是副本

818
00:39:08,929 --> 00:39:13,039
哈哈 是或不是都行 从概念上讲他们都是副本

819
00:39:13,039 --> 00:39:14,869
事实上你可能已经注意到了 之前我们讨论过他们并不都是

820
00:39:14,869 --> 00:39:17,209
你知道 他们并不完全相同

821
00:39:17,209 --> 00:39:20,689
你知道 他们并不完全相同

822
00:39:20,689 --> 00:39:21,979
应用程序应该是能够容忍这种情况

823
00:39:21,979 --> 00:39:23,779
但是事实上是依赖于你读取的 chunk server 副本

824
00:39:23,779 --> 00:39:24,829
你得到的数据会有稍稍不同

825
00:39:24,829 --> 00:39:28,999
所以论文上说客户端会尝试

826
00:39:28,999 --> 00:39:32,420
从相同的机架上或是从同一个交换机后的 server 读取数据

827
00:39:32,420 --> 00:39:34,699
从相同的机架上或是从同一个交换机后的 server 读取数据

828
00:39:34,699 --> 00:39:44,749
从相同的机架上或是从同一个交换机后的 server 读取数据

829
00:39:44,749 --> 00:39:47,229
好的 读取数据就是这些

830
00:39:48,859 --> 00:39:51,420
写的话会更加复杂一点 但是挺有趣

831
00:39:51,420 --> 00:40:02,880
应用程序对于写的接口是类似的

832
00:40:02,880 --> 00:40:04,410
应用程序对于写的接口是类似的

833
00:40:04,410 --> 00:40:06,030
有一些函数调用 一些可调用的库可以请求 gfs

834
00:40:06,030 --> 00:40:08,910
有一些函数调用 一些可调用的库可以请求 gfs

835
00:40:08,910 --> 00:40:10,230
客户端 lib 库请求会说

836
00:40:10,230 --> 00:40:12,540
看 这儿有个文件名以及一段我想写的字节数据

837
00:40:12,540 --> 00:40:14,339
这个 buffer 里的数据 我请求你能写入

838
00:40:14,339 --> 00:40:17,609
这个 buffer 里的数据 我请求你能写入

839
00:40:17,609 --> 00:40:19,530
稍稍往后退一步 我只是想讨论记录追加 所以我打算

840
00:40:19,530 --> 00:40:23,099
稍稍往后退一步 我只是想讨论记录追加 所以我打算

841
00:40:23,099 --> 00:40:26,339
称赞一下这种客户端接口

842
00:40:26,339 --> 00:40:28,200
客户端发起 lib 库调用会说

843
00:40:28,200 --> 00:40:29,940
这有个文件名 我想把这个 buffer 里的字节数据追加到文件里

844
00:40:29,940 --> 00:40:32,069
这有个文件名 我想把这个 buffer 里的字节数据追加到文件里

845
00:40:32,069 --> 00:40:35,099
我说的这个就是论文里讨论的记录追加

846
00:40:35,099 --> 00:40:42,900
我说的这个就是论文里讨论的记录追加

847
00:40:42,900 --> 00:40:47,579
客户端会发送 “我想追加数据“ 这样的请求到 master

848
00:40:47,579 --> 00:40:49,680
客户端会发送 “我想追加数据“ 这样的请求到 master

849
00:40:49,680 --> 00:40:51,240
请求内容是 我要给这个名字的文件追加数据

850
00:40:51,240 --> 00:40:55,140
请告诉我这个文件最后一个 chunk 在哪里

851
00:40:55,140 --> 00:40:56,790
请告诉我这个文件最后一个 chunk 在哪里

852
00:40:56,790 --> 00:40:58,619
如果有很多客户端向相同的文件里追加

853
00:40:58,619 --> 00:41:00,329
客户端可能就不知道文件有多长

854
00:41:00,329 --> 00:41:02,819
因为我们有一些大文件

855
00:41:02,819 --> 00:41:04,950
比如许多不同客户端的日志

856
00:41:04,950 --> 00:41:06,900
比如许多不同客户端的日志

857
00:41:06,900 --> 00:41:08,369
client不知道文件有多长

858
00:41:08,369 --> 00:41:10,380
因此也不知道偏移量，或是应该附加到哪个 chunk 中

859
00:41:10,380 --> 00:41:12,270
因此也不知道偏移量，或是应该附加到哪个 chunk 中

860
00:41:12,270 --> 00:41:14,280
你可以问master，请告诉我

861
00:41:14,280 --> 00:41:16,680
包含当前该文件最后一个 chunk 的服务器的信息

862
00:41:16,680 --> 00:41:18,710
包含当前该文件最后一个 chunk 的服务器的信息

863
00:41:18,710 --> 00:41:22,550
包含当前该文件最后一个 chunk 的服务器的信息

864
00:41:22,550 --> 00:41:26,040
很不幸的是 现在是写操作

865
00:41:26,040 --> 00:41:27,569
如果你在读取，你可以从任何最新副本中读取内容

866
00:41:27,569 --> 00:41:30,060
对于写的情况，需要有一个primary

867
00:41:30,060 --> 00:41:32,760
此时文件上的 primary 可能已经由master指定 也可能没有

868
00:41:32,760 --> 00:41:35,579
此时文件上的 primary 可能已经由master指定 也可能没有

869
00:41:35,579 --> 00:41:37,710
此时文件上的 primary 可能已经由master指定 也可能没有

870
00:41:37,710 --> 00:41:39,180
所以我们需要考虑这个情况

871
00:41:39,180 --> 00:41:40,980
如果还没有primary

872
00:41:40,980 --> 00:41:49,560
并且 master 知道不存在 primary

873
00:41:49,560 --> 00:41:53,119
第一种情况是没有primary

874
00:41:57,599 --> 00:42:00,099
在这种情况下，master 服务器需要

875
00:42:00,099 --> 00:42:03,430
找出具有最新 chunk 副本的 chunk 服务器集合

876
00:42:03,430 --> 00:42:06,339
找出具有最新 chunk 副本的 chunk 服务器集合

877
00:42:06,339 --> 00:42:08,470
因为，如果你的系统已经运行了很长时间

878
00:42:08,470 --> 00:42:10,660
因为，如果你的系统已经运行了很长时间

879
00:42:10,660 --> 00:42:11,800
由于故障或其他原因

880
00:42:11,800 --> 00:42:14,290
导致有的 chunk 服务器存在旧的副本

881
00:42:14,290 --> 00:42:15,579
比如昨天或上周的我保持的最新的副本

882
00:42:15,579 --> 00:42:17,950
比如昨天或上周的我保持的最新的副本

883
00:42:17,950 --> 00:42:19,690
因为该服务器可能已挂了两天 而没有更新

884
00:42:19,690 --> 00:42:21,819
因为该服务器可能已挂了两天 而没有更新

885
00:42:21,819 --> 00:42:23,800
因为该服务器可能已挂了两天 而没有更新

886
00:42:23,800 --> 00:42:24,730
因此，你需要能够分辨出 新旧副本之间的区别

887
00:42:24,730 --> 00:42:27,190
因此，你需要能够分辨出 新旧副本之间的区别

888
00:42:27,190 --> 00:42:33,569
所以第一步是要找到 找到最新的

889
00:42:33,569 --> 00:42:37,510
所以第一步是要找到 找到最新的

890
00:42:37,510 --> 00:42:41,319
这一切都发生在master

891
00:42:41,319 --> 00:42:42,790
因为client请求master

892
00:42:42,790 --> 00:42:44,260
告诉master我要追加此文件

893
00:42:44,260 --> 00:42:46,180
请告诉我要与哪些块服务器对话

894
00:42:46,180 --> 00:42:48,550
所以master服务器一部分

895
00:42:48,550 --> 00:42:49,780
试图弄清楚client端

896
00:42:49,780 --> 00:42:50,680
应该与哪些服务器通信

897
00:42:50,680 --> 00:42:52,950
所以当我们最终找到最新的副本时

898
00:42:52,950 --> 00:42:59,770
up-to-date 的意思是

899
00:42:59,770 --> 00:43:02,260
一个副本中的 chunk 版本等于 master 服务器知道的最新版本号

900
00:43:02,260 --> 00:43:04,720
一个副本中的 chunk 版本等于 master 服务器知道的最新版本号

901
00:43:04,720 --> 00:43:06,730
一个副本中的 chunk 版本等于 master 服务器知道的最新版本号

902
00:43:06,730 --> 00:43:08,140
因为这些版本号是 master 服务器分发的

903
00:43:08,140 --> 00:43:10,630
因为这些版本号是 master 服务器分发的

904
00:43:10,630 --> 00:43:14,740
所以 master 记得它们，oh

905
00:43:14,740 --> 00:43:18,460
对于这个特定的 chunk

906
00:43:18,460 --> 00:43:19,569
仅当 chunk 服务器的版本号为 17 时它才是最新的

907
00:43:19,569 --> 00:43:21,220
仅当 chunk 服务器的版本号为 17 时它才是最新的

908
00:43:21,220 --> 00:43:23,550
这就是为什么它必须是非易失性的 需要存储在磁盘上的原因

909
00:43:23,550 --> 00:43:26,560
如果版本号在崩溃中丢失

910
00:43:26,560 --> 00:43:31,000
并且 chunk 服务器持有过时 chunk 副本

911
00:43:31,000 --> 00:43:33,670
并且 chunk 服务器持有过时 chunk 副本

912
00:43:33,670 --> 00:43:35,140
master 就无法区分

913
00:43:35,140 --> 00:43:36,819
这个 chunk sever 上的 chunk 副本是上周的还是最新的

914
00:43:36,819 --> 00:43:39,310
这个 chunk sever 上的 chunk 副本是上周的还是最新的

915
00:43:39,310 --> 00:43:42,250
这个 chunk sever 上的 chunk 副本是上周的还是最新的

916
00:43:42,250 --> 00:43:44,440
这个 chunk sever 上的 chunk 副本是上周的还是最新的

917
00:43:44,440 --> 00:43:46,660
这就是为什么 master 服务器需要把版本号记在磁盘上的的原因

918
00:43:46,660 --> 00:43:49,470
(提问)

919
00:43:54,450 --> 00:43:56,859
如果你正在与所有 chunk 服务器通信

920
00:43:56,859 --> 00:43:59,970
okay 结论是如果 master 重启

921
00:43:59,970 --> 00:44:02,260
okay 结论是如果 master 重启

922
00:44:02,260 --> 00:44:04,660
master 服务器无论如何都要与 chunk 服务器进行通信

923
00:44:04,660 --> 00:44:06,280
来确定哪个 chunk 服务器持有哪个 chunk

924
00:44:06,280 --> 00:44:08,890
因为 master 不记得那些信息了

925
00:44:08,890 --> 00:44:12,150
你可能会想 你只要找到 version 最大的那个就行

926
00:44:12,150 --> 00:44:14,380
你可能会想 你只要找到 version 最大的那个就行

927
00:44:14,380 --> 00:44:15,579
你只需和 chunk 服务器通信 找出他们拥有哪些 chunk 和版本

928
00:44:15,579 --> 00:44:17,079
你只需和 chunk 服务器通信 找出他们拥有哪些 chunk 和版本

929
00:44:17,079 --> 00:44:19,000
从所有响应中找到 version 最大值

930
00:44:19,000 --> 00:44:20,619
从所有响应中找到 version 最大值

931
00:44:20,619 --> 00:44:22,750
如果所有持有 chunk 的 chunk 服务器都响应

932
00:44:22,750 --> 00:44:24,579
这种做法没有问题

933
00:44:24,579 --> 00:44:26,920
但风险是 master 重启时

934
00:44:26,920 --> 00:44:28,480
也许一些 chunk 服务器离线或断开连接

935
00:44:28,480 --> 00:44:30,400
也许一些 chunk 服务器离线或断开连接

936
00:44:30,400 --> 00:44:32,770
或是别的什么原因重新 导致它不响应 master

937
00:44:32,770 --> 00:44:35,349
导致 master 拿到的都是持有前几周旧副本的 chunk server 的响应

938
00:44:35,349 --> 00:44:38,200
导致 master 拿到的都是持有前几周旧副本的 chunk server 的响应

939
00:44:38,200 --> 00:44:40,119
导致 master 拿到的都是持有前几周旧副本的 chunk server 的响应

940
00:44:40,119 --> 00:44:42,460
而具有最新副本的 chunk 服务器还没完成重启 甚至是离线

941
00:44:42,460 --> 00:44:44,320
而具有最新副本的 chunk 服务器还没完成重启 甚至是离线

942
00:44:44,320 --> 00:44:54,940
而具有最新副本的 chunk 服务器还没完成重启 甚至是离线

943
00:44:54,940 --> 00:44:56,619
如果服务器上所有的最新版本都失效或丢失的话 答案是 yes

944
00:44:56,619 --> 00:44:59,859
如果服务器上所有的最新版本都失效或丢失的话 答案是 yes

945
00:44:59,859 --> 00:45:02,980
如果服务器上所有的最新版本都失效或丢失的话 答案是 yes

946
00:45:02,980 --> 00:45:06,540
如果服务器上所有的最新版本都失效或丢失的话 答案是 yes

947
00:45:09,030 --> 00:45:11,130
不对

948
00:45:11,130 --> 00:45:15,339
okay，问题是，master 知道

949
00:45:15,339 --> 00:45:17,560
对于这个 chunk 寻找版本17

950
00:45:17,560 --> 00:45:18,550
对于这个 chunk 寻找版本17

951
00:45:18,550 --> 00:45:21,579
假设它找不到这样的 chunk 服务器

952
00:45:21,579 --> 00:45:22,690
你知道 master 会定期与 chunk 服务器进行对话以询问它们

953
00:45:22,690 --> 00:45:24,430
你知道 master 会定期与 chunk 服务器进行对话以询问它们

954
00:45:24,430 --> 00:45:25,780
拥有哪些块 拥有什么版本

955
00:45:25,780 --> 00:45:27,520
假设它没有找到包含版本 17 chunk 服务器

956
00:45:27,520 --> 00:45:30,369
假设它没有找到包含版本 17 chunk 服务器

957
00:45:30,369 --> 00:45:32,800
master 要么先不回复并等待

958
00:45:32,800 --> 00:45:35,710
master 要么先不回复并等待

959
00:45:35,710 --> 00:45:39,790
要么告诉 client，我无法回答，请稍后再试

960
00:45:39,790 --> 00:45:42,880
要么告诉client，我无法回答，请稍后再试

961
00:45:42,880 --> 00:45:44,530
就像建筑物中的电源故障

962
00:45:44,530 --> 00:45:45,849
就像建筑物中的电源故障

963
00:45:45,849 --> 00:45:47,079
所有服务器都崩溃了，我们正在缓慢地重新启动

964
00:45:47,079 --> 00:45:49,510
master 可能先启动完成

965
00:45:49,510 --> 00:45:51,430
一些 chunk 服务器可能已启动

966
00:45:51,430 --> 00:45:53,079
其他的在五分钟后才完成启动

967
00:45:53,079 --> 00:45:57,609
其他的在五分钟后才完成启动

968
00:45:57,609 --> 00:45:59,890
所以必须等待 并且会永远等待

969
00:45:59,890 --> 00:46:02,290
所以必须等待 并且会永远等待

970
00:46:02,290 --> 00:46:05,440
因为你不想使用 chunk 的旧版本

971
00:46:05,440 --> 00:46:09,190
所以 master 需要整合具有最新版本的 chunk 服务器列表

972
00:46:09,190 --> 00:46:10,540
所以 master 需要整合具有最新版本的 chunk 服务器列表

973
00:46:10,540 --> 00:46:12,910
master 知道磁盘上存储的最新版本

974
00:46:12,910 --> 00:46:14,619
master 知道磁盘上存储的最新版本

975
00:46:14,619 --> 00:46:16,540
正如你所指出的 每个 chunk 服务器以及每个 chunk

976
00:46:16,540 --> 00:46:18,280
正如你所指出的 每个 chunk 服务器以及每个 chunk

977
00:46:18,280 --> 00:46:19,810
也记得它存储的 chunk 的版本号

978
00:46:19,810 --> 00:46:22,540
当 chunk 服务器向 master 报告说

979
00:46:22,540 --> 00:46:23,859
看，我有这个 chunk

980
00:46:23,859 --> 00:46:25,690
master 服务器便可以

981
00:46:25,690 --> 00:46:27,760
忽略那些版本与 master 知道的最新版本不匹配的 chunk server

982
00:46:27,760 --> 00:46:30,339
忽略那些版本与 master 知道的最新版本不匹配的 chunk server

983
00:46:30,339 --> 00:46:34,869
okay 回到之前的话题 我们 client 想要执行追加

984
00:46:34,869 --> 00:46:36,670
okay 回到之前的话题 我们 client 想要执行追加

985
00:46:36,670 --> 00:46:39,579
但是 master 还没有 primary 它意识到

986
00:46:39,579 --> 00:46:42,310
你可能需要等待具有该 chunk 最新版本的服务器集合

987
00:46:42,310 --> 00:46:43,960
你可能需要等待具有该 chunk 最新版本的服务器集合

988
00:46:43,960 --> 00:46:49,020
master 会挑一个 chunk server 出来作为 primary

989
00:46:50,040 --> 00:46:52,930
所以我要选择其中一个作为 primary

990
00:46:52,930 --> 00:46:56,859
所以我要选择其中一个作为 primary

992
00:46:56,859 --> 00:46:58,210
将其他作为 secondary（次级服务）

993
00:46:58,210 --> 00:47:02,140
然后 master 将版本号递增 并将其写入磁盘

994
00:47:02,140 --> 00:47:11,170
然后 master 将版本号递增 并将其写入磁盘

996
00:47:11,170 --> 00:47:13,600
这样在崩溃时也不会丢失（版本号）

997
00:47:13,600 --> 00:47:15,970
接下来请求 primary 和 secondary

998
00:47:15,970 --> 00:47:18,700
通知它们都是什么身份

999
00:47:18,700 --> 00:47:20,710
每个 chunk server 都能收到一条消息：找到这个 chunk

1000
00:47:20,710 --> 00:47:22,840
这是 primary，这是 secondary

1001
00:47:22,840 --> 00:47:26,650
收件人可能是其中之一

1002
00:47:26,650 --> 00:47:28,450
这个新版本号

1003
00:47:28,450 --> 00:47:32,170
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
然后它会把这个信息以及版本号告诉 primary 和 secondary

1004
00:47:32,170 --> 00:47:37,060
然后它会把这个信息以及版本号告诉 primary 和 secondary

1005
00:47:37,060 --> 00:47:39,970
primary 节点和 secondary 节点都将版本号写入磁盘

1007
00:47:39,970 --> 00:47:41,920
primary 节点和 secondary 节点都将版本号写入磁盘

1008
00:47:41,920 --> 00:47:43,780
所以它们不会丢失这个信息

1009
00:47:43,780 --> 00:47:45,040
如果因为电源故障或其他原因

1010
00:47:45,040 --> 00:47:47,140
等它们重启后必须拿着这个版本号向 master 报告

1011
00:47:47,140 --> 00:47:51,210
等它们重启后必须拿着这个版本号向 master 报告

1012
00:48:04,230 --> 00:48:06,190
问题很棒

1013
00:48:06,190 --> 00:48:08,500
我不知道答案 不过论文中有提示

1014
00:48:08,500 --> 00:48:11,170
关于你问的这点 其实之前我犯了点小错误

1015
00:48:11,170 --> 00:48:14,740
我觉得你的问题已经做了解释

1016
00:48:14,740 --> 00:48:16,030
我觉得你的问题已经做了解释

1017
00:48:16,030 --> 00:48:18,310
论文里说 如果 master 重启并与 chunk server 进行通信

1018
00:48:18,310 --> 00:48:22,480
论文里说 如果 master 重启并与 chunk server 进行通信

1019
00:48:22,480 --> 00:48:24,220
并且其中一个 chunk server 重启时报告的版本号

1020
00:48:24,220 --> 00:48:26,530
高于 master 记住的版本号

1021
00:48:26,530 --> 00:48:28,540
高于 master 记住的版本号

1022
00:48:28,540 --> 00:48:31,600
master 会假设它在分配新 primary 时发生了某些错误

1023
00:48:31,600 --> 00:48:34,600
master 会假设它在分配新 primary 时发生了某些错误

1024
00:48:34,600 --> 00:48:36,760
于是它会使用这个更高的版本号（来自这个 chunk server）作为当前版本号

1025
00:48:36,760 --> 00:48:38,860
于是它会使用这个更高的版本号（来自这个 chunk server）作为当前版本号

1026
00:48:38,860 --> 00:48:42,250
为什么会有这么诡异的错误？

1027
00:48:42,250 --> 00:48:48,010
我觉得是 master 在通知 primary 之后才做的持久化

1028
00:48:48,010 --> 00:48:55,869
我觉得是 master 在通知 primary 之后才做的持久化

1029
00:48:55,869 --> 00:49:02,530
但碰巧 在把版本号写入磁盘之前 master 崩了

1030
00:49:02,530 --> 00:49:03,550
所以这里是有点问题的

1031
00:49:03,550 --> 00:49:11,880
(提问) 是否有 ACK ?

1032
00:49:12,410 --> 00:49:17,250
master 服务器可能会告知 primary 和 backup

1033
00:49:17,250 --> 00:49:18,810
master 服务器可能会告知 primary 和 backup

1034
00:49:18,810 --> 00:49:20,400
是告知 primary 和 secondary

1035
00:49:20,400 --> 00:49:21,720
如果有 primary secondary 就通知它新版本号

1036
00:49:21,720 --> 00:49:24,450
然后等待 ACK 再写入磁盘 或是其它不满足条件的操作

1037
00:49:24,450 --> 00:49:27,870
然后等待 ACK 再写入磁盘 或是其它不满足条件的操作

1038
00:49:27,870 --> 00:49:37,770
我认为这行不通

1039
00:49:37,770 --> 00:49:40,380
因为存在这种可能性

1040
00:49:40,380 --> 00:49:41,940
master 服务器重启时 具有最新版本号的 chunk server 可能是离线的

1041
00:49:41,940 --> 00:49:44,190
master 服务器重启时 具有最新版本号的 chunk server 可能是离线的

1042
00:49:44,190 --> 00:49:46,650
master 服务器重启时 具有最新版本号的 chunk server 可能是离线的

1043
00:49:46,650 --> 00:49:48,360
我们不希望 master 不知道当前版本号

1044
00:49:48,360 --> 00:49:50,610
我们不希望 master 不知道当前版本号

1045
00:49:50,610 --> 00:49:51,960
因为它收到的所谓的最高的版本号 可能是个旧版本号

1046
00:49:51,960 --> 00:49:54,300
因为它收到的所谓的最高的版本号 可能是个旧版本号

1047
00:49:54,300 --> 00:49:57,000
这个领域我知道的不多

1048
00:49:57,000 --> 00:49:58,260
我不太清楚 master 是否是先更新其自己的版本号

1049
00:49:58,260 --> 00:50:00,570
我不太清楚 master 是否是先更新其自己的版本号

1050
00:50:00,570 --> 00:50:01,800
再告诉 primary 和 secondary 又或是其他方式

1051
00:50:01,800 --> 00:50:03,600
再告诉 primary 和 secondary 又或是其他方式

1052
00:50:03,600 --> 00:50:06,360
我不确定它采用哪种方式

1053
00:50:06,360 --> 00:50:11,340
但无论如何 总有某种方式

1054
00:50:11,340 --> 00:50:12,810
master 更新其版本号 并告诉 primary secondary

1055
00:50:12,810 --> 00:50:14,340
master 更新其版本号 并告诉 primary secondary

1056
00:50:14,340 --> 00:50:16,140
看看你的 primaries 和 secondaries，这儿还有个最新版本号

1057
00:50:16,140 --> 00:50:17,700
看看你的 primaries 和 secondaries，这儿还有个最新版本号

1058
00:50:17,700 --> 00:50:19,410
现在我们有了一个可以接受写入的 primary

1059
00:50:19,410 --> 00:50:21,480
primary 的工作是接收客户端的请求

1060
00:50:21,480 --> 00:50:23,730
primary 的工作是接收客户端的请求

1061
00:50:23,730 --> 00:50:26,760
将这些写入进行组织成一定顺序 然后应用于各个 chunk servers

1062
00:50:26,760 --> 00:50:35,130
将这些写入进行组织成一定顺序 然后应用于各个 chunk servers

1063
00:50:35,130 --> 00:50:36,450
版本号的目的是使 master 能找到哪些 server 具有最新的 chunk

1064
00:50:36,450 --> 00:50:44,270
版本号的目的是使 master 能找到哪些 server 具有最新的 chunk

1065
00:50:44,420 --> 00:50:49,940
版本号的目的是使 master 能找到哪些 server 具有最新的 chunk

1066
00:50:50,240 --> 00:50:52,800
master 授予某些 chunk server 成为 primary 的能力

1067
00:50:52,800 --> 00:50:55,320
master 授予某些 chunk server 成为 primary 的能力

1068
00:50:55,320 --> 00:50:58,950
我们希望能够辨认出 如果主机崩溃

1069
00:50:58,950 --> 00:51:01,260
我们希望能够辨认出 如果主机崩溃

1070
00:51:01,260 --> 00:51:03,840
只有那个 primary 和 secondaries

1071
00:51:03,840 --> 00:51:05,070
只有那个 primary 和 secondaries

1072
00:51:05,070 --> 00:51:06,720
才能处理 才能负责更新这个 chunk

1073
00:51:06,720 --> 00:51:08,250
才能处理 才能负责更新这个 chunk

1074
00:51:08,250 --> 00:51:10,530
将来只有那些 primaries 和 secondaries

1075
00:51:10,530 --> 00:51:12,630
可以在未来成为 chunk server

1076
00:51:12,630 --> 00:51:14,070
master 实现这个目的的方式就是使用版本号

1077
00:51:14,070 --> 00:51:17,270
master 实现这个目的的方式就是使用版本号

1078
00:51:17,480 --> 00:51:21,500
master 告诉 primaries 和 secondaries

1079
00:51:21,500 --> 00:51:23,119
它们被允许修改这个 chunk

1080
00:51:23,119 --> 00:51:24,740
它们被允许修改这个 chunk

1081
00:51:24,740 --> 00:51:27,530
它还给 primary 一个租约 告诉primary

1082
00:51:27,530 --> 00:51:29,390
它还给 primary 一个租约 告诉primary

1083
00:51:29,390 --> 00:51:31,099
在接下来的 60 秒内你将是 primary，60 秒后你就不再是

1084
00:51:31,099 --> 00:51:33,200
在接下来的 60 秒内你将是 primary，60 秒后你就不再是

1085
00:51:33,200 --> 00:51:37,280
这个机制确保我们不会同时两个 primary，稍后我们再讨论

1086
00:51:37,280 --> 00:51:39,290
这个机制确保我们不会同时两个 primary，稍后我们再讨论

1087
00:51:39,290 --> 00:51:41,869
这个机制确保我们不会同时两个 primary，稍后我们再讨论

1088
00:51:41,869 --> 00:51:46,339
okay 现在假设我们是 primary

1089
00:51:46,339 --> 00:51:50,089
master 告诉 client 谁是 primary 谁是secondary

1090
00:51:50,089 --> 00:51:54,440
master 告诉 client 谁是 primary 谁是secondary

1091
00:51:54,440 --> 00:51:59,050
此时，我们正在执行论文中的图二

1092
00:51:59,050 --> 00:52:02,240
此时，我们正在执行论文中的图二

1093
00:52:02,240 --> 00:52:04,040
client 现在知道谁是 primary 谁是 secondaries

1094
00:52:04,040 --> 00:52:05,660
client 的请求以某种秩序组织在一起 这篇论文

1095
00:52:05,660 --> 00:52:08,180
提出了一种聪明的方法来管理这种秩序

1096
00:52:08,180 --> 00:52:10,849
提出了一种聪明的方法来管理这种秩序

1097
00:52:10,849 --> 00:52:13,250
client 端将要追加的数据副本发送给 primary

1098
00:52:13,250 --> 00:52:15,230
client 端将要追加的数据副本发送给 primary

1099
00:52:15,230 --> 00:52:18,440
和所有 secondaries 然后 primary 和

1100
00:52:18,440 --> 00:52:20,390
secondaries 将该数据写入一个临时位置

1101
00:52:20,390 --> 00:52:22,099
此时这些数据并不会追加到文件中

1102
00:52:22,099 --> 00:52:24,380
等 primary 和 secondaries 都收到数据并回复 yes 后

1103
00:52:24,380 --> 00:52:29,180
等 primary 和 secondaries 都收到数据并回复 yes 后

1104
00:52:29,180 --> 00:52:31,130
client 发送一条消息到 primary 说

1105
00:52:31,130 --> 00:52:33,470
你和所有 secondaries 节点都收到了我要追加的数据

1106
00:52:33,470 --> 00:52:36,579
你和所有 secondaries 节点都收到了我要追加的数据

1108
00:52:36,579 --> 00:52:38,960
primary 可能此时正从很多不同的 client 接收这些请求

1109
00:52:38,960 --> 00:52:40,520
primary 可能此时正从很多不同的 client 接收这些请求

1110
00:52:40,520 --> 00:52:43,010
这时 primary 会选择某种顺序依次执行所有 client 的请求 把数据追加到文件里

1111
00:52:43,010 --> 00:52:45,260
这时 primary 会选择某种顺序依次执行所有 client 的请求 把数据追加到文件里

1112
00:52:45,260 --> 00:52:48,260
这时 primary 会选择某种顺序依次执行所有 client 的请求 把数据追加到文件里

1113
00:52:48,260 --> 00:52:50,450
primary 查看文件末尾的偏移量 也就是 chunk 的末尾

1114
00:52:50,450 --> 00:52:53,030
primary 查看文件末尾的偏移量 也就是 chunk 的末尾

1115
00:52:53,030 --> 00:52:54,740
确保 chunk 中有足够的剩余空间

1116
00:52:54,740 --> 00:52:56,480
确保 chunk 中有足够的剩余空间

1117
00:52:56,480 --> 00:52:59,960
然后将 client 记录写入当前块的末尾

1118
00:52:59,960 --> 00:53:02,240
然后将 client 记录写入当前块的末尾

1119
00:53:02,240 --> 00:53:04,369
并告诉所有 secondary 也将其写到末尾的相同偏移量处

1120
00:53:04,369 --> 00:53:08,359
并告诉所有 secondary 也将其写到末尾的相同偏移量处

1121
00:53:08,359 --> 00:53:12,010
并告诉所有 secondary 也其写到末尾的相同偏移量处

1122
00:53:12,010 --> 00:53:20,500
primary 选一个偏移量

1123
00:53:20,500 --> 00:53:26,480
所有副本 包括primary 被告知在指定偏移位置追加新记录

1124
00:53:26,480 --> 00:53:29,180
所有副本 包括primary 被告知在指定偏移位置追加新记录

1125
00:53:29,180 --> 00:53:36,090
所有副本 包括primary 被告知在指定偏移位置追加新记录

1126
00:53:36,090 --> 00:53:38,700
这些 secondaries 它们可能会执行成功 也可能会失败

1127
00:53:38,700 --> 00:53:41,250
比如说空间不足 或是崩溃

1128
00:53:41,250 --> 00:53:42,810
比如说空间不足 或是崩溃

1129
00:53:42,810 --> 00:53:45,480
也可能是 primary 发送的消息在网络中丢失

1130
00:53:45,480 --> 00:53:47,970
如果 secondary 节点确实在这个偏移处

1131
00:53:47,970 --> 00:53:50,760
把数据写入了磁盘 它会回复 “yes” 给 primary

1132
00:53:50,760 --> 00:53:52,859
如果 primary 收到了所有 secondaries 回复的 yes

1133
00:53:52,859 --> 00:53:57,740
如果 primary 收到了所有 secondaries 回复的 yes

1134
00:53:58,520 --> 00:54:02,190
如果它们确实把数据写入了磁盘且向 primary 回复了 yes

1135
00:54:02,190 --> 00:54:03,630
如果它们确实把数据写入了磁盘且向 primary 回复了 yes

1136
00:54:03,630 --> 00:54:08,250
如果它们确实把数据写入了磁盘且向 primary 回复了 yes

1137
00:54:08,250 --> 00:54:10,800
那么 primary 将向 client 端回复 success

1138
00:54:10,800 --> 00:54:18,930
如果 primary 没有收到某一个 secondary 的回复

1139
00:54:18,930 --> 00:54:21,510
如果 primary 没有收到某一个 secondary 的回复

1140
00:54:21,510 --> 00:54:23,580
或是某个 secondary 回复了错误：

1141
00:54:23,580 --> 00:54:25,590
sorry 发生了一些不好的事情 我磁盘空间不足 我的磁盘挂了

1142
00:54:25,590 --> 00:54:28,980
那么 primary 就会回复 no 给 client

1143
00:54:28,980 --> 00:54:37,950
那么 primary 就会回复 no 给 client

1144
00:54:37,950 --> 00:54:39,420
论文说，如果 client 从 primary 得到这样的错误

1145
00:54:39,420 --> 00:54:42,000
论文说，如果 client 从 primary 得到这样的错误

1146
00:54:42,000 --> 00:54:44,369
client 应该重新发起整个追加的过程

1147
00:54:44,369 --> 00:54:46,020
重新开始与 master 通信 以找出文件末尾

1148
00:54:46,020 --> 00:54:48,530
重新开始与 master 通信 以找出文件末尾

1149
00:54:48,530 --> 00:54:50,369
重新开始与 master 通信 以找出文件末尾

1150
00:54:50,369 --> 00:54:52,500
我想知道 client 端应该

1151
00:54:52,500 --> 00:54:54,300
重新发起整个记录追加操作

1152
00:54:54,300 --> 00:55:01,650
(提问) 你可能会这样想，但它们不会

1153
00:55:01,650 --> 00:55:05,180
所以问题让人很吃惊

1154
00:55:05,180 --> 00:55:08,220
你知道 primary 服务器告诉所有副本执行追加操作

1155
00:55:08,220 --> 00:55:09,869
也许其中一些服务器成功了 有些失败了

1156
00:55:09,869 --> 00:55:10,830
也许其中一些服务器成功了 有些失败了

1157
00:55:10,830 --> 00:55:12,869
如果其中一些失败 那么我们会向 client 端报错误

1158
00:55:12,869 --> 00:55:14,460
如果其中一些失败 那么我们会向 client 端报错误

1159
00:55:14,460 --> 00:55:16,109
因此 client 认为 追加没有发生

1160
00:55:16,109 --> 00:55:18,630
但是其他副本的追加操作确实成功了

1161
00:55:18,630 --> 00:55:23,550
但是其他副本的追加操作确实成功了

1162
00:55:23,550 --> 00:55:25,400
所有的副本都在追加相同的数据

1163
00:55:25,400 --> 00:55:27,480
但是其中之一返回了错误 它没有执行追加

1164
00:55:27,480 --> 00:55:28,890
但是其中之一返回了错误 它没有执行追加

1165
00:55:28,890 --> 00:55:31,830
而返回的 yes 的那些服务器确实做了追加

1166
00:55:31,830 --> 00:55:35,119
这就是 GFS 运作的方式

1167
00:55:44,590 --> 00:55:47,590
如果客户端随后读取了此文件

1168
00:55:47,590 --> 00:55:50,330
读取的结果取决于请求的是哪个副本

1169
00:55:50,330 --> 00:55:53,360
它们可能会看到追加的记录 也可能看不到

1170
00:55:53,360 --> 00:55:56,810
它们可能会看到追加的记录 也可能看不到

1171
00:55:56,810 --> 00:55:59,120
但是如果记录追加成功

1172
00:55:59,120 --> 00:56:00,920
client 收到 success 成功消息

1173
00:56:00,920 --> 00:56:03,920
意味着所有副本 都以相同的偏移量追加了该记录

1174
00:56:03,920 --> 00:56:05,420
意味着所有副本 都以相同的偏移量追加了该记录

1175
00:56:05,420 --> 00:56:10,160
如果 client 得到 no 的回复

1176
00:56:10,160 --> 00:56:14,090
说明有 0 个或多个副本可能已经追加了该偏移量的记录

1177
00:56:14,090 --> 00:56:15,740
说明有 0 个或多个副本可能已经追加了该偏移量的记录

1178
00:56:15,740 --> 00:56:20,240
而其他副本则没有 所以 client 得到了 no

1179
00:56:20,240 --> 00:56:22,280
如果发生这种情况 会导致有些副本有记录 有些没有

1180
00:56:22,280 --> 00:56:25,130
如果发生这种情况 会导致有些副本有记录 有些没有

1181
00:56:25,130 --> 00:56:27,860
所以你读取你可能读到 也可能读不到这个记录

1182
00:56:27,860 --> 00:56:29,750
所以你可能读到 也可能读不到这个记录

1183
00:56:29,750 --> 00:56:32,980
所以你可能读到 也可能读不到这个记录

1184
00:56:39,410 --> 00:56:45,319
所有副本都是一样的

1185
00:56:45,319 --> 00:56:47,240
所有 secondaries 都有相同的版本号

1186
00:56:47,240 --> 00:56:49,430
版本号仅在 master 分配新的 primary 时更改

1187
00:56:49,430 --> 00:56:51,500
版本号仅在 master 分配新的 primary 时更改

1188
00:56:51,500 --> 00:56:53,900
你说的可能仅在 primary 出故障时才会发生

1189
00:56:53,900 --> 00:56:55,309
你说的可能仅在 primary 出故障时才会发生

1190
00:56:55,309 --> 00:56:58,270
所以我们讨论的都是具有新版本号的副本

1191
00:56:58,270 --> 00:57:00,200
所以我们讨论的都是具有新版本号的副本

1192
00:57:00,200 --> 00:57:02,660
你无法分辨出这些副本的区别

1193
00:57:02,660 --> 00:57:03,740
你无法分辨出这些副本的区别

1194
00:57:03,740 --> 00:57:08,059
你无法分辨出这些副本的区别

1195
00:57:08,059 --> 00:57:09,319
但可能他们就是有区别

1196
00:57:09,319 --> 00:57:11,390
这样做的理由是 可能不是所有副本都有那个追加记录

1197
00:57:11,390 --> 00:57:13,160
这样做的理由是 可能不是所有副本都有那个追加记录

1198
00:57:13,160 --> 00:57:16,099
这样做的理由是 可能不是所有副本都有那个追加记录

1199
00:57:16,099 --> 00:57:18,200
但是在这种情况下 primary 回答是 no

1200
00:57:18,200 --> 00:57:20,180
并且 client 知道写入失败了

1201
00:57:20,180 --> 00:57:22,940
并且 client 知道写入失败了

1202
00:57:22,940 --> 00:57:24,410
这样做背后的原因是 client 将重新请求追加记录

1203
00:57:24,410 --> 00:57:27,859
这样做背后的原因是 client 将重新请求追加记录

1204
00:57:27,859 --> 00:57:29,480
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
你知道 记录最终追加会成功

1205
00:57:29,480 --> 00:57:33,260
你知道 记录最终追加会成功

1206
00:57:33,260 --> 00:57:36,920
因为 client 会继续发出（写请求）直到成功

1207
00:57:36,920 --> 00:57:38,480
因为 client 会继续发出（写请求）直到成功

1208
00:57:38,480 --> 00:57:39,770
当它成功时 追加记录的偏移量会在更远的位置

1209
00:57:39,770 --> 00:57:41,510
当它成功时 追加记录的偏移量会在更远的位置

1210
00:57:41,510 --> 00:57:43,460
并且所有副本中的这个偏移位置都会有这个记录

1211
00:57:43,460 --> 00:57:45,859
并且所有副本中的这个偏移位置都会有这个记录

1212
00:57:45,859 --> 00:57:48,049
而那之前的偏移量位置 只有部分副本中才会出现追加的记录

1213
00:57:48,049 --> 00:58:04,680
而那之前的偏移量位置 只有部分副本中才会出现追加的记录

1214
00:58:04,680 --> 00:58:11,779
oh，这是一个好问题

1215
00:58:11,779 --> 00:58:15,690
对于底层网络而言 数据传输路径可能非常重要

1216
00:58:15,690 --> 00:58:17,910
对于底层网络而言 数据传输路径可能非常重要

1217
00:58:17,910 --> 00:58:19,410
对于底层网络而言 数据传输路径可能非常重要

1218
00:58:19,410 --> 00:58:22,950
论文在第一次提及时声称 client 把数据发送到每个副本

1219
00:58:22,950 --> 00:58:24,539
论文在第一次提及时声称 client 把数据发送到每个副本

1220
00:58:24,539 --> 00:58:26,490
论文在第一次提及时声称 client 把数据发送到每个副本

1221
00:58:26,490 --> 00:58:29,309
后来论文又改变说法 说 client 只把数据发送到离它最近的副本

1222
00:58:29,309 --> 00:58:31,289
后来论文又改变说法 说 client 只把数据发送到离它最近的副本

1223
00:58:31,289 --> 00:58:33,539
后来论文又改变说法 说 client 只把数据发送到离它最近的副本

1224
00:58:33,539 --> 00:58:36,359
然后该副本将数据转发到另一个副本

1225
00:58:36,359 --> 00:58:37,829
然后该副本将数据转发到另一个副本

1226
00:58:37,829 --> 00:58:39,630
沿着某种链路直到所有的副本都拿到数据

1227
00:58:39,630 --> 00:58:41,940
沿着某种链路直到所有的副本都拿到数据

1228
00:58:41,940 --> 00:58:43,770
这条链路在整个数据中心上做过了最小化跨越交换机的处理

1229
00:58:43,770 --> 00:58:46,859
这条链路在整个数据中心上做过了最小化跨越交换机的处理

1230
00:58:46,859 --> 00:59:00,390
这条链路在整个数据中心上做过了最小化跨越交换机的处理

1231
00:59:00,390 --> 00:59:03,539
版本号只在 master 服务器认为没有 primary 时才会增加

1232
00:59:03,539 --> 00:59:06,119
版本号只在 master 服务器认为没有 primary 时才会增加

1233
00:59:06,119 --> 00:59:09,359
在通常的流程中 那个 chunk 已经有一个 primary

1234
00:59:09,359 --> 00:59:13,710
在通常的流程中 那个 chunk 已经有一个 primary

1235
00:59:13,710 --> 00:59:16,680
master 会记得该 chunk 已经有一个 primary 和 secondary

1236
00:59:16,680 --> 00:59:18,180
master 会记得该 chunk 已经有一个 primary 和 secondary

1237
00:59:18,180 --> 00:59:19,470
master 会记得该 chunk 已经有一个 primary 和 secondary

1238
00:59:19,470 --> 00:59:20,640
master 就不会再重新选择 primary 也就不会增加版本号

1239
00:59:20,640 --> 00:59:22,079
master 就不会再重新选择 primary 也就不会增加版本号

1240
00:59:22,079 --> 00:59:24,450
它只会告诉 client 端：看 这个是 primary

1241
00:59:24,450 --> 00:59:26,400
它只会告诉 client 端：看 这个是 primary

1242
00:59:26,400 --> 00:59:29,270
这里没有发生版本号更改

1243
00:59:42,340 --> 00:59:47,090
我的理解是 如果是这样的话

1244
00:59:47,090 --> 00:59:49,130
我想你是在问一个有趣的问题

1245
00:59:49,130 --> 00:59:51,050
我想你是在问一个有趣的问题

1246
00:59:51,050 --> 00:59:52,940
在这种情况下，primary 向 client 端 回复失败消息

1247
00:59:52,940 --> 00:59:54,590
在这种情况下，primary 向 client 端 回复失败消息

1248
00:59:54,590 --> 00:59:56,000
你可能会认为一定哪里出错了

1249
00:59:56,000 --> 00:59:57,860
应该在继续进行之前将其修复

1250
00:59:57,860 --> 00:59:59,870
事实上 据我所知 论文里没有立即让 client 重试追加

1251
00:59:59,870 --> 01:00:03,320
事实上 据我所知 论文里没有立即让 client 重试追加

1252
01:00:03,320 --> 01:00:08,300
事实上 据我所知 论文里没有立即让 client 重试追加

1253
01:00:08,300 --> 01:00:10,010
也许是因为网络消息丢失了

1254
01:00:10,010 --> 01:00:11,570
所以没有什么可以修复的

1255
01:00:11,570 --> 01:00:12,980
本该传递出去的网络消息丢失了

1256
01:00:12,980 --> 01:00:13,850
本该传递出去的网络消息丢失了

1257
01:00:13,850 --> 01:00:15,080
重传网络消息的话这就有点复杂了

1258
01:00:15,080 --> 01:00:17,600
重传网络消息的话这就有点复杂了

1259
01:00:17,600 --> 01:00:19,040
这种错误太常见了

1260
01:00:19,040 --> 01:00:21,020
这种错误太常见了

1261
01:00:21,020 --> 01:00:22,790
所以我们什么都不用改变

1262
01:00:22,790 --> 01:00:26,750
如果还是相同的 primary，相同的 secondary

1263
01:00:26,750 --> 01:00:28,130
client 的重试也许能正常工作

1264
01:00:28,130 --> 01:00:29,270
client 的重试也许能正常工作

1265
01:00:29,270 --> 01:00:31,490
因为网络没有丢弃消息

1266
01:00:31,490 --> 01:00:32,900
但是有意思的是 如果问题是某个 secondary 出现严重故障

1267
01:00:32,900 --> 01:00:35,510
但是有意思的是 如果问题是某个 secondary 出现严重故障

1268
01:00:35,510 --> 01:00:37,910
但是有意思的是 如果问题是某个 secondary 出现严重故障

1269
01:00:37,910 --> 01:00:41,150
我们希望 master 服务器重新配置那组副本

1270
01:00:41,150 --> 01:00:43,880
我们希望 master 服务器重新配置那组副本

1271
01:00:43,880 --> 01:00:46,820
丢掉不工作的 secondary

1272
01:00:46,820 --> 01:00:49,460
丢掉不工作的 secondary

1273
01:00:49,460 --> 01:00:50,900
master 会选择一个新的 primary 并递增版本号

1274
01:00:50,900 --> 01:00:52,610
master 会选择一个新的 primary 并递增版本号

1275
01:00:52,610 --> 01:00:54,890
master 会选择一个新的 primary 并递增版本号

1276
01:00:54,890 --> 01:00:56,750
接下来就有一组新的 primary、secondaries 和新版本号

1277
01:00:56,750 --> 01:01:00,170
接下来就有一组新的 primary、secondaries 和新版本号

1278
01:01:00,170 --> 01:01:02,720
还有一个不太健康的 secondary，它包含的是旧版本和过期的副本

1279
01:01:02,720 --> 01:01:04,160
还有一个不太健康的 secondary，它包含的是旧版本和过期的副本

1280
01:01:04,160 --> 01:01:07,000
因为它的版本比较旧 所以 master 永远不会将其误认为新版本

1281
01:01:07,000 --> 01:01:09,260
因为它的版本比较旧 所以 master 永远不会将其误认为新版本

1282
01:01:09,260 --> 01:01:10,640
但是论文中没有证据表明 我说的这些会立即发生

1283
01:01:10,640 --> 01:01:12,470
但是论文中没有证据表明 我说的这些会立即发生

1284
01:01:12,470 --> 01:01:15,110
论文上说 client 只是重试并希望它稍后能正常工作

1285
01:01:15,110 --> 01:01:17,180
论文上说 client 只是重试并希望它稍后能正常工作

1286
01:01:17,180 --> 01:01:19,610
如果 secondary 挂了，最终 master 会 ping 所有的 chunk 服务器

1287
01:01:19,610 --> 01:01:21,230
如果 secondary 挂了，最终 master 会 ping 所有的 chunk 服务器

1288
01:01:21,230 --> 01:01:23,990
如果 secondary 挂了，最终 master 会 ping 所有的 chunk 服务器

1289
01:01:23,990 --> 01:01:25,850
并可能会定义新的 primary 和 secondary 的集合 并增加版本号

1290
01:01:25,850 --> 01:01:30,770
并可能会定义新的 primary 和 secondary 的集合 并增加版本号

1291
01:01:30,770 --> 01:01:32,090
并可能会定义新的 primary 和 secondary 的集合 并增加版本号

1292
01:01:32,090 --> 01:01:35,590
但仅在（重试）以后

1293
01:01:40,380 --> 01:01:45,660
(提问) 租约是解决这个问题的答案

1294
01:01:45,660 --> 01:01:49,890
如果 master 认为 primary 已经挂了怎么办，因为它无法访问到它

1295
01:01:49,890 --> 01:01:52,500
如果 master 认为 primary 已经挂了怎么办，因为它无法访问到它

1296
01:01:52,500 --> 01:01:53,790
假设我们处于一种情况

1297
01:01:53,790 --> 01:01:55,470
在某个时候 master 说，你是 primary

1298
01:01:55,470 --> 01:01:58,110
在某个时候 master 说，你是 primary

1299
01:01:58,110 --> 01:01:59,940
然后 master 对它们定期执行 ping 操作 检查它是否还活着

1300
01:01:59,940 --> 01:02:01,260
然后 master 对它们定期执行 ping 操作 检查它是否还活着

1301
01:02:01,260 --> 01:02:02,610
如果它挂了 master 就会选择一个新的primary

1302
01:02:02,610 --> 01:02:05,160
如果它挂了 master 就会选择一个新的primary

1303
01:02:05,160 --> 01:02:07,080
master 会向 primary 发送一些 ping 消息

1304
01:02:07,080 --> 01:02:09,690
如果某个时候 primary 没有回应

1305
01:02:09,690 --> 01:02:11,850
你肯定会觉得 上帝 这个 primary 没有回应我的 ping

1306
01:02:11,850 --> 01:02:14,060
你肯定会觉得 上帝 这个 primary 没有回应我的 ping

1307
01:02:14,060 --> 01:02:16,560
如果你觉得 master 此时会先指定一个新的 primary 那就有问题了

1308
01:02:16,560 --> 01:02:20,790
如果你觉得 master 此时会先指定一个新的 primary 那就有问题了

1309
01:02:20,790 --> 01:02:23,820
如果你觉得 master 此时会先指定一个新的 primary 那就有问题了

1310
01:02:23,820 --> 01:02:26,130
为什么？

1311
01:02:26,130 --> 01:02:30,090
如果你只是这样简单这样搞的话 就会出问题

1312
01:02:30,090 --> 01:02:32,400
如果你只是这样简单这样搞的话 就会出问题

1313
01:02:32,400 --> 01:02:33,870
master 去 ping primary 没有得到回复的原因

1314
01:02:33,870 --> 01:02:35,400
master 去 ping primary 没有得到回复的原因

1315
01:02:35,400 --> 01:02:36,570
可能仅仅就只是 master 和 primary 之间的网络有点问题

1316
01:02:36,570 --> 01:02:38,190
可能仅仅就只是 master 和 primary 之间的网络有点问题

1317
01:02:38,190 --> 01:02:39,870
primary 可能还活着，master ping 它，但是数据包在网络中丢失了

1318
01:02:39,870 --> 01:02:41,220
primary 可能还活着，master ping 它，但是数据包在网络中丢失了

1319
01:02:41,220 --> 01:02:42,750
primary 可能还活着，master ping 它，但是数据包在网络中丢失了

1320
01:02:42,750 --> 01:02:44,280
master 此时可以与其他 client 通信

1321
01:02:44,280 --> 01:02:46,320
并且正在处理其他 client 的请求

1322
01:02:46,320 --> 01:02:49,140
如果 master 为那个 chunk 指定了​​一个新的 primary

1323
01:02:49,140 --> 01:02:51,840
如果 master 为那个 chunk 指定了​​一个新的 primary

1324
01:02:51,840 --> 01:02:54,600
就会出现两个 primary 处理写 但是却又两个不同的数据拷贝

1325
01:02:54,600 --> 01:02:56,340
就会出现两个 primary 处理写 但是却又两个不同的数据拷贝

1326
01:02:56,340 --> 01:02:58,830
最终会出现 2 个分道扬镳的数据

1327
01:02:58,830 --> 01:03:02,370
最终会出现 2 个分道扬镳的数据

1328
01:03:02,370 --> 01:03:07,560
这种具有两个 primary 处理请求

1329
01:03:07,560 --> 01:03:10,770
且不知道彼此的错误的情况 称为脑裂

1330
01:03:10,770 --> 01:03:12,570
且不知道彼此的错误的情况 称为脑裂

1331
01:03:12,570 --> 01:03:16,710
我在黑板上写出这个

1332
01:03:16,710 --> 01:03:19,440
这非常重要 它将会再次出现

1333
01:03:19,440 --> 01:03:23,160
这非常重要 它将会再次出现

1334
01:03:23,160 --> 01:03:24,540
这通常是由网络分区引起的

1335
01:03:24,540 --> 01:03:33,120
这是一种网络错误

1336
01:03:33,120 --> 01:03:34,260
其中 master 服务器无法与 primary 服务器通信

1337
01:03:34,260 --> 01:03:35,640
但 primary 可以与 client 端通信

1338
01:03:35,640 --> 01:03:38,330
这种部分网络故障 是构建这类存储系统中最难处理的问题之一

1339
01:03:38,330 --> 01:03:41,160
这种部分网络故障 是构建这类存储系统中最难处理的问题之一

1340
01:03:41,160 --> 01:03:44,760
这种部分网络故障 是构建这类存储系统中最难处理的问题之一

1341
01:03:44,760 --> 01:03:46,470
这种部分网络故障 是构建这类存储系统中最难处理的问题之一

1342
01:03:46,470 --> 01:03:49,170
好，那是问题所在

1343
01:03:49,170 --> 01:03:51,690
我们想避免为同一 chunk 错误地指定两个 primary 的情况

1344
01:03:51,690 --> 01:03:54,280
我们想避免为同一 chunk 错误地指定两个 primary 的情况

1345
01:03:54,280 --> 01:03:56,210
我们想避免为同一 chunk 错误地指定两个 primary 的情况

1346
01:03:56,210 --> 01:03:58,610
master 采取的方式是 当它指定一个 primary 时建立一个租约

1347
01:03:58,610 --> 01:04:00,920
master 采取的方式是 当它指定一个 primary 时建立一个租约

1348
01:04:00,920 --> 01:04:03,320
master 采取的方式是 当它指定一个 primary 时建立一个租约

1349
01:04:03,320 --> 01:04:05,590
租约是在一定时间内作为 primary 的权利

1350
01:04:05,590 --> 01:04:08,990
master 记得租约持续多长时间

1351
01:04:08,990 --> 01:04:12,500
master 记得租约持续多长时间

1352
01:04:12,500 --> 01:04:14,960
并且 primary 知道租约能持续多久

1353
01:04:14,960 --> 01:04:18,800
如果租约到期，primary 就知道到期了 它就会停止执行 client 的请求

1354
01:04:18,800 --> 01:04:20,570
如果租约到期，primary 就知道到期了 它就会停止执行 client 的请求

1355
01:04:20,570 --> 01:04:23,150
租约到期后 它将忽略或拒绝 client 请求

1356
01:04:23,150 --> 01:04:24,830
租约到期后 它将忽略或拒绝 client 请求

1357
01:04:24,830 --> 01:04:27,800
因此，如果 master 不能与 primary 通信

1358
01:04:27,800 --> 01:04:29,570
master 将会在租约到期后指定一个新的 primary

1359
01:04:29,570 --> 01:04:31,220
master 将会在租约到期后指定一个新的 primary

1360
01:04:31,220 --> 01:04:33,830
master 将会在租约到期后指定一个新的 primary

1361
01:04:33,830 --> 01:04:35,270
master 将会在租约到期后指定一个新的 primary

1362
01:04:35,270 --> 01:04:37,670
master 必须要等待租约到期

1363
01:04:37,670 --> 01:04:40,010
60秒的租约到期后 可以确信旧的 primary 已经停止了它的角色

1364
01:04:40,010 --> 01:04:41,660
60秒的租约到期后 可以确信旧的 primary 已经停止了它的角色

1365
01:04:41,660 --> 01:04:44,510
60秒的租约到期后 可以确信旧的 primary 已经停止了它的角色

1366
01:04:44,510 --> 01:04:46,160
那时候 master 就可以安全地指定新的 primary

1367
01:04:46,160 --> 01:04:50,810
而不会产生这种可怕的裂脑情况

1368
01:04:50,810 --> 01:04:54,460
而不会产生这种可怕的裂脑情况

1369
01:05:02,299 --> 01:05:14,119
(提问) 问题是说 为什么指定一个新的 primary 是坏的（设计）

1370
01:05:14,119 --> 01:05:15,920
(提问) 问题是说 为什么指定一个新的 primary 是坏的（设计）

1371
01:05:15,920 --> 01:05:18,079
既然 client 总是先问 master

1372
01:05:18,079 --> 01:05:20,059
master 改变主意后可先把 client 定向到新的 primary

1373
01:05:20,059 --> 01:05:22,819
master 改变主意后可先把 client 定向到新的 primary

1374
01:05:22,819 --> 01:05:26,390
原因之一是 client 会通过缓存提高效率

1375
01:05:26,390 --> 01:05:28,429
原因之一是 client 会通过缓存提高效率

1376
01:05:28,429 --> 01:05:31,279
client 会在短时间内缓存 primary 的身份信息

1377
01:05:31,279 --> 01:05:34,009
client 会在短时间内缓存 primary 的身份信息

1378
01:05:34,009 --> 01:05:37,489
即使没有缓存，还有一种可怕的情况是这样的

1379
01:05:37,489 --> 01:05:40,640
比如我是master，你问我 primary 是谁

1380
01:05:40,640 --> 01:05:43,449
我告诉你那个谁谁谁是是 primary

1381
01:05:43,449 --> 01:05:46,369
我告诉你那个谁谁谁是是 primary

1382
01:05:46,369 --> 01:05:47,809
该消息在网络中传递

1383
01:05:47,809 --> 01:05:50,630
然后我发现 primary 出了故障

1384
01:05:50,630 --> 01:05:52,160
然后我发现 primary 出了故障

1385
01:05:52,160 --> 01:05:53,269
然后我发现 primary 出了故障

1386
01:05:53,269 --> 01:05:55,219
然后我又指定了个新的 primary

1387
01:05:55,219 --> 01:05:56,209
我发信息给你 说你是primary

1388
01:05:56,209 --> 01:05:57,619
然后我开始回答其他 client 谁是这个 primary

1389
01:05:57,619 --> 01:06:00,349
然后我开始回答其他 client 谁是这个 primary

1390
01:06:00,349 --> 01:06:01,400
比如说那个服务器是 primary

1391
01:06:01,400 --> 01:06:03,019
然而给你的信息仍在传递中

1392
01:06:03,019 --> 01:06:04,880
你收到消息里的仍然是旧primary

1393
01:06:04,880 --> 01:06:07,130
你会觉得 我刚从 master 那里得到这个 primary 我要去和它通信

1394
01:06:07,130 --> 01:06:10,219
你会觉得 我刚从 master 那里得到这个 primary 我要去和它通信

1395
01:06:10,219 --> 01:06:11,630
你会觉得 我刚从 master 那里得到这个 primary 我要去和它通信

1396
01:06:11,630 --> 01:06:13,459
如果没有一些更聪明的机制

1397
01:06:13,459 --> 01:06:14,859
你不可能意识到（primary是旧的）

1398
01:06:14,859 --> 01:06:16,849
即使你刚刚从 master 那里获得了这些信息

1399
01:06:16,849 --> 01:06:19,309
即使你刚刚从 master 那里获得了这些信息

1400
01:06:19,309 --> 01:06:21,679
它也已经过时

1401
01:06:21,679 --> 01:06:24,410
而且如果该 primary 接受了你的修改请求 回复你 success

1402
01:06:24,410 --> 01:06:27,920
而且如果该 primary 接受了你的修改请求 回复你 success

1403
01:06:27,920 --> 01:06:35,349
就会得到两个相互冲突的副本

1404
01:06:35,890 --> 01:06:38,890
(提问)
翻译: allen/adam (窃取成果追究法律责任)
翻译项目地址

1405
01:06:41,910 --> 01:06:50,710
请再说一次。你有一个新文件，且没有备份

1406
01:06:50,710 --> 01:06:53,410
好的，如果你有一个新文件，没有备份

1407
01:06:53,410 --> 01:06:55,180
甚至是已有文件，没有备份

1408
01:06:55,180 --> 01:06:58,090
你将会执行一遍黑板上画的路线

1409
01:06:58,090 --> 01:07:00,130
你将会执行一遍黑板上画的路线

1410
01:07:00,130 --> 01:07:02,140
master 会收到 client 的要求说

1411
01:07:02,140 --> 01:07:04,270
我想追加这个文件

1412
01:07:04,270 --> 01:07:06,430
我猜 master 会首先发现

1413
01:07:06,430 --> 01:07:08,200
没有任何 chunk 与该文件关联

1414
01:07:08,200 --> 01:07:11,710
它将创造一个新的 chunk 标识符

1415
01:07:11,710 --> 01:07:13,570
它将创造一个新的 chunk 标识符

1416
01:07:13,570 --> 01:07:15,730
可能通过调用随机数生成器 然后在其块信息表中查看

1417
01:07:15,730 --> 01:07:17,920
可能通过调用随机数生成器 然后在其块信息表中查看

1418
01:07:17,920 --> 01:07:20,080
发现，天哪 我没有关于那个 chunk 的任何信息

1419
01:07:20,080 --> 01:07:22,030
发现，天哪 我没有关于那个 chunk 的任何信息

1420
01:07:22,030 --> 01:07:24,730
于是它会创建一个新记录

1421
01:07:24,730 --> 01:07:26,410
它一定是一段特殊分支的代码

1422
01:07:26,410 --> 01:07:28,720
我不知道任何版本号

1423
01:07:28,720 --> 01:07:30,850
这个 chunk 不存在，我要创建一个新的版本号1

1424
01:07:30,850 --> 01:07:32,740
这个 chunk 不存在，我要创建一个新的版本号1

1425
01:07:32,740 --> 01:07:35,380
再随机选择一个 primary 和一组 secondaries 并告诉它们

1426
01:07:35,380 --> 01:07:37,900
再随机选择一个 primary 和一组 secondaries 并告诉它们

1427
01:07:37,900 --> 01:07:40,660
你们对此新的空 chunk 负责，请开始工作

1428
01:07:40,660 --> 01:07:47,020
论文说默认情况下 每个块有三个备份

1429
01:07:47,020 --> 01:07:50,110
通常是一个 primary 和两个 secondaries

1430
01:07:50,110 --> 01:07:52,710
通常是一个 primary 和两个 secondaries

1431
01:08:03,930 --> 01:08:13,270
也许这里最重要的是重复我们几分钟前的讨论

1432
01:08:13,270 --> 01:08:16,299
也许这里最重要的是重复我们几分钟前的讨论

1433
01:08:16,299 --> 01:08:19,890
也许这里最重要的是重复我们几分钟前的讨论

1434
01:08:21,540 --> 01:08:32,140
GFS 是有意被创造的

1435
01:08:32,140 --> 01:08:33,790
我们有这些追加的记录 且有三个备份

1436
01:08:33,790 --> 01:08:41,009
我们有这些追加的记录 且有三个备份

1437
01:08:41,009 --> 01:08:43,779
client 可能会发送来一个记录 A 的追加

1438
01:08:43,779 --> 01:08:46,719
client 可能会发送来一个记录 A 的追加

1439
01:08:46,719 --> 01:08:49,569
所有三个备份，primary 和两个 secondaries 成功追加了数据

1440
01:08:49,569 --> 01:08:52,120
所有三个备份，primary 和两个 secondaries 成功追加了数据

1441
01:08:52,120 --> 01:08:54,069
也许这个 chunk 中第一个记录是 A

1442
01:08:54,069 --> 01:08:55,689
也许这个 chunk 中第一个记录是 A

1443
01:08:55,689 --> 01:08:57,930
它们都一致，因为它们都执行了追加

1444
01:08:57,930 --> 01:09:00,040
假设另一个 client 进来说我要追加记录 B

1445
01:09:00,040 --> 01:09:03,339
假设另一个 client 进来说我要追加记录 B

1446
01:09:03,339 --> 01:09:06,250
但消息传递给某个备份时丢失

1447
01:09:06,250 --> 01:09:08,410
因为网络某种错误

1448
01:09:08,410 --> 01:09:11,589
但另外两个备份拿到了消息

1449
01:09:11,589 --> 01:09:13,390
但另外两个备份拿到了消息

1450
01:09:13,390 --> 01:09:14,380
其中一个是 primary 另一个是 secondary

1451
01:09:14,380 --> 01:09:16,000
它们都在文件中做了追加

1452
01:09:16,000 --> 01:09:19,390
所以现在我们有两个备份有记录

1453
01:09:19,390 --> 01:09:21,759
另一个没有任何记录

1454
01:09:21,759 --> 01:09:26,410
然后可能有第三个 client 想要追加 C

1455
01:09:26,410 --> 01:09:29,109
然后可能有第三个 client 想要追加 C

1456
01:09:29,109 --> 01:09:30,460
记得这是 primary

1457
01:09:30,460 --> 01:09:32,738
primary 选择偏移量并告诉 secondary

1458
01:09:32,738 --> 01:09:35,109
primary 选择偏移量并告诉 secondary

1459
01:09:35,109 --> 01:09:38,620
把记录 C 写在这个 chunk 里

1460
01:09:38,620 --> 01:09:43,450
他们都在这里写C

1461
01:09:43,450 --> 01:09:45,040
对于 B 的 client 来说

1462
01:09:45,040 --> 01:09:47,830
它的请求收到 error 回复

1463
01:09:47,830 --> 01:09:50,439
它的请求收到 error 回复

1464
01:09:50,439 --> 01:09:53,770
它会重新发送请求

1465
01:09:53,770 --> 01:09:56,020
因此现在要求追加记录 B 的客户端

1466
01:09:56,020 --> 01:09:57,640
将再次请求追加记录 B

1467
01:09:57,640 --> 01:10:00,340
也许这次信息没有在网络中丢失

1468
01:10:00,340 --> 01:10:05,040
所有三个备份追加了记录 B

1469
01:10:05,040 --> 01:10:07,239
对，这些备份都活着

1470
01:10:07,239 --> 01:10:09,870
都拥有最新的版本号

1471
01:10:09,870 --> 01:10:13,150
如果 client 执行读的话

1472
01:10:13,150 --> 01:10:16,830
读取到的内容取决于读取哪个副本

1473
01:10:17,820 --> 01:10:20,020
读取到的内容取决于读取哪个副本

1474
01:10:20,020 --> 01:10:22,929
它将总共看到所有三个记录

1475
01:10:22,929 --> 01:10:25,030
但它会看到不同的顺序 具体取决于读取了哪个副本

1476
01:10:25,030 --> 01:10:28,750
但它会看到不同的顺序 具体取决于读取了哪个副本

1477
01:10:28,750 --> 01:10:31,870
我会看到 A B C，然后一个重复的 B

1478
01:10:31,870 --> 01:10:33,730
所以如果它读取此副本，将会看到B，然后C

1479
01:10:33,730 --> 01:10:36,969
如果它读取这个备份

1480
01:10:36,969 --> 01:10:39,340
它会看到A，然后一个空白

1481
01:10:39,340 --> 01:10:41,920
然后是 C 然后是 B

1482
01:10:41,920 --> 01:10:44,199
所以如果你在这里读，你会看到 C，然后是 B

1483
01:10:44,199 --> 01:10:47,320
在这里你看到 B 然后 C

1484
01:10:47,320 --> 01:10:49,350
不同的读请求会看到不同的结果

1485
01:10:49,350 --> 01:10:52,330
也许最糟糕的情况是

1486
01:10:52,330 --> 01:10:54,489
一些 client 端从 primary 服务器收到错误

1487
01:10:54,489 --> 01:10:58,360
因为其中一个 secondary 未能执行追加操作

1488
01:10:58,360 --> 01:11:00,159
因为其中一个 secondary 未能执行附加操作

1489
01:11:00,159 --> 01:11:02,260
然后 client 端在重新发送请求之前挂掉

1490
01:11:02,260 --> 01:11:04,030
所以你可能进入这种情形

1491
01:11:04,030 --> 01:11:07,030
你的记录 D

1492
01:11:07,030 --> 01:11:11,890
出现在某些副本中 而在其他副本则完全没有

1493
01:11:11,890 --> 01:11:13,750
出现在某些副本中 而在其他副本则完全没有

1494
01:11:13,750 --> 01:11:16,420
所以在这个方案下 primary 返回成功就具有很好的性质

1495
01:11:16,420 --> 01:11:19,659
所以在这个方案下 primary 返回成功就具有很好的性质

1496
01:11:19,659 --> 01:11:23,620
所以在这个方案下 primary 返回成功就具有很好的性质

1497
01:11:23,620 --> 01:11:26,800
但是对于 primary 返回失败的追加操作 就有点糟糕了

1498
01:11:26,800 --> 01:11:29,469
但是对于 primary 返回失败的追加操作 就有点糟糕了

1499
01:11:29,469 --> 01:11:32,949
但是对于 primary 返回失败的追加操作 就有点糟糕了

1500
01:11:32,949 --> 01:11:35,530
追加的记录 副本都完全不同 一组完全不同的副本

1501
01:11:35,530 --> 01:11:37,540
追加的记录 副本都完全不同 一组完全不同的副本

1502
01:11:37,540 --> 01:11:40,440
(提问)
翻译: allen/adam (窃取成果追究法律责任)
翻译项目地址

1503
01:11:44,400 --> 01:11:46,660
论文里说 client 从流程的最开始就开始

1504
01:11:46,660 --> 01:11:49,090
论文里说 client 从流程的最开始就开始

1505
01:11:49,090 --> 01:11:51,310
再次询问 master 该文件中的最后一个 chunk 是什么

1506
01:11:51,310 --> 01:11:54,190
再次询问 master 该文件中的最后一个 chunk 是什么

1507
01:11:54,190 --> 01:11:55,240
因为如果其他人在文件中追加 这就可能会发生变化

1508
01:11:55,240 --> 01:11:56,710
因为如果其他人在文件中追加 这就可能会发生变化

1509
01:11:56,710 --> 01:12:02,820
(提问)
翻译: allen/adam (窃取成果追究法律责任)
翻译项目地址

1510
01:12:17,760 --> 01:12:20,290
我看不懂设计者心里想的啥

1511
01:12:20,290 --> 01:12:22,720
我认为该系统可以设计成使副本保持精确同步

1512
01:12:22,720 --> 01:12:24,760
我认为该系统可以设计成使副本保持精确同步

1513
01:12:24,760 --> 01:12:27,640
我认为该系统可以设计成使副本保持精确同步

1514
01:12:27,640 --> 01:12:30,820
这是真的，你将在实验 2 和 3 中实现它

1515
01:12:30,820 --> 01:12:33,100
你们将会设计一个进行复制的系统

1516
01:12:33,100 --> 01:12:34,930
你们将会设计一个进行复制的系统

1517
01:12:34,930 --> 01:12:36,880
它能真正的让副本保持同步

1518
01:12:36,880 --> 01:12:38,490
并且你将了解到 你需要采取多种技巧才能做到这一点

1519
01:12:38,490 --> 01:12:41,020
并且你将了解到 你需要采取多种技巧才能做到这一点

1520
01:12:41,020 --> 01:12:43,180
并且你将了解到 你需要采取多种技巧才能做到这一点

1521
01:12:43,180 --> 01:12:46,150
其中之一是 如果你希望副本保持同步 就必须遵循的一个规则

1522
01:12:46,150 --> 01:12:47,740
其中之一是 如果你希望副本保持同步 就必须遵循的一个规则

1523
01:12:47,740 --> 01:12:50,410
其中之一是 如果你希望副本保持同步 就必须遵循的一个规则

1524
01:12:50,410 --> 01:12:53,320
规则是你不能将这种部分操作 仅应用于部分服务器 而不是所有服务器

1525
01:12:53,320 --> 01:12:54,490
规则是你不能将这种部分操作 仅应用于部分服务器 而不是所有服务器

1526
01:12:54,490 --> 01:12:56,410
这意味着必须有某种机制 即使 client 死了

1527
01:12:56,410 --> 01:12:58,630
这意味着必须有某种机制

1528
01:12:58,630 --> 01:13:00,130
比如说 client 挂了，系统会说：等等，这个操作我还没完成

1529
01:13:00,130 --> 01:13:01,900
比如说 client 挂了，系统会说：等等，这个操作我还没完成

1530
01:13:01,900 --> 01:13:04,060
比如说 client 挂了，系统会说：等等，这个操作我还没完成

1531
01:13:04,060 --> 01:13:07,390
因此，你构建的系统中 primary 实际上要确保副本获得了每条消息

1532
01:13:07,390 --> 01:13:11,820
因此，你构建的系统中 primary 实际上要确保副本获得了每条消息

1533
01:13:11,820 --> 01:13:15,360
因此，你构建的系统中 primary 实际上要确保副本获得了每条消息

1534
01:13:29,460 --> 01:13:34,390
如果第一次写 B 失败

1535
01:13:34,390 --> 01:13:37,739
你认为 C 应该写在 B 的位置 然而它并没有

1536
01:13:37,770 --> 01:13:40,450
你认为 C 应该写在 B 的位置 然而它并没有

1537
01:13:40,450 --> 01:13:42,130
但是这个系统实际运行的方式是 primary 将 C 添加到 chunk 的末尾

1538
01:13:42,130 --> 01:13:46,690
但是这个系统实际运行的方式是 primary 将 C 添加到 chunk 的末尾

1539
01:13:46,690 --> 01:13:57,730
在 B 的后面

1540
01:13:57,730 --> 01:13:59,890
这样做的原因之一是在写 C 的时候

1541
01:13:59,890 --> 01:14:01,480
这样做的原因之一是在写 C 的时候

1542
01:14:01,480 --> 01:14:03,010
primary 实际上可能不知道 B 的命运是什么

1543
01:14:03,010 --> 01:14:05,710
因为我们遇到了多个同时请求追加的 client

1544
01:14:05,710 --> 01:14:07,510
因为我们遇到了多个同时请求追加的 client

1545
01:14:07,510 --> 01:14:10,600
为了获得高性能

1546
01:14:10,600 --> 01:14:14,890
你希望 priamry 服务器启动执行 B 的追加操作

1547
01:14:14,890 --> 01:14:17,860
一旦得知下一步结束 就告诉所有人把 C 写在那个offset之后

1548
01:14:17,860 --> 01:14:20,170
一旦得知下一步结束 就告诉所有人把 C 写在那个offset之后

1549
01:14:20,170 --> 01:14:21,750
这样所有这些事情就可以并行地发生

1550
01:14:21,750 --> 01:14:25,270
通过减慢速度 primary 可以断定 B 完全失败了

1551
01:14:25,270 --> 01:14:31,750
通过减慢速度 primary 可以断定 B 完全失败了

1552
01:14:31,750 --> 01:14:33,760
通过减慢速度 primary 可以断定 B 完全失败了

1553
01:14:33,760 --> 01:14:35,560
然后发送另一轮消息请求撤消 B 的写操作

1554
01:14:35,560 --> 01:14:39,970
然后发送另一轮消息请求撤消 B 的写操作

1555
01:14:39,970 --> 01:14:43,360
那样会更复杂 更慢

1556
01:14:43,360 --> 01:14:45,880
同样 这样做的理由是 这个设计非常简单

1557
01:14:45,880 --> 01:14:48,730
同样 这样做的理由是 这个设计非常简单

1558
01:14:48,730 --> 01:14:53,820
但它会暴露给应用程序一些奇怪的东西

1559
01:14:53,820 --> 01:14:58,060
我们希望可以相对容易地编写应用程序

1560
01:14:58,060 --> 01:14:59,680
我们希望可以相对容易地编写应用程序

1561
01:14:59,680 --> 01:15:01,750
去容忍记录的顺序不同或别的

1562
01:15:01,750 --> 01:15:04,960
去容忍记录的顺序不同或别的

1563
01:15:04,960 --> 01:15:08,800
如果他们不能容忍 应用程序可以

1564
01:15:08,800 --> 01:15:11,080
要么自己安排选择一个顺序

1565
01:15:11,080 --> 01:15:13,300
要么自己安排选择一个顺序

1566
01:15:13,300 --> 01:15:14,860
在文件或其他内容中写入你知道的序号

1567
01:15:14,860 --> 01:15:17,739
在文件或其他内容中写入你知道的序号

1568
01:15:17,739 --> 01:15:20,140
如果应用程序真的对顺序非常敏感

1569
01:15:20,140 --> 01:15:21,910
你就不应该从不同 client 端到同一文件的并发追加操作

1570
01:15:21,910 --> 01:15:24,220
你就不应该从不同 client 端到同一文件的并发追加操作

1571
01:15:24,220 --> 01:15:27,520
你就不应该从不同 client 端到同一文件的并发追加操作

1572
01:15:27,520 --> 01:15:29,410
对于顺序很重要的文件 例如说电影文件

1573
01:15:29,410 --> 01:15:31,390
对于顺序很重要的文件 例如说电影文件

1574
01:15:31,390 --> 01:15:32,750
你可不想把电影文件中的数据弄颠倒

1575
01:15:32,750 --> 01:15:35,840
你可不想把电影文件中的数据弄颠倒

1576
01:15:35,840 --> 01:15:37,550
那你就只用一个 client 连续地将电影写入文件

1577
01:15:37,550 --> 01:15:40,100
那你就只用一个 client 连续地将电影写入文件

1578
01:15:40,100 --> 01:15:45,040
而不是并发地追加记录

1579
01:15:49,150 --> 01:15:56,680
好

1580
01:15:56,680 --> 01:16:04,400
有人问如何把这种设计 变成强一致性的系统

1581
01:16:04,400 --> 01:16:06,770
有人问如何把这种设计 变成强一致性的系统

1582
01:16:06,770 --> 01:16:08,120
有人问如何把这种设计 变成强一致性的系统

1583
01:16:08,120 --> 01:16:11,960
它的一致性更接近 我们的单服务器模型

1584
01:16:11,960 --> 01:16:13,790
它不会让人产生令人吃惊的结果

1585
01:16:13,790 --> 01:16:18,680
它不会让人产生令人吃惊的结果

1586
01:16:18,680 --> 01:16:20,180
实际上我不知道怎么做 因为这需要全新的复杂设计

1587
01:16:20,180 --> 01:16:22,340
实际上我不知道怎么做 因为这需要全新的复杂设计

1588
01:16:22,340 --> 01:16:24,560
目前尚不清楚如何将 GFS 变成这样

1589
01:16:24,560 --> 01:16:26,330
但我可以为你列出一些你需要考虑的事情

1590
01:16:26,330 --> 01:16:27,440
如果你想将 GFS 升级到强一致性系统

1591
01:16:27,440 --> 01:16:32,350
如果你想将 GFS 升级到强一致性系统

1592
01:16:32,350 --> 01:16:34,460
如果你想将 GFS 升级到强一致性系统

1593
01:16:34,460 --> 01:16:37,370
一个（要考虑的）是你可能

1594
01:16:37,370 --> 01:16:40,940
需要让 primary 来检测重复的请求

1595
01:16:40,940 --> 01:16:43,460
这样当第二个 B 到达 primary 能够知晓

1596
01:16:43,460 --> 01:16:44,960
这样当第二个 B 到达 primary 能够知晓

1597
01:16:44,960 --> 01:16:47,030
哦，实际上我们早些时候已看到了该请求

1598
01:16:47,030 --> 01:16:50,570
并且已经执行了或没有执行

1599
01:16:50,570 --> 01:16:52,160
并且要确保 B 不会在文件中出现两次

1600
01:16:52,160 --> 01:16:54,140
所以你需要具备检测重复的能力

1601
01:16:54,140 --> 01:16:59,570
另一个问题 如果一个 secondary 扮演 secondary

1602
01:16:59,570 --> 01:17:02,660
另一个问题 如果一个 secondary 就只是次要的

1603
01:17:02,660 --> 01:17:05,000
你真的需要设计系统

1604
01:17:05,000 --> 01:17:06,920
（翻译：Allen, Adam）
（https://github.com/ivanallen/thor）
所以，如果 primary 告诉 secondary 做某事

1605
01:17:06,920 --> 01:17:08,180
所以，如果 primary 告诉 secondary 做某事

1606
01:17:08,180 --> 01:17:10,010
secondary 就必须得真的执行了 而不只是返回错误

1607
01:17:10,010 --> 01:17:12,560
secondary 就必须得真的执行了 而不只是返回错误

1608
01:17:12,560 --> 01:17:15,260
对于一个严格一致的系统

1609
01:17:15,260 --> 01:17:16,880
如果 secondary 能够随意终止 primary 请求而没有付出任何代价

1610
01:17:16,880 --> 01:17:20,210
如果 secondary 能够随意终止 primary 请求而没有付出任何代价

1611
01:17:20,210 --> 01:17:24,170
这样是不行的 所以我认为 secondary 必须接受并执行请求

1612
01:17:24,170 --> 01:17:25,730
这样是不行的 所以我认为 secondary 必须接受并执行请求

1613
01:17:25,730 --> 01:17:28,460
或者如果 secondary 磁盘有某种永久性损坏

1614
01:17:28,460 --> 01:17:30,050
或者如果 secondary 磁盘有某种永久性损坏

1615
01:17:30,050 --> 01:17:32,180
例如错误地拔出了磁盘

1616
01:17:32,180 --> 01:17:34,160
你需要一种机制将 secondary 从系统中移除

1617
01:17:34,160 --> 01:17:36,200
你需要一种机制将 secondary 从系统中移除

1618
01:17:36,200 --> 01:17:39,140
这样 primary 可以和剩下的 secondary 继续工作

1619
01:17:39,140 --> 01:17:41,750
但这两点 GFS 都没有做 至少没有马上做

1620
01:17:41,750 --> 01:17:44,950
但这两点 GFS 都没有做 至少没有马上做

1621
01:17:45,200 --> 01:17:49,350
所以这也意味着 当 primary 要求 secondary 追加什么时

1622
01:17:49,350 --> 01:17:50,910
所以这也意味着 当 primary 要求 secondary 追加什么时

1623
01:17:50,910 --> 01:17:52,800
secondary 必须小心不要将数据暴露给请求者

1624
01:17:52,800 --> 01:17:54,810
secondary 必须小心不要将数据暴露给请求者

1625
01:17:54,810 --> 01:17:57,600
直到 primary 确信所有 secondary 都能够执行追加操作为止

1626
01:17:57,600 --> 01:17:59,250
直到 primary 确信所有 secondary 都能够执行追加操作为止

1627
01:17:59,250 --> 01:18:02,610
直到 primary 确信所有 secondary 都能够执行追加操作为止

1628
01:18:02,610 --> 01:18:05,400
因此你可能需要把写操作分成多个阶段

1629
01:18:05,400 --> 01:18:06,900
第一阶段，primary 请求 secondary

1630
01:18:06,900 --> 01:18:09,030
我真的想让你执行此操作 你能执行此操作吗

1631
01:18:09,030 --> 01:18:11,310
我真的想让你执行此操作 你能执行此操作吗

1632
01:18:11,310 --> 01:18:13,560
但此时 secondary 并不是真的执行此操作

1633
01:18:13,560 --> 01:18:15,810
如果所有 secondary 都答应能够进行操作

1634
01:18:15,810 --> 01:18:17,670
如果所有 secondary 都答应能够进行操作

1635
01:18:17,670 --> 01:18:20,550
只有这个时候 primary 说

1636
01:18:20,550 --> 01:18:22,080
好的去吧，这样每个 secondary 都将执行你所承诺的操作

1637
01:18:22,080 --> 01:18:24,570
好的去吧，这样每个 secondary 都将执行你所承诺的操作

1638
01:18:24,570 --> 01:18:27,210
这是现实世界中很多强一致的系统的工作方式

1639
01:18:27,210 --> 01:18:28,950
这是现实世界中很多强一致的系统的工作方式

1640
01:18:28,950 --> 01:18:32,540
这种技巧称为两阶段提交

1641
01:18:32,630 --> 01:18:34,590
另一个问题是，如果 primary 崩溃

1642
01:18:34,590 --> 01:18:38,370
但已经有最后的一组 primary 发给 secondary 的操作开始了

1643
01:18:38,370 --> 01:18:40,410
但已经有最后的一组 primary 发给 secondary 的操作开始了

1644
01:18:40,410 --> 01:18:44,340
但已经有最后的一组 primary 发给 secondary 的操作开始了

1645
01:18:44,340 --> 01:18:46,890
而 primary 在确定所有 secondary 拿到拷贝之前就崩溃了

1646
01:18:46,890 --> 01:18:48,900
而 primary 在确定所有 secondary 拿到拷贝之前就崩溃了

1647
01:18:48,900 --> 01:18:51,660
而 primary 在确定所有 secondary 拿到拷贝之前就崩溃了

1648
01:18:51,660 --> 01:18:54,510
所以如果 primary 崩溃

1649
01:18:54,510 --> 01:18:56,040
其中一个 secondary 将接任新的 primary

1650
01:18:56,040 --> 01:18:57,780
其中一个 secondary 将接任新的 primary

1651
01:18:57,780 --> 01:19:01,200
但是在那时 新的 primary 和其余的 secondary

1652
01:19:01,200 --> 01:19:03,240
但是在那时 新的 primary 和其余的 secondary

1653
01:19:03,240 --> 01:19:05,580
在最后的几次操作中可能会有所不同

1654
01:19:05,580 --> 01:19:07,200
因为也许其中一些在 primary 服务器崩溃之前没有收到消息

1655
01:19:07,200 --> 01:19:09,030
因为也许其中一些在 primary 服务器崩溃之前没有收到消息

1656
01:19:09,030 --> 01:19:11,490
因此，新的 primary 开始时必须与 secondary 显式地重新同步

1657
01:19:11,490 --> 01:19:15,300
因此，新的 primary 开始时必须与 secondary 显式地重新同步

1658
01:19:15,300 --> 01:19:17,010
以确保他们的操作历史的最后几个步骤是一样的

1659
01:19:17,010 --> 01:19:20,750
以确保他们的操作历史的最后几个步骤是一样的

1660
01:19:21,080 --> 01:19:24,060
最后，为了解决这个问题

1661
01:19:24,060 --> 01:19:25,530
你知道 有时候 secondary 会有所不同

1662
01:19:25,530 --> 01:19:28,500
或 client 可能会从 master 那里得到过时的指示

1663
01:19:28,500 --> 01:19:31,200
或 client 可能会从 master 那里得到过时的指示

1664
01:19:31,200 --> 01:19:33,000
或 client 可能会从 master 那里得到过时的指示

1665
01:19:33,000 --> 01:19:35,940
所以 要么所有 client 都发送读请求给 primary

1666
01:19:35,940 --> 01:19:38,010
所以 要么所有 client 都发送读请求给 primary

1667
01:19:38,010 --> 01:19:41,490
因为只有 primary 才可能知道实际发生了哪些操作

1668
01:19:41,490 --> 01:19:43,860
因为只有 primary 才可能知道实际发生了哪些操作

1669
01:19:43,860 --> 01:19:45,570
要么我们需要给 secondary 一个租约系统

1670
01:19:45,570 --> 01:19:47,400
就像 primary 那样

1671
01:19:47,400 --> 01:19:50,700
因此，众所周知

1672
01:19:50,700 --> 01:19:55,030
当 secondary 能或不能合法回应 client 时

1673
01:19:55,030 --> 01:19:56,650
我要意识到这些事情必须在此系统中修复

1674
01:19:56,650 --> 01:19:58,570
我要意识到这些事情必须在此系统中修复

1675
01:19:58,570 --> 01:20:00,550
你需要更多复杂的技术使其具有强一致性

1676
01:20:00,550 --> 01:20:02,230
你需要更多复杂的技术使其具有强一致性

1677
01:20:02,230 --> 01:20:05,050
你需要更多复杂的技术使其具有强一致性

1678
01:20:05,050 --> 01:20:08,020
我通过思考lab内容得到这份列表

1679
01:20:08,020 --> 01:20:09,940
你最终会做 我刚才所说的所有事情

1680
01:20:09,940 --> 01:20:12,099
你最终会做 我刚才所说的所有事情

1681
01:20:12,099 --> 01:20:13,989
它是 lab2，lab3 的一部分

1682
01:20:13,989 --> 01:20:18,940
你需要建立严格一致的系统

1683
01:20:18,940 --> 01:20:21,099
好吧，让我花一分钟的时间

1684
01:20:21,099 --> 01:20:23,079
笔记中有一个链接

1685
01:20:23,079 --> 01:20:25,840
一个回顾性访谈，关于 GFS 在 Google 生涯的前五年或十年中表现的如何出色

1686
01:20:25,840 --> 01:20:28,389
一个回顾性访谈，关于 GFS 在 Google 生涯的前五年或十年中表现的如何出色

1687
01:20:28,389 --> 01:20:32,770
一个回顾性访谈，关于 GFS 在 Google 生涯的前五年或十年中表现的如何出色

1688
01:20:32,770 --> 01:20:36,219
最终的总结是 它取得了巨大的成功

1689
01:20:36,219 --> 01:20:37,690
最终的总结是 它取得了巨大的成功

1690
01:20:37,690 --> 01:20:40,570
许多 Google 的应用都使用了它

1691
01:20:40,570 --> 01:20:43,000
许多 Google 基础架构 例如 BigTable 都构建在它之上

1692
01:20:43,000 --> 01:20:45,250
许多 Google 基础架构 例如 BigTable 都构建在它之上

1693
01:20:45,250 --> 01:20:47,409
许多 Google 基础架构 例如 BigTable 都构建在它之上

1694
01:20:47,409 --> 01:20:50,190
MapReduce 也是这样

1695
01:20:50,190 --> 01:20:54,550
它在 Google 被广泛使用

1696
01:20:54,550 --> 01:20:57,460
可能最严重的局限是

1697
01:20:57,460 --> 01:20:59,289
只有一个 master，它必须为每个 chunk 每个文件构造一个表条目

1698
01:20:59,289 --> 01:21:01,510
只有一个 master，它必须为每个 chunk 每个文件构造一个表条目

1699
01:21:01,510 --> 01:21:04,510
这意味着随着 GFS 的使用量增加

1700
01:21:04,510 --> 01:21:06,820
它们涉及的文件越来越多

1701
01:21:06,820 --> 01:21:08,650
主机就用完了内存

1702
01:21:08,650 --> 01:21:11,980
用完了 RAM 来存储文件

1703
01:21:11,980 --> 01:21:13,690
你可以增加更多的 RAM

1704
01:21:13,690 --> 01:21:15,010
但是一台计算机可以拥有多少 RAM 是有限度的

1705
01:21:15,010 --> 01:21:18,309
但是一台计算机可以拥有多少 RAM 是有限度的

1706
01:21:18,309 --> 01:21:19,599
因此这是人们遇到的最直接的问题

1707
01:21:19,599 --> 01:21:24,159
此外，单个 master 服务器上的负载来自成千上万个 client

1708
01:21:24,159 --> 01:21:25,869
此外，单个 master 服务器上的负载来自成千上万个 client

1709
01:21:25,869 --> 01:21:28,030
这种情况越来越严重

1710
01:21:28,030 --> 01:21:29,650
在 master 中 cpu 每秒只能处理数百个请求

1711
01:21:29,650 --> 01:21:30,940
在 master 中 cpu 每秒只能处理数百个请求

1712
01:21:30,940 --> 01:21:33,070
特别是硬盘的写操作

1713
01:21:33,070 --> 01:21:35,739
很快就会有过多的 client

1714
01:21:35,739 --> 01:21:39,880
很快就会有过多的 client

1715
01:21:39,880 --> 01:21:41,409
另一个问题是 一些应用程序发现

1716
01:21:41,409 --> 01:21:44,260
很难处理这种有点奇怪的语义

1717
01:21:44,260 --> 01:21:47,500
最后一个问题是

1718
01:21:47,500 --> 01:21:49,599
master 服务器的故障切换并不是自动的

1719
01:21:49,599 --> 01:21:52,059
master 服务器的故障切换并不是自动的

1720
01:21:52,059 --> 01:21:54,400
GFS 论文的原文里说需要人工干预

1721
01:21:54,400 --> 01:21:56,440
GFS 论文的原文里说需要人工干预

1722
01:21:56,440 --> 01:21:59,170
来处理已永久崩溃且需要更换的 master 主机

1723
01:21:59,170 --> 01:22:00,460
来处理已永久崩溃且需要更换的 master 主机

1724
01:22:00,460 --> 01:22:03,579
那可能要花几十分钟甚至更长的时间

1725
01:22:03,579 --> 01:22:05,980
那可能要花几十分钟甚至更长的时间

1726
01:22:05,980 --> 01:22:09,360
对于某些应用程序来说 这个故障恢复时间太长了

1727
01:22:09,360 --> 01:22:13,630
好极了，我们星期四见

1728
01:22:13,630 --> 01:22:15,970
我们将听到这个更多课程主题的信息

